{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DR_Detection_DenseNet121.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWfYzG9IEzqz",
        "outputId": "9b837db0-6e15-4ac6-f8d1-7fa7e9ffde22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from os.path import basename, join, exists"
      ],
      "metadata": {
        "id": "HGELrSewHMVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder=r\"/content/drive/MyDrive/My_projects _and _datasets/Final_work/APTOS/Train/\"\n",
        "total=0\n",
        "print('---Training set details----')\n",
        "for sub_folder in os.listdir(folder):\n",
        "  no_of_images=len(os.listdir(folder + sub_folder))\n",
        "  total+=no_of_images\n",
        "  print(str(no_of_images) + \" \" + sub_folder + \" images\")\n",
        "\n",
        "print(\"Total no. of images \",total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYKNgnxMHQbg",
        "outputId": "420d1432-b7f2-440d-a671-2dd8a6037ec9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---Training set details----\n",
            "1676 with_DR images\n",
            "1608 without_DR images\n",
            "Total no. of images  3284\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folder=r\"/content/drive/MyDrive/My_projects _and _datasets/Final_work/APTOS/Test/\"\n",
        "total=0\n",
        "print('---Test set details----')\n",
        "for sub_folder in os.listdir(folder):\n",
        "  no_of_images=len(os.listdir(folder + sub_folder))\n",
        "  total+=no_of_images\n",
        "  print(str(no_of_images) + \" \" + sub_folder + \" images\")\n",
        "\n",
        "print(\"Total no. of images\",total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJLPYMMYHgWw",
        "outputId": "a8e19c55-c72f-4b3e-f27c-b6344bb226e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---Test set details----\n",
            "181 with_DR images\n",
            "197 without_DR images\n",
            "Total no. of images 378\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.random.seed(777)\n",
        "import time\n",
        "import keras as keras\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.vgg16 import decode_predictions\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Activation,Flatten\n",
        "from keras.layers import merge,Input\n",
        "from keras.models import Model\n",
        "from keras.utils import np_utils\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.densenet import DenseNet121\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.applications.xception import Xception\n",
        "from keras.applications.vgg16 import preprocess_input as pi_vgg16\n",
        "from keras.applications.inception_v3 import preprocess_input as pi_incep\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input as pi_resnet\n",
        "from keras.applications.vgg19 import preprocess_input as pi_vgg19\n",
        "from keras.applications.xception import preprocess_input as pi_xcep \n",
        "from keras.models import load_model\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from sklearn.metrics import accuracy_score\n",
        "from  numpy import mean \n",
        "from numpy import std\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.optimizers import Adam,SGD\n",
        "from keras.callbacks import ReduceLROnPlateau,EarlyStopping,ModelCheckpoint\n",
        "from keras.layers import GlobalAveragePooling2D, Concatenate\n",
        "from keras.layers import BatchNormalization,Dropout\n",
        "from keras.layers import Lambda\n",
        "from keras.regularizers import l2\n",
        "import math\n",
        "from keras import backend as K\n",
        "from keras.metrics import categorical_accuracy\n",
        "import warnings\n",
        "warnings.filterwarnings('always')\n",
        "warnings.filterwarnings('ignore')\n",
        "from keras.models import load_model\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "dyQ6F4y9HmUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_height =224\n",
        "img_width = 224\n",
        "batch_size =32\n",
        "input_shape = (img_width, img_height, 3)"
      ],
      "metadata": {
        "id": "PvNArQseHsGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_seed = np.random.seed(1142)\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    featurewise_center=True,\n",
        "    featurewise_std_normalization=True,\n",
        "    validation_split= 0.2,\n",
        "    zoom_range=0.2)\n",
        "    #shear_range=0.2)\n",
        "\n",
        "train_generator_Dense = train_datagen.flow_from_directory(\n",
        "    \"/content/drive/MyDrive/My_projects _and _datasets/Final_work/APTOS/Train/\",\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    seed = random_seed,\n",
        "    shuffle=False,\n",
        "    subset = 'training',\n",
        "    class_mode='binary')\n",
        "\n",
        "val_generator_Dense = train_datagen.flow_from_directory(\n",
        "    \"/content/drive/MyDrive/My_projects _and _datasets/Final_work/APTOS/Train/\",\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    seed = random_seed,\n",
        "    shuffle=False,\n",
        "    subset = 'validation',\n",
        "    class_mode='binary')\n",
        "test_datagen=ImageDataGenerator(rescale=1./255)\n",
        "test_generator_Dense=test_datagen.flow_from_directory(\"/content/drive/MyDrive/My_projects _and _datasets/Final_work/APTOS/Test/\",\n",
        "                                                      target_size=(img_height, img_width),\n",
        "                                                          batch_size=batch_size, \n",
        "                                                          seed=random_seed,\n",
        "                                                          shuffle=False,\n",
        "                                                          class_mode='binary') # set as training data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yk4IxGPvJZc4",
        "outputId": "b8ac65ea-446a-491f-a248-62cdcc3479f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2628 images belonging to 2 classes.\n",
            "Found 656 images belonging to 2 classes.\n",
            "Found 378 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nb_train_samples = len(train_generator_Dense.filenames)\n",
        "nb_validation_samples = len(val_generator_Dense.filenames)\n",
        "predict_size_train = int(math.ceil(nb_train_samples / batch_size))\n",
        "predict_size_validation = int(math.ceil(nb_validation_samples / batch_size))\n",
        "\n",
        "nb_test_samples = len(test_generator_Dense.filenames)\n",
        "predict_size_test = int(math.ceil(nb_test_samples / batch_size))\n",
        "print(nb_train_samples)\n",
        "print(nb_validation_samples)\n",
        "print(nb_test_samples)\n",
        "print(predict_size_train)\n",
        "print(predict_size_validation)\n",
        "print(predict_size_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1s10sAFJfS5",
        "outputId": "4910c25b-b2c9-45f3-823d-f1bedef97c8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2628\n",
            "656\n",
            "378\n",
            "83\n",
            "21\n",
            "12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name=\"DenseNet121\"\n",
        "model = DenseNet121(include_top=False, weights=\"imagenet\",pooling='avg',input_tensor=Input(shape=input_shape))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ut9mjG-J0kP",
        "outputId": "19ecd142-0c8f-4bb0-ee5c-2e80d339c6b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29089792/29084464 [==============================] - 0s 0us/step\n",
            "29097984/29084464 [==============================] - 0s 0us/step\n",
            "Model: \"densenet121\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " zero_padding2d (ZeroPadding2D)  (None, 230, 230, 3)  0          ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv1/conv (Conv2D)            (None, 112, 112, 64  9408        ['zero_padding2d[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1/bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1/conv[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1/relu (Activation)        (None, 112, 112, 64  0           ['conv1/bn[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " zero_padding2d_1 (ZeroPadding2  (None, 114, 114, 64  0          ['conv1/relu[0][0]']             \n",
            " D)                             )                                                                 \n",
            "                                                                                                  \n",
            " pool1 (MaxPooling2D)           (None, 56, 56, 64)   0           ['zero_padding2d_1[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 64)  256         ['pool1[0][0]']                  \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_0_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 128)  8192        ['conv2_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_concat (Concatena  (None, 56, 56, 96)  0           ['pool1[0][0]',                  \n",
            " te)                                                              'conv2_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_0_bn (BatchNormal  (None, 56, 56, 96)  384         ['conv2_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_0_relu (Activatio  (None, 56, 56, 96)  0           ['conv2_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 128)  12288       ['conv2_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_concat (Concatena  (None, 56, 56, 128)  0          ['conv2_block1_concat[0][0]',    \n",
            " te)                                                              'conv2_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_0_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_0_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 128)  16384       ['conv2_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_concat (Concatena  (None, 56, 56, 160)  0          ['conv2_block2_concat[0][0]',    \n",
            " te)                                                              'conv2_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block4_0_bn (BatchNormal  (None, 56, 56, 160)  640        ['conv2_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block4_0_relu (Activatio  (None, 56, 56, 160)  0          ['conv2_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block4_1_conv (Conv2D)   (None, 56, 56, 128)  20480       ['conv2_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block4_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block4_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block4_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block4_concat (Concatena  (None, 56, 56, 192)  0          ['conv2_block3_concat[0][0]',    \n",
            " te)                                                              'conv2_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block5_0_bn (BatchNormal  (None, 56, 56, 192)  768        ['conv2_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block5_0_relu (Activatio  (None, 56, 56, 192)  0          ['conv2_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block5_1_conv (Conv2D)   (None, 56, 56, 128)  24576       ['conv2_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block5_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block5_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block5_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block5_concat (Concatena  (None, 56, 56, 224)  0          ['conv2_block4_concat[0][0]',    \n",
            " te)                                                              'conv2_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block6_0_bn (BatchNormal  (None, 56, 56, 224)  896        ['conv2_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block6_0_relu (Activatio  (None, 56, 56, 224)  0          ['conv2_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block6_1_conv (Conv2D)   (None, 56, 56, 128)  28672       ['conv2_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block6_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block6_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block6_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block6_concat (Concatena  (None, 56, 56, 256)  0          ['conv2_block5_concat[0][0]',    \n",
            " te)                                                              'conv2_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " pool2_bn (BatchNormalization)  (None, 56, 56, 256)  1024        ['conv2_block6_concat[0][0]']    \n",
            "                                                                                                  \n",
            " pool2_relu (Activation)        (None, 56, 56, 256)  0           ['pool2_bn[0][0]']               \n",
            "                                                                                                  \n",
            " pool2_conv (Conv2D)            (None, 56, 56, 128)  32768       ['pool2_relu[0][0]']             \n",
            "                                                                                                  \n",
            " pool2_pool (AveragePooling2D)  (None, 28, 28, 128)  0           ['pool2_conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 128)  512        ['pool2_pool[0][0]']             \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_0_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  16384       ['conv3_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_concat (Concatena  (None, 28, 28, 160)  0          ['pool2_pool[0][0]',             \n",
            " te)                                                              'conv3_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_0_bn (BatchNormal  (None, 28, 28, 160)  640        ['conv3_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_0_relu (Activatio  (None, 28, 28, 160)  0          ['conv3_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  20480       ['conv3_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_concat (Concatena  (None, 28, 28, 192)  0          ['conv3_block1_concat[0][0]',    \n",
            " te)                                                              'conv3_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_0_bn (BatchNormal  (None, 28, 28, 192)  768        ['conv3_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_0_relu (Activatio  (None, 28, 28, 192)  0          ['conv3_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  24576       ['conv3_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_concat (Concatena  (None, 28, 28, 224)  0          ['conv3_block2_concat[0][0]',    \n",
            " te)                                                              'conv3_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_0_bn (BatchNormal  (None, 28, 28, 224)  896        ['conv3_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_0_relu (Activatio  (None, 28, 28, 224)  0          ['conv3_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  28672       ['conv3_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_concat (Concatena  (None, 28, 28, 256)  0          ['conv3_block3_concat[0][0]',    \n",
            " te)                                                              'conv3_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block5_0_bn (BatchNormal  (None, 28, 28, 256)  1024       ['conv3_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block5_0_relu (Activatio  (None, 28, 28, 256)  0          ['conv3_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block5_1_conv (Conv2D)   (None, 28, 28, 128)  32768       ['conv3_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block5_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block5_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block5_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block5_concat (Concatena  (None, 28, 28, 288)  0          ['conv3_block4_concat[0][0]',    \n",
            " te)                                                              'conv3_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block6_0_bn (BatchNormal  (None, 28, 28, 288)  1152       ['conv3_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block6_0_relu (Activatio  (None, 28, 28, 288)  0          ['conv3_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block6_1_conv (Conv2D)   (None, 28, 28, 128)  36864       ['conv3_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block6_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block6_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block6_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block6_concat (Concatena  (None, 28, 28, 320)  0          ['conv3_block5_concat[0][0]',    \n",
            " te)                                                              'conv3_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block7_0_bn (BatchNormal  (None, 28, 28, 320)  1280       ['conv3_block6_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block7_0_relu (Activatio  (None, 28, 28, 320)  0          ['conv3_block7_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block7_1_conv (Conv2D)   (None, 28, 28, 128)  40960       ['conv3_block7_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block7_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block7_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block7_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block7_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block7_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block7_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block7_concat (Concatena  (None, 28, 28, 352)  0          ['conv3_block6_concat[0][0]',    \n",
            " te)                                                              'conv3_block7_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block8_0_bn (BatchNormal  (None, 28, 28, 352)  1408       ['conv3_block7_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block8_0_relu (Activatio  (None, 28, 28, 352)  0          ['conv3_block8_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block8_1_conv (Conv2D)   (None, 28, 28, 128)  45056       ['conv3_block8_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block8_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block8_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block8_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block8_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block8_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block8_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block8_concat (Concatena  (None, 28, 28, 384)  0          ['conv3_block7_concat[0][0]',    \n",
            " te)                                                              'conv3_block8_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block9_0_bn (BatchNormal  (None, 28, 28, 384)  1536       ['conv3_block8_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block9_0_relu (Activatio  (None, 28, 28, 384)  0          ['conv3_block9_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block9_1_conv (Conv2D)   (None, 28, 28, 128)  49152       ['conv3_block9_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block9_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block9_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block9_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block9_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block9_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block9_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block9_concat (Concatena  (None, 28, 28, 416)  0          ['conv3_block8_concat[0][0]',    \n",
            " te)                                                              'conv3_block9_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block10_0_bn (BatchNorma  (None, 28, 28, 416)  1664       ['conv3_block9_concat[0][0]']    \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block10_0_relu (Activati  (None, 28, 28, 416)  0          ['conv3_block10_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block10_1_conv (Conv2D)  (None, 28, 28, 128)  53248       ['conv3_block10_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block10_1_bn (BatchNorma  (None, 28, 28, 128)  512        ['conv3_block10_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block10_1_relu (Activati  (None, 28, 28, 128)  0          ['conv3_block10_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block10_2_conv (Conv2D)  (None, 28, 28, 32)   36864       ['conv3_block10_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block10_concat (Concaten  (None, 28, 28, 448)  0          ['conv3_block9_concat[0][0]',    \n",
            " ate)                                                             'conv3_block10_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block11_0_bn (BatchNorma  (None, 28, 28, 448)  1792       ['conv3_block10_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block11_0_relu (Activati  (None, 28, 28, 448)  0          ['conv3_block11_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block11_1_conv (Conv2D)  (None, 28, 28, 128)  57344       ['conv3_block11_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block11_1_bn (BatchNorma  (None, 28, 28, 128)  512        ['conv3_block11_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block11_1_relu (Activati  (None, 28, 28, 128)  0          ['conv3_block11_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block11_2_conv (Conv2D)  (None, 28, 28, 32)   36864       ['conv3_block11_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block11_concat (Concaten  (None, 28, 28, 480)  0          ['conv3_block10_concat[0][0]',   \n",
            " ate)                                                             'conv3_block11_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block12_0_bn (BatchNorma  (None, 28, 28, 480)  1920       ['conv3_block11_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block12_0_relu (Activati  (None, 28, 28, 480)  0          ['conv3_block12_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block12_1_conv (Conv2D)  (None, 28, 28, 128)  61440       ['conv3_block12_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block12_1_bn (BatchNorma  (None, 28, 28, 128)  512        ['conv3_block12_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block12_1_relu (Activati  (None, 28, 28, 128)  0          ['conv3_block12_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block12_2_conv (Conv2D)  (None, 28, 28, 32)   36864       ['conv3_block12_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block12_concat (Concaten  (None, 28, 28, 512)  0          ['conv3_block11_concat[0][0]',   \n",
            " ate)                                                             'conv3_block12_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " pool3_bn (BatchNormalization)  (None, 28, 28, 512)  2048        ['conv3_block12_concat[0][0]']   \n",
            "                                                                                                  \n",
            " pool3_relu (Activation)        (None, 28, 28, 512)  0           ['pool3_bn[0][0]']               \n",
            "                                                                                                  \n",
            " pool3_conv (Conv2D)            (None, 28, 28, 256)  131072      ['pool3_relu[0][0]']             \n",
            "                                                                                                  \n",
            " pool3_pool (AveragePooling2D)  (None, 14, 14, 256)  0           ['pool3_conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 256)  1024       ['pool3_pool[0][0]']             \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_0_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 128)  32768       ['conv4_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_concat (Concatena  (None, 14, 14, 288)  0          ['pool3_pool[0][0]',             \n",
            " te)                                                              'conv4_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_0_bn (BatchNormal  (None, 14, 14, 288)  1152       ['conv4_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_0_relu (Activatio  (None, 14, 14, 288)  0          ['conv4_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 128)  36864       ['conv4_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_concat (Concatena  (None, 14, 14, 320)  0          ['conv4_block1_concat[0][0]',    \n",
            " te)                                                              'conv4_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_0_bn (BatchNormal  (None, 14, 14, 320)  1280       ['conv4_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_0_relu (Activatio  (None, 14, 14, 320)  0          ['conv4_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 128)  40960       ['conv4_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_concat (Concatena  (None, 14, 14, 352)  0          ['conv4_block2_concat[0][0]',    \n",
            " te)                                                              'conv4_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_0_bn (BatchNormal  (None, 14, 14, 352)  1408       ['conv4_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_0_relu (Activatio  (None, 14, 14, 352)  0          ['conv4_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 128)  45056       ['conv4_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_concat (Concatena  (None, 14, 14, 384)  0          ['conv4_block3_concat[0][0]',    \n",
            " te)                                                              'conv4_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_0_bn (BatchNormal  (None, 14, 14, 384)  1536       ['conv4_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_0_relu (Activatio  (None, 14, 14, 384)  0          ['conv4_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 128)  49152       ['conv4_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_concat (Concatena  (None, 14, 14, 416)  0          ['conv4_block4_concat[0][0]',    \n",
            " te)                                                              'conv4_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_0_bn (BatchNormal  (None, 14, 14, 416)  1664       ['conv4_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_0_relu (Activatio  (None, 14, 14, 416)  0          ['conv4_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 128)  53248       ['conv4_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_concat (Concatena  (None, 14, 14, 448)  0          ['conv4_block5_concat[0][0]',    \n",
            " te)                                                              'conv4_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block7_0_bn (BatchNormal  (None, 14, 14, 448)  1792       ['conv4_block6_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block7_0_relu (Activatio  (None, 14, 14, 448)  0          ['conv4_block7_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block7_1_conv (Conv2D)   (None, 14, 14, 128)  57344       ['conv4_block7_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block7_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block7_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block7_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block7_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block7_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block7_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block7_concat (Concatena  (None, 14, 14, 480)  0          ['conv4_block6_concat[0][0]',    \n",
            " te)                                                              'conv4_block7_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block8_0_bn (BatchNormal  (None, 14, 14, 480)  1920       ['conv4_block7_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block8_0_relu (Activatio  (None, 14, 14, 480)  0          ['conv4_block8_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block8_1_conv (Conv2D)   (None, 14, 14, 128)  61440       ['conv4_block8_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block8_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block8_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block8_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block8_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block8_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block8_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block8_concat (Concatena  (None, 14, 14, 512)  0          ['conv4_block7_concat[0][0]',    \n",
            " te)                                                              'conv4_block8_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block9_0_bn (BatchNormal  (None, 14, 14, 512)  2048       ['conv4_block8_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block9_0_relu (Activatio  (None, 14, 14, 512)  0          ['conv4_block9_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block9_1_conv (Conv2D)   (None, 14, 14, 128)  65536       ['conv4_block9_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block9_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block9_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block9_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block9_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block9_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block9_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block9_concat (Concatena  (None, 14, 14, 544)  0          ['conv4_block8_concat[0][0]',    \n",
            " te)                                                              'conv4_block9_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block10_0_bn (BatchNorma  (None, 14, 14, 544)  2176       ['conv4_block9_concat[0][0]']    \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block10_0_relu (Activati  (None, 14, 14, 544)  0          ['conv4_block10_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block10_1_conv (Conv2D)  (None, 14, 14, 128)  69632       ['conv4_block10_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block10_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block10_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block10_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block10_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block10_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block10_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block10_concat (Concaten  (None, 14, 14, 576)  0          ['conv4_block9_concat[0][0]',    \n",
            " ate)                                                             'conv4_block10_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block11_0_bn (BatchNorma  (None, 14, 14, 576)  2304       ['conv4_block10_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block11_0_relu (Activati  (None, 14, 14, 576)  0          ['conv4_block11_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block11_1_conv (Conv2D)  (None, 14, 14, 128)  73728       ['conv4_block11_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block11_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block11_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block11_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block11_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block11_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block11_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block11_concat (Concaten  (None, 14, 14, 608)  0          ['conv4_block10_concat[0][0]',   \n",
            " ate)                                                             'conv4_block11_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block12_0_bn (BatchNorma  (None, 14, 14, 608)  2432       ['conv4_block11_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block12_0_relu (Activati  (None, 14, 14, 608)  0          ['conv4_block12_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block12_1_conv (Conv2D)  (None, 14, 14, 128)  77824       ['conv4_block12_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block12_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block12_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block12_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block12_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block12_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block12_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block12_concat (Concaten  (None, 14, 14, 640)  0          ['conv4_block11_concat[0][0]',   \n",
            " ate)                                                             'conv4_block12_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block13_0_bn (BatchNorma  (None, 14, 14, 640)  2560       ['conv4_block12_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block13_0_relu (Activati  (None, 14, 14, 640)  0          ['conv4_block13_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block13_1_conv (Conv2D)  (None, 14, 14, 128)  81920       ['conv4_block13_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block13_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block13_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block13_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block13_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block13_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block13_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block13_concat (Concaten  (None, 14, 14, 672)  0          ['conv4_block12_concat[0][0]',   \n",
            " ate)                                                             'conv4_block13_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block14_0_bn (BatchNorma  (None, 14, 14, 672)  2688       ['conv4_block13_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block14_0_relu (Activati  (None, 14, 14, 672)  0          ['conv4_block14_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block14_1_conv (Conv2D)  (None, 14, 14, 128)  86016       ['conv4_block14_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block14_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block14_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block14_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block14_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block14_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block14_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block14_concat (Concaten  (None, 14, 14, 704)  0          ['conv4_block13_concat[0][0]',   \n",
            " ate)                                                             'conv4_block14_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block15_0_bn (BatchNorma  (None, 14, 14, 704)  2816       ['conv4_block14_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block15_0_relu (Activati  (None, 14, 14, 704)  0          ['conv4_block15_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block15_1_conv (Conv2D)  (None, 14, 14, 128)  90112       ['conv4_block15_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block15_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block15_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block15_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block15_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block15_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block15_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block15_concat (Concaten  (None, 14, 14, 736)  0          ['conv4_block14_concat[0][0]',   \n",
            " ate)                                                             'conv4_block15_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block16_0_bn (BatchNorma  (None, 14, 14, 736)  2944       ['conv4_block15_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block16_0_relu (Activati  (None, 14, 14, 736)  0          ['conv4_block16_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block16_1_conv (Conv2D)  (None, 14, 14, 128)  94208       ['conv4_block16_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block16_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block16_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block16_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block16_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block16_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block16_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block16_concat (Concaten  (None, 14, 14, 768)  0          ['conv4_block15_concat[0][0]',   \n",
            " ate)                                                             'conv4_block16_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block17_0_bn (BatchNorma  (None, 14, 14, 768)  3072       ['conv4_block16_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block17_0_relu (Activati  (None, 14, 14, 768)  0          ['conv4_block17_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block17_1_conv (Conv2D)  (None, 14, 14, 128)  98304       ['conv4_block17_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block17_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block17_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block17_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block17_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block17_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block17_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block17_concat (Concaten  (None, 14, 14, 800)  0          ['conv4_block16_concat[0][0]',   \n",
            " ate)                                                             'conv4_block17_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block18_0_bn (BatchNorma  (None, 14, 14, 800)  3200       ['conv4_block17_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block18_0_relu (Activati  (None, 14, 14, 800)  0          ['conv4_block18_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block18_1_conv (Conv2D)  (None, 14, 14, 128)  102400      ['conv4_block18_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block18_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block18_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block18_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block18_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block18_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block18_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block18_concat (Concaten  (None, 14, 14, 832)  0          ['conv4_block17_concat[0][0]',   \n",
            " ate)                                                             'conv4_block18_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block19_0_bn (BatchNorma  (None, 14, 14, 832)  3328       ['conv4_block18_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block19_0_relu (Activati  (None, 14, 14, 832)  0          ['conv4_block19_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block19_1_conv (Conv2D)  (None, 14, 14, 128)  106496      ['conv4_block19_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block19_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block19_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block19_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block19_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block19_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block19_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block19_concat (Concaten  (None, 14, 14, 864)  0          ['conv4_block18_concat[0][0]',   \n",
            " ate)                                                             'conv4_block19_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block20_0_bn (BatchNorma  (None, 14, 14, 864)  3456       ['conv4_block19_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block20_0_relu (Activati  (None, 14, 14, 864)  0          ['conv4_block20_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block20_1_conv (Conv2D)  (None, 14, 14, 128)  110592      ['conv4_block20_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block20_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block20_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block20_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block20_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block20_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block20_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block20_concat (Concaten  (None, 14, 14, 896)  0          ['conv4_block19_concat[0][0]',   \n",
            " ate)                                                             'conv4_block20_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block21_0_bn (BatchNorma  (None, 14, 14, 896)  3584       ['conv4_block20_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block21_0_relu (Activati  (None, 14, 14, 896)  0          ['conv4_block21_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block21_1_conv (Conv2D)  (None, 14, 14, 128)  114688      ['conv4_block21_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block21_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block21_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block21_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block21_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block21_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block21_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block21_concat (Concaten  (None, 14, 14, 928)  0          ['conv4_block20_concat[0][0]',   \n",
            " ate)                                                             'conv4_block21_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block22_0_bn (BatchNorma  (None, 14, 14, 928)  3712       ['conv4_block21_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block22_0_relu (Activati  (None, 14, 14, 928)  0          ['conv4_block22_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block22_1_conv (Conv2D)  (None, 14, 14, 128)  118784      ['conv4_block22_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block22_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block22_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block22_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block22_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block22_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block22_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block22_concat (Concaten  (None, 14, 14, 960)  0          ['conv4_block21_concat[0][0]',   \n",
            " ate)                                                             'conv4_block22_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block23_0_bn (BatchNorma  (None, 14, 14, 960)  3840       ['conv4_block22_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block23_0_relu (Activati  (None, 14, 14, 960)  0          ['conv4_block23_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block23_1_conv (Conv2D)  (None, 14, 14, 128)  122880      ['conv4_block23_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block23_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block23_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block23_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block23_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block23_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block23_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block23_concat (Concaten  (None, 14, 14, 992)  0          ['conv4_block22_concat[0][0]',   \n",
            " ate)                                                             'conv4_block23_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block24_0_bn (BatchNorma  (None, 14, 14, 992)  3968       ['conv4_block23_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block24_0_relu (Activati  (None, 14, 14, 992)  0          ['conv4_block24_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block24_1_conv (Conv2D)  (None, 14, 14, 128)  126976      ['conv4_block24_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block24_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block24_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block24_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block24_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block24_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block24_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block24_concat (Concaten  (None, 14, 14, 1024  0          ['conv4_block23_concat[0][0]',   \n",
            " ate)                           )                                 'conv4_block24_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " pool4_bn (BatchNormalization)  (None, 14, 14, 1024  4096        ['conv4_block24_concat[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool4_relu (Activation)        (None, 14, 14, 1024  0           ['pool4_bn[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool4_conv (Conv2D)            (None, 14, 14, 512)  524288      ['pool4_relu[0][0]']             \n",
            "                                                                                                  \n",
            " pool4_pool (AveragePooling2D)  (None, 7, 7, 512)    0           ['pool4_conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 512)   2048        ['pool4_pool[0][0]']             \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_0_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 128)    65536       ['conv5_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_concat (Concatena  (None, 7, 7, 544)   0           ['pool4_pool[0][0]',             \n",
            " te)                                                              'conv5_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_0_bn (BatchNormal  (None, 7, 7, 544)   2176        ['conv5_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_0_relu (Activatio  (None, 7, 7, 544)   0           ['conv5_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 128)    69632       ['conv5_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_concat (Concatena  (None, 7, 7, 576)   0           ['conv5_block1_concat[0][0]',    \n",
            " te)                                                              'conv5_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_0_bn (BatchNormal  (None, 7, 7, 576)   2304        ['conv5_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_0_relu (Activatio  (None, 7, 7, 576)   0           ['conv5_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 128)    73728       ['conv5_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_concat (Concatena  (None, 7, 7, 608)   0           ['conv5_block2_concat[0][0]',    \n",
            " te)                                                              'conv5_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block4_0_bn (BatchNormal  (None, 7, 7, 608)   2432        ['conv5_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block4_0_relu (Activatio  (None, 7, 7, 608)   0           ['conv5_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block4_1_conv (Conv2D)   (None, 7, 7, 128)    77824       ['conv5_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block4_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block4_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block4_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block4_concat (Concatena  (None, 7, 7, 640)   0           ['conv5_block3_concat[0][0]',    \n",
            " te)                                                              'conv5_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block5_0_bn (BatchNormal  (None, 7, 7, 640)   2560        ['conv5_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block5_0_relu (Activatio  (None, 7, 7, 640)   0           ['conv5_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block5_1_conv (Conv2D)   (None, 7, 7, 128)    81920       ['conv5_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block5_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block5_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block5_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block5_concat (Concatena  (None, 7, 7, 672)   0           ['conv5_block4_concat[0][0]',    \n",
            " te)                                                              'conv5_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block6_0_bn (BatchNormal  (None, 7, 7, 672)   2688        ['conv5_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block6_0_relu (Activatio  (None, 7, 7, 672)   0           ['conv5_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block6_1_conv (Conv2D)   (None, 7, 7, 128)    86016       ['conv5_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block6_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block6_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block6_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block6_concat (Concatena  (None, 7, 7, 704)   0           ['conv5_block5_concat[0][0]',    \n",
            " te)                                                              'conv5_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block7_0_bn (BatchNormal  (None, 7, 7, 704)   2816        ['conv5_block6_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block7_0_relu (Activatio  (None, 7, 7, 704)   0           ['conv5_block7_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block7_1_conv (Conv2D)   (None, 7, 7, 128)    90112       ['conv5_block7_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block7_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block7_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block7_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block7_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block7_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block7_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block7_concat (Concatena  (None, 7, 7, 736)   0           ['conv5_block6_concat[0][0]',    \n",
            " te)                                                              'conv5_block7_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block8_0_bn (BatchNormal  (None, 7, 7, 736)   2944        ['conv5_block7_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block8_0_relu (Activatio  (None, 7, 7, 736)   0           ['conv5_block8_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block8_1_conv (Conv2D)   (None, 7, 7, 128)    94208       ['conv5_block8_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block8_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block8_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block8_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block8_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block8_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block8_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block8_concat (Concatena  (None, 7, 7, 768)   0           ['conv5_block7_concat[0][0]',    \n",
            " te)                                                              'conv5_block8_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block9_0_bn (BatchNormal  (None, 7, 7, 768)   3072        ['conv5_block8_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block9_0_relu (Activatio  (None, 7, 7, 768)   0           ['conv5_block9_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block9_1_conv (Conv2D)   (None, 7, 7, 128)    98304       ['conv5_block9_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block9_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block9_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block9_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block9_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block9_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block9_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block9_concat (Concatena  (None, 7, 7, 800)   0           ['conv5_block8_concat[0][0]',    \n",
            " te)                                                              'conv5_block9_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block10_0_bn (BatchNorma  (None, 7, 7, 800)   3200        ['conv5_block9_concat[0][0]']    \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block10_0_relu (Activati  (None, 7, 7, 800)   0           ['conv5_block10_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block10_1_conv (Conv2D)  (None, 7, 7, 128)    102400      ['conv5_block10_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block10_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block10_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block10_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block10_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block10_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block10_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block10_concat (Concaten  (None, 7, 7, 832)   0           ['conv5_block9_concat[0][0]',    \n",
            " ate)                                                             'conv5_block10_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block11_0_bn (BatchNorma  (None, 7, 7, 832)   3328        ['conv5_block10_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block11_0_relu (Activati  (None, 7, 7, 832)   0           ['conv5_block11_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block11_1_conv (Conv2D)  (None, 7, 7, 128)    106496      ['conv5_block11_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block11_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block11_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block11_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block11_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block11_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block11_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block11_concat (Concaten  (None, 7, 7, 864)   0           ['conv5_block10_concat[0][0]',   \n",
            " ate)                                                             'conv5_block11_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block12_0_bn (BatchNorma  (None, 7, 7, 864)   3456        ['conv5_block11_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block12_0_relu (Activati  (None, 7, 7, 864)   0           ['conv5_block12_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block12_1_conv (Conv2D)  (None, 7, 7, 128)    110592      ['conv5_block12_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block12_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block12_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block12_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block12_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block12_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block12_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block12_concat (Concaten  (None, 7, 7, 896)   0           ['conv5_block11_concat[0][0]',   \n",
            " ate)                                                             'conv5_block12_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block13_0_bn (BatchNorma  (None, 7, 7, 896)   3584        ['conv5_block12_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block13_0_relu (Activati  (None, 7, 7, 896)   0           ['conv5_block13_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block13_1_conv (Conv2D)  (None, 7, 7, 128)    114688      ['conv5_block13_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block13_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block13_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block13_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block13_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block13_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block13_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block13_concat (Concaten  (None, 7, 7, 928)   0           ['conv5_block12_concat[0][0]',   \n",
            " ate)                                                             'conv5_block13_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block14_0_bn (BatchNorma  (None, 7, 7, 928)   3712        ['conv5_block13_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block14_0_relu (Activati  (None, 7, 7, 928)   0           ['conv5_block14_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block14_1_conv (Conv2D)  (None, 7, 7, 128)    118784      ['conv5_block14_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block14_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block14_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block14_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block14_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block14_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block14_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block14_concat (Concaten  (None, 7, 7, 960)   0           ['conv5_block13_concat[0][0]',   \n",
            " ate)                                                             'conv5_block14_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block15_0_bn (BatchNorma  (None, 7, 7, 960)   3840        ['conv5_block14_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block15_0_relu (Activati  (None, 7, 7, 960)   0           ['conv5_block15_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block15_1_conv (Conv2D)  (None, 7, 7, 128)    122880      ['conv5_block15_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block15_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block15_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block15_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block15_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block15_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block15_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block15_concat (Concaten  (None, 7, 7, 992)   0           ['conv5_block14_concat[0][0]',   \n",
            " ate)                                                             'conv5_block15_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block16_0_bn (BatchNorma  (None, 7, 7, 992)   3968        ['conv5_block15_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block16_0_relu (Activati  (None, 7, 7, 992)   0           ['conv5_block16_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block16_1_conv (Conv2D)  (None, 7, 7, 128)    126976      ['conv5_block16_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block16_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block16_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block16_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block16_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block16_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block16_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block16_concat (Concaten  (None, 7, 7, 1024)  0           ['conv5_block15_concat[0][0]',   \n",
            " ate)                                                             'conv5_block16_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " bn (BatchNormalization)        (None, 7, 7, 1024)   4096        ['conv5_block16_concat[0][0]']   \n",
            "                                                                                                  \n",
            " relu (Activation)              (None, 7, 7, 1024)   0           ['bn[0][0]']                     \n",
            "                                                                                                  \n",
            " avg_pool (GlobalAveragePooling  (None, 1024)        0           ['relu[0][0]']                   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 7,037,504\n",
            "Trainable params: 6,953,856\n",
            "Non-trainable params: 83,648\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3O7-oiTKneU",
        "outputId": "5ecb2021-1cce-464e-f881-e91444851048"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"densenet121\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " zero_padding2d (ZeroPadding2D)  (None, 230, 230, 3)  0          ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv1/conv (Conv2D)            (None, 112, 112, 64  9408        ['zero_padding2d[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1/bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1/conv[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1/relu (Activation)        (None, 112, 112, 64  0           ['conv1/bn[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " zero_padding2d_1 (ZeroPadding2  (None, 114, 114, 64  0          ['conv1/relu[0][0]']             \n",
            " D)                             )                                                                 \n",
            "                                                                                                  \n",
            " pool1 (MaxPooling2D)           (None, 56, 56, 64)   0           ['zero_padding2d_1[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 64)  256         ['pool1[0][0]']                  \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_0_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 128)  8192        ['conv2_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_concat (Concatena  (None, 56, 56, 96)  0           ['pool1[0][0]',                  \n",
            " te)                                                              'conv2_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_0_bn (BatchNormal  (None, 56, 56, 96)  384         ['conv2_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_0_relu (Activatio  (None, 56, 56, 96)  0           ['conv2_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 128)  12288       ['conv2_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_concat (Concatena  (None, 56, 56, 128)  0          ['conv2_block1_concat[0][0]',    \n",
            " te)                                                              'conv2_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_0_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_0_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 128)  16384       ['conv2_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_concat (Concatena  (None, 56, 56, 160)  0          ['conv2_block2_concat[0][0]',    \n",
            " te)                                                              'conv2_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block4_0_bn (BatchNormal  (None, 56, 56, 160)  640        ['conv2_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block4_0_relu (Activatio  (None, 56, 56, 160)  0          ['conv2_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block4_1_conv (Conv2D)   (None, 56, 56, 128)  20480       ['conv2_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block4_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block4_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block4_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block4_concat (Concatena  (None, 56, 56, 192)  0          ['conv2_block3_concat[0][0]',    \n",
            " te)                                                              'conv2_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block5_0_bn (BatchNormal  (None, 56, 56, 192)  768        ['conv2_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block5_0_relu (Activatio  (None, 56, 56, 192)  0          ['conv2_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block5_1_conv (Conv2D)   (None, 56, 56, 128)  24576       ['conv2_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block5_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block5_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block5_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block5_concat (Concatena  (None, 56, 56, 224)  0          ['conv2_block4_concat[0][0]',    \n",
            " te)                                                              'conv2_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block6_0_bn (BatchNormal  (None, 56, 56, 224)  896        ['conv2_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block6_0_relu (Activatio  (None, 56, 56, 224)  0          ['conv2_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block6_1_conv (Conv2D)   (None, 56, 56, 128)  28672       ['conv2_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block6_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block6_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block6_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block6_concat (Concatena  (None, 56, 56, 256)  0          ['conv2_block5_concat[0][0]',    \n",
            " te)                                                              'conv2_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " pool2_bn (BatchNormalization)  (None, 56, 56, 256)  1024        ['conv2_block6_concat[0][0]']    \n",
            "                                                                                                  \n",
            " pool2_relu (Activation)        (None, 56, 56, 256)  0           ['pool2_bn[0][0]']               \n",
            "                                                                                                  \n",
            " pool2_conv (Conv2D)            (None, 56, 56, 128)  32768       ['pool2_relu[0][0]']             \n",
            "                                                                                                  \n",
            " pool2_pool (AveragePooling2D)  (None, 28, 28, 128)  0           ['pool2_conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 128)  512        ['pool2_pool[0][0]']             \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_0_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  16384       ['conv3_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_concat (Concatena  (None, 28, 28, 160)  0          ['pool2_pool[0][0]',             \n",
            " te)                                                              'conv3_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_0_bn (BatchNormal  (None, 28, 28, 160)  640        ['conv3_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_0_relu (Activatio  (None, 28, 28, 160)  0          ['conv3_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  20480       ['conv3_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_concat (Concatena  (None, 28, 28, 192)  0          ['conv3_block1_concat[0][0]',    \n",
            " te)                                                              'conv3_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_0_bn (BatchNormal  (None, 28, 28, 192)  768        ['conv3_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_0_relu (Activatio  (None, 28, 28, 192)  0          ['conv3_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  24576       ['conv3_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_concat (Concatena  (None, 28, 28, 224)  0          ['conv3_block2_concat[0][0]',    \n",
            " te)                                                              'conv3_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_0_bn (BatchNormal  (None, 28, 28, 224)  896        ['conv3_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_0_relu (Activatio  (None, 28, 28, 224)  0          ['conv3_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  28672       ['conv3_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_concat (Concatena  (None, 28, 28, 256)  0          ['conv3_block3_concat[0][0]',    \n",
            " te)                                                              'conv3_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block5_0_bn (BatchNormal  (None, 28, 28, 256)  1024       ['conv3_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block5_0_relu (Activatio  (None, 28, 28, 256)  0          ['conv3_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block5_1_conv (Conv2D)   (None, 28, 28, 128)  32768       ['conv3_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block5_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block5_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block5_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block5_concat (Concatena  (None, 28, 28, 288)  0          ['conv3_block4_concat[0][0]',    \n",
            " te)                                                              'conv3_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block6_0_bn (BatchNormal  (None, 28, 28, 288)  1152       ['conv3_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block6_0_relu (Activatio  (None, 28, 28, 288)  0          ['conv3_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block6_1_conv (Conv2D)   (None, 28, 28, 128)  36864       ['conv3_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block6_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block6_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block6_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block6_concat (Concatena  (None, 28, 28, 320)  0          ['conv3_block5_concat[0][0]',    \n",
            " te)                                                              'conv3_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block7_0_bn (BatchNormal  (None, 28, 28, 320)  1280       ['conv3_block6_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block7_0_relu (Activatio  (None, 28, 28, 320)  0          ['conv3_block7_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block7_1_conv (Conv2D)   (None, 28, 28, 128)  40960       ['conv3_block7_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block7_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block7_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block7_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block7_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block7_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block7_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block7_concat (Concatena  (None, 28, 28, 352)  0          ['conv3_block6_concat[0][0]',    \n",
            " te)                                                              'conv3_block7_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block8_0_bn (BatchNormal  (None, 28, 28, 352)  1408       ['conv3_block7_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block8_0_relu (Activatio  (None, 28, 28, 352)  0          ['conv3_block8_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block8_1_conv (Conv2D)   (None, 28, 28, 128)  45056       ['conv3_block8_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block8_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block8_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block8_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block8_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block8_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block8_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block8_concat (Concatena  (None, 28, 28, 384)  0          ['conv3_block7_concat[0][0]',    \n",
            " te)                                                              'conv3_block8_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block9_0_bn (BatchNormal  (None, 28, 28, 384)  1536       ['conv3_block8_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block9_0_relu (Activatio  (None, 28, 28, 384)  0          ['conv3_block9_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block9_1_conv (Conv2D)   (None, 28, 28, 128)  49152       ['conv3_block9_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block9_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block9_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block9_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block9_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block9_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block9_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block9_concat (Concatena  (None, 28, 28, 416)  0          ['conv3_block8_concat[0][0]',    \n",
            " te)                                                              'conv3_block9_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block10_0_bn (BatchNorma  (None, 28, 28, 416)  1664       ['conv3_block9_concat[0][0]']    \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block10_0_relu (Activati  (None, 28, 28, 416)  0          ['conv3_block10_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block10_1_conv (Conv2D)  (None, 28, 28, 128)  53248       ['conv3_block10_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block10_1_bn (BatchNorma  (None, 28, 28, 128)  512        ['conv3_block10_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block10_1_relu (Activati  (None, 28, 28, 128)  0          ['conv3_block10_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block10_2_conv (Conv2D)  (None, 28, 28, 32)   36864       ['conv3_block10_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block10_concat (Concaten  (None, 28, 28, 448)  0          ['conv3_block9_concat[0][0]',    \n",
            " ate)                                                             'conv3_block10_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block11_0_bn (BatchNorma  (None, 28, 28, 448)  1792       ['conv3_block10_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block11_0_relu (Activati  (None, 28, 28, 448)  0          ['conv3_block11_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block11_1_conv (Conv2D)  (None, 28, 28, 128)  57344       ['conv3_block11_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block11_1_bn (BatchNorma  (None, 28, 28, 128)  512        ['conv3_block11_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block11_1_relu (Activati  (None, 28, 28, 128)  0          ['conv3_block11_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block11_2_conv (Conv2D)  (None, 28, 28, 32)   36864       ['conv3_block11_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block11_concat (Concaten  (None, 28, 28, 480)  0          ['conv3_block10_concat[0][0]',   \n",
            " ate)                                                             'conv3_block11_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block12_0_bn (BatchNorma  (None, 28, 28, 480)  1920       ['conv3_block11_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block12_0_relu (Activati  (None, 28, 28, 480)  0          ['conv3_block12_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block12_1_conv (Conv2D)  (None, 28, 28, 128)  61440       ['conv3_block12_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block12_1_bn (BatchNorma  (None, 28, 28, 128)  512        ['conv3_block12_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block12_1_relu (Activati  (None, 28, 28, 128)  0          ['conv3_block12_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block12_2_conv (Conv2D)  (None, 28, 28, 32)   36864       ['conv3_block12_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block12_concat (Concaten  (None, 28, 28, 512)  0          ['conv3_block11_concat[0][0]',   \n",
            " ate)                                                             'conv3_block12_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " pool3_bn (BatchNormalization)  (None, 28, 28, 512)  2048        ['conv3_block12_concat[0][0]']   \n",
            "                                                                                                  \n",
            " pool3_relu (Activation)        (None, 28, 28, 512)  0           ['pool3_bn[0][0]']               \n",
            "                                                                                                  \n",
            " pool3_conv (Conv2D)            (None, 28, 28, 256)  131072      ['pool3_relu[0][0]']             \n",
            "                                                                                                  \n",
            " pool3_pool (AveragePooling2D)  (None, 14, 14, 256)  0           ['pool3_conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 256)  1024       ['pool3_pool[0][0]']             \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_0_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 128)  32768       ['conv4_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_concat (Concatena  (None, 14, 14, 288)  0          ['pool3_pool[0][0]',             \n",
            " te)                                                              'conv4_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_0_bn (BatchNormal  (None, 14, 14, 288)  1152       ['conv4_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_0_relu (Activatio  (None, 14, 14, 288)  0          ['conv4_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 128)  36864       ['conv4_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_concat (Concatena  (None, 14, 14, 320)  0          ['conv4_block1_concat[0][0]',    \n",
            " te)                                                              'conv4_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_0_bn (BatchNormal  (None, 14, 14, 320)  1280       ['conv4_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_0_relu (Activatio  (None, 14, 14, 320)  0          ['conv4_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 128)  40960       ['conv4_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_concat (Concatena  (None, 14, 14, 352)  0          ['conv4_block2_concat[0][0]',    \n",
            " te)                                                              'conv4_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_0_bn (BatchNormal  (None, 14, 14, 352)  1408       ['conv4_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_0_relu (Activatio  (None, 14, 14, 352)  0          ['conv4_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 128)  45056       ['conv4_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_concat (Concatena  (None, 14, 14, 384)  0          ['conv4_block3_concat[0][0]',    \n",
            " te)                                                              'conv4_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_0_bn (BatchNormal  (None, 14, 14, 384)  1536       ['conv4_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_0_relu (Activatio  (None, 14, 14, 384)  0          ['conv4_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 128)  49152       ['conv4_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_concat (Concatena  (None, 14, 14, 416)  0          ['conv4_block4_concat[0][0]',    \n",
            " te)                                                              'conv4_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_0_bn (BatchNormal  (None, 14, 14, 416)  1664       ['conv4_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_0_relu (Activatio  (None, 14, 14, 416)  0          ['conv4_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 128)  53248       ['conv4_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_concat (Concatena  (None, 14, 14, 448)  0          ['conv4_block5_concat[0][0]',    \n",
            " te)                                                              'conv4_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block7_0_bn (BatchNormal  (None, 14, 14, 448)  1792       ['conv4_block6_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block7_0_relu (Activatio  (None, 14, 14, 448)  0          ['conv4_block7_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block7_1_conv (Conv2D)   (None, 14, 14, 128)  57344       ['conv4_block7_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block7_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block7_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block7_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block7_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block7_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block7_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block7_concat (Concatena  (None, 14, 14, 480)  0          ['conv4_block6_concat[0][0]',    \n",
            " te)                                                              'conv4_block7_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block8_0_bn (BatchNormal  (None, 14, 14, 480)  1920       ['conv4_block7_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block8_0_relu (Activatio  (None, 14, 14, 480)  0          ['conv4_block8_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block8_1_conv (Conv2D)   (None, 14, 14, 128)  61440       ['conv4_block8_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block8_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block8_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block8_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block8_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block8_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block8_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block8_concat (Concatena  (None, 14, 14, 512)  0          ['conv4_block7_concat[0][0]',    \n",
            " te)                                                              'conv4_block8_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block9_0_bn (BatchNormal  (None, 14, 14, 512)  2048       ['conv4_block8_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block9_0_relu (Activatio  (None, 14, 14, 512)  0          ['conv4_block9_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block9_1_conv (Conv2D)   (None, 14, 14, 128)  65536       ['conv4_block9_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block9_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block9_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block9_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block9_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block9_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block9_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block9_concat (Concatena  (None, 14, 14, 544)  0          ['conv4_block8_concat[0][0]',    \n",
            " te)                                                              'conv4_block9_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block10_0_bn (BatchNorma  (None, 14, 14, 544)  2176       ['conv4_block9_concat[0][0]']    \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block10_0_relu (Activati  (None, 14, 14, 544)  0          ['conv4_block10_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block10_1_conv (Conv2D)  (None, 14, 14, 128)  69632       ['conv4_block10_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block10_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block10_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block10_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block10_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block10_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block10_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block10_concat (Concaten  (None, 14, 14, 576)  0          ['conv4_block9_concat[0][0]',    \n",
            " ate)                                                             'conv4_block10_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block11_0_bn (BatchNorma  (None, 14, 14, 576)  2304       ['conv4_block10_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block11_0_relu (Activati  (None, 14, 14, 576)  0          ['conv4_block11_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block11_1_conv (Conv2D)  (None, 14, 14, 128)  73728       ['conv4_block11_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block11_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block11_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block11_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block11_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block11_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block11_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block11_concat (Concaten  (None, 14, 14, 608)  0          ['conv4_block10_concat[0][0]',   \n",
            " ate)                                                             'conv4_block11_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block12_0_bn (BatchNorma  (None, 14, 14, 608)  2432       ['conv4_block11_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block12_0_relu (Activati  (None, 14, 14, 608)  0          ['conv4_block12_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block12_1_conv (Conv2D)  (None, 14, 14, 128)  77824       ['conv4_block12_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block12_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block12_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block12_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block12_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block12_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block12_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block12_concat (Concaten  (None, 14, 14, 640)  0          ['conv4_block11_concat[0][0]',   \n",
            " ate)                                                             'conv4_block12_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block13_0_bn (BatchNorma  (None, 14, 14, 640)  2560       ['conv4_block12_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block13_0_relu (Activati  (None, 14, 14, 640)  0          ['conv4_block13_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block13_1_conv (Conv2D)  (None, 14, 14, 128)  81920       ['conv4_block13_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block13_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block13_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block13_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block13_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block13_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block13_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block13_concat (Concaten  (None, 14, 14, 672)  0          ['conv4_block12_concat[0][0]',   \n",
            " ate)                                                             'conv4_block13_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block14_0_bn (BatchNorma  (None, 14, 14, 672)  2688       ['conv4_block13_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block14_0_relu (Activati  (None, 14, 14, 672)  0          ['conv4_block14_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block14_1_conv (Conv2D)  (None, 14, 14, 128)  86016       ['conv4_block14_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block14_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block14_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block14_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block14_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block14_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block14_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block14_concat (Concaten  (None, 14, 14, 704)  0          ['conv4_block13_concat[0][0]',   \n",
            " ate)                                                             'conv4_block14_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block15_0_bn (BatchNorma  (None, 14, 14, 704)  2816       ['conv4_block14_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block15_0_relu (Activati  (None, 14, 14, 704)  0          ['conv4_block15_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block15_1_conv (Conv2D)  (None, 14, 14, 128)  90112       ['conv4_block15_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block15_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block15_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block15_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block15_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block15_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block15_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block15_concat (Concaten  (None, 14, 14, 736)  0          ['conv4_block14_concat[0][0]',   \n",
            " ate)                                                             'conv4_block15_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block16_0_bn (BatchNorma  (None, 14, 14, 736)  2944       ['conv4_block15_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block16_0_relu (Activati  (None, 14, 14, 736)  0          ['conv4_block16_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block16_1_conv (Conv2D)  (None, 14, 14, 128)  94208       ['conv4_block16_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block16_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block16_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block16_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block16_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block16_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block16_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block16_concat (Concaten  (None, 14, 14, 768)  0          ['conv4_block15_concat[0][0]',   \n",
            " ate)                                                             'conv4_block16_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block17_0_bn (BatchNorma  (None, 14, 14, 768)  3072       ['conv4_block16_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block17_0_relu (Activati  (None, 14, 14, 768)  0          ['conv4_block17_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block17_1_conv (Conv2D)  (None, 14, 14, 128)  98304       ['conv4_block17_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block17_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block17_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block17_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block17_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block17_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block17_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block17_concat (Concaten  (None, 14, 14, 800)  0          ['conv4_block16_concat[0][0]',   \n",
            " ate)                                                             'conv4_block17_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block18_0_bn (BatchNorma  (None, 14, 14, 800)  3200       ['conv4_block17_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block18_0_relu (Activati  (None, 14, 14, 800)  0          ['conv4_block18_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block18_1_conv (Conv2D)  (None, 14, 14, 128)  102400      ['conv4_block18_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block18_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block18_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block18_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block18_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block18_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block18_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block18_concat (Concaten  (None, 14, 14, 832)  0          ['conv4_block17_concat[0][0]',   \n",
            " ate)                                                             'conv4_block18_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block19_0_bn (BatchNorma  (None, 14, 14, 832)  3328       ['conv4_block18_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block19_0_relu (Activati  (None, 14, 14, 832)  0          ['conv4_block19_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block19_1_conv (Conv2D)  (None, 14, 14, 128)  106496      ['conv4_block19_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block19_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block19_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block19_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block19_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block19_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block19_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block19_concat (Concaten  (None, 14, 14, 864)  0          ['conv4_block18_concat[0][0]',   \n",
            " ate)                                                             'conv4_block19_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block20_0_bn (BatchNorma  (None, 14, 14, 864)  3456       ['conv4_block19_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block20_0_relu (Activati  (None, 14, 14, 864)  0          ['conv4_block20_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block20_1_conv (Conv2D)  (None, 14, 14, 128)  110592      ['conv4_block20_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block20_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block20_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block20_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block20_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block20_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block20_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block20_concat (Concaten  (None, 14, 14, 896)  0          ['conv4_block19_concat[0][0]',   \n",
            " ate)                                                             'conv4_block20_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block21_0_bn (BatchNorma  (None, 14, 14, 896)  3584       ['conv4_block20_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block21_0_relu (Activati  (None, 14, 14, 896)  0          ['conv4_block21_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block21_1_conv (Conv2D)  (None, 14, 14, 128)  114688      ['conv4_block21_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block21_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block21_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block21_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block21_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block21_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block21_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block21_concat (Concaten  (None, 14, 14, 928)  0          ['conv4_block20_concat[0][0]',   \n",
            " ate)                                                             'conv4_block21_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block22_0_bn (BatchNorma  (None, 14, 14, 928)  3712       ['conv4_block21_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block22_0_relu (Activati  (None, 14, 14, 928)  0          ['conv4_block22_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block22_1_conv (Conv2D)  (None, 14, 14, 128)  118784      ['conv4_block22_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block22_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block22_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block22_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block22_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block22_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block22_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block22_concat (Concaten  (None, 14, 14, 960)  0          ['conv4_block21_concat[0][0]',   \n",
            " ate)                                                             'conv4_block22_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block23_0_bn (BatchNorma  (None, 14, 14, 960)  3840       ['conv4_block22_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block23_0_relu (Activati  (None, 14, 14, 960)  0          ['conv4_block23_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block23_1_conv (Conv2D)  (None, 14, 14, 128)  122880      ['conv4_block23_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block23_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block23_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block23_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block23_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block23_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block23_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block23_concat (Concaten  (None, 14, 14, 992)  0          ['conv4_block22_concat[0][0]',   \n",
            " ate)                                                             'conv4_block23_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block24_0_bn (BatchNorma  (None, 14, 14, 992)  3968       ['conv4_block23_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block24_0_relu (Activati  (None, 14, 14, 992)  0          ['conv4_block24_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block24_1_conv (Conv2D)  (None, 14, 14, 128)  126976      ['conv4_block24_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block24_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block24_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block24_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block24_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block24_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block24_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block24_concat (Concaten  (None, 14, 14, 1024  0          ['conv4_block23_concat[0][0]',   \n",
            " ate)                           )                                 'conv4_block24_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " pool4_bn (BatchNormalization)  (None, 14, 14, 1024  4096        ['conv4_block24_concat[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool4_relu (Activation)        (None, 14, 14, 1024  0           ['pool4_bn[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool4_conv (Conv2D)            (None, 14, 14, 512)  524288      ['pool4_relu[0][0]']             \n",
            "                                                                                                  \n",
            " pool4_pool (AveragePooling2D)  (None, 7, 7, 512)    0           ['pool4_conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 512)   2048        ['pool4_pool[0][0]']             \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_0_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 128)    65536       ['conv5_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_concat (Concatena  (None, 7, 7, 544)   0           ['pool4_pool[0][0]',             \n",
            " te)                                                              'conv5_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_0_bn (BatchNormal  (None, 7, 7, 544)   2176        ['conv5_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_0_relu (Activatio  (None, 7, 7, 544)   0           ['conv5_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 128)    69632       ['conv5_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_concat (Concatena  (None, 7, 7, 576)   0           ['conv5_block1_concat[0][0]',    \n",
            " te)                                                              'conv5_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_0_bn (BatchNormal  (None, 7, 7, 576)   2304        ['conv5_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_0_relu (Activatio  (None, 7, 7, 576)   0           ['conv5_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 128)    73728       ['conv5_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_concat (Concatena  (None, 7, 7, 608)   0           ['conv5_block2_concat[0][0]',    \n",
            " te)                                                              'conv5_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block4_0_bn (BatchNormal  (None, 7, 7, 608)   2432        ['conv5_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block4_0_relu (Activatio  (None, 7, 7, 608)   0           ['conv5_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block4_1_conv (Conv2D)   (None, 7, 7, 128)    77824       ['conv5_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block4_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block4_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block4_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block4_concat (Concatena  (None, 7, 7, 640)   0           ['conv5_block3_concat[0][0]',    \n",
            " te)                                                              'conv5_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block5_0_bn (BatchNormal  (None, 7, 7, 640)   2560        ['conv5_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block5_0_relu (Activatio  (None, 7, 7, 640)   0           ['conv5_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block5_1_conv (Conv2D)   (None, 7, 7, 128)    81920       ['conv5_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block5_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block5_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block5_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block5_concat (Concatena  (None, 7, 7, 672)   0           ['conv5_block4_concat[0][0]',    \n",
            " te)                                                              'conv5_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block6_0_bn (BatchNormal  (None, 7, 7, 672)   2688        ['conv5_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block6_0_relu (Activatio  (None, 7, 7, 672)   0           ['conv5_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block6_1_conv (Conv2D)   (None, 7, 7, 128)    86016       ['conv5_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block6_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block6_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block6_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block6_concat (Concatena  (None, 7, 7, 704)   0           ['conv5_block5_concat[0][0]',    \n",
            " te)                                                              'conv5_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block7_0_bn (BatchNormal  (None, 7, 7, 704)   2816        ['conv5_block6_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block7_0_relu (Activatio  (None, 7, 7, 704)   0           ['conv5_block7_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block7_1_conv (Conv2D)   (None, 7, 7, 128)    90112       ['conv5_block7_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block7_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block7_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block7_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block7_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block7_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block7_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block7_concat (Concatena  (None, 7, 7, 736)   0           ['conv5_block6_concat[0][0]',    \n",
            " te)                                                              'conv5_block7_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block8_0_bn (BatchNormal  (None, 7, 7, 736)   2944        ['conv5_block7_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block8_0_relu (Activatio  (None, 7, 7, 736)   0           ['conv5_block8_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block8_1_conv (Conv2D)   (None, 7, 7, 128)    94208       ['conv5_block8_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block8_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block8_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block8_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block8_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block8_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block8_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block8_concat (Concatena  (None, 7, 7, 768)   0           ['conv5_block7_concat[0][0]',    \n",
            " te)                                                              'conv5_block8_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block9_0_bn (BatchNormal  (None, 7, 7, 768)   3072        ['conv5_block8_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block9_0_relu (Activatio  (None, 7, 7, 768)   0           ['conv5_block9_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block9_1_conv (Conv2D)   (None, 7, 7, 128)    98304       ['conv5_block9_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block9_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block9_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block9_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block9_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block9_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block9_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block9_concat (Concatena  (None, 7, 7, 800)   0           ['conv5_block8_concat[0][0]',    \n",
            " te)                                                              'conv5_block9_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block10_0_bn (BatchNorma  (None, 7, 7, 800)   3200        ['conv5_block9_concat[0][0]']    \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block10_0_relu (Activati  (None, 7, 7, 800)   0           ['conv5_block10_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block10_1_conv (Conv2D)  (None, 7, 7, 128)    102400      ['conv5_block10_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block10_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block10_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block10_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block10_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block10_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block10_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block10_concat (Concaten  (None, 7, 7, 832)   0           ['conv5_block9_concat[0][0]',    \n",
            " ate)                                                             'conv5_block10_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block11_0_bn (BatchNorma  (None, 7, 7, 832)   3328        ['conv5_block10_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block11_0_relu (Activati  (None, 7, 7, 832)   0           ['conv5_block11_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block11_1_conv (Conv2D)  (None, 7, 7, 128)    106496      ['conv5_block11_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block11_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block11_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block11_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block11_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block11_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block11_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block11_concat (Concaten  (None, 7, 7, 864)   0           ['conv5_block10_concat[0][0]',   \n",
            " ate)                                                             'conv5_block11_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block12_0_bn (BatchNorma  (None, 7, 7, 864)   3456        ['conv5_block11_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block12_0_relu (Activati  (None, 7, 7, 864)   0           ['conv5_block12_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block12_1_conv (Conv2D)  (None, 7, 7, 128)    110592      ['conv5_block12_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block12_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block12_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block12_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block12_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block12_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block12_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block12_concat (Concaten  (None, 7, 7, 896)   0           ['conv5_block11_concat[0][0]',   \n",
            " ate)                                                             'conv5_block12_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block13_0_bn (BatchNorma  (None, 7, 7, 896)   3584        ['conv5_block12_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block13_0_relu (Activati  (None, 7, 7, 896)   0           ['conv5_block13_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block13_1_conv (Conv2D)  (None, 7, 7, 128)    114688      ['conv5_block13_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block13_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block13_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block13_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block13_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block13_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block13_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block13_concat (Concaten  (None, 7, 7, 928)   0           ['conv5_block12_concat[0][0]',   \n",
            " ate)                                                             'conv5_block13_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block14_0_bn (BatchNorma  (None, 7, 7, 928)   3712        ['conv5_block13_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block14_0_relu (Activati  (None, 7, 7, 928)   0           ['conv5_block14_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block14_1_conv (Conv2D)  (None, 7, 7, 128)    118784      ['conv5_block14_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block14_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block14_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block14_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block14_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block14_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block14_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block14_concat (Concaten  (None, 7, 7, 960)   0           ['conv5_block13_concat[0][0]',   \n",
            " ate)                                                             'conv5_block14_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block15_0_bn (BatchNorma  (None, 7, 7, 960)   3840        ['conv5_block14_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block15_0_relu (Activati  (None, 7, 7, 960)   0           ['conv5_block15_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block15_1_conv (Conv2D)  (None, 7, 7, 128)    122880      ['conv5_block15_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block15_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block15_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block15_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block15_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block15_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block15_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block15_concat (Concaten  (None, 7, 7, 992)   0           ['conv5_block14_concat[0][0]',   \n",
            " ate)                                                             'conv5_block15_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block16_0_bn (BatchNorma  (None, 7, 7, 992)   3968        ['conv5_block15_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block16_0_relu (Activati  (None, 7, 7, 992)   0           ['conv5_block16_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block16_1_conv (Conv2D)  (None, 7, 7, 128)    126976      ['conv5_block16_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block16_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block16_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block16_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block16_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block16_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block16_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block16_concat (Concaten  (None, 7, 7, 1024)  0           ['conv5_block15_concat[0][0]',   \n",
            " ate)                                                             'conv5_block16_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " bn (BatchNormalization)        (None, 7, 7, 1024)   4096        ['conv5_block16_concat[0][0]']   \n",
            "                                                                                                  \n",
            " relu (Activation)              (None, 7, 7, 1024)   0           ['bn[0][0]']                     \n",
            "                                                                                                  \n",
            " avg_pool (GlobalAveragePooling  (None, 1024)        0           ['relu[0][0]']                   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 7,037,504\n",
            "Trainable params: 0\n",
            "Non-trainable params: 7,037,504\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bottleneck_features_train = model.predict_generator(train_generator_Dense, predict_size_train)\n",
        "np.save('/content/drive/MyDrive/My_projects _and _datasets/IDRID_detection/'+'bottleneck_features_train_'+model_name+'.npy', bottleneck_features_train)"
      ],
      "metadata": {
        "id": "NheMA6sQK4q8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bottleneck_features_validation = model.predict_generator(val_generator_Dense, predict_size_validation)\n",
        "np.save('/content/drive/MyDrive/My_projects _and _datasets/IDRID_detection/'+'bottleneck_features_validation_'+model_name+'.npy', bottleneck_features_validation)"
      ],
      "metadata": {
        "id": "UxvPoSkxLoHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bottleneck_features_test = model.predict_generator(test_generator_Dense, predict_size_test)\n",
        "np.save(\"/content/drive/MyDrive/My_projects _and _datasets/IDRID_detection/\"+'bottleneck_features_test_'+model_name+'.npy', bottleneck_features_test)"
      ],
      "metadata": {
        "id": "0vDnSc0xL0oY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=np.load('/content/drive/MyDrive/My_projects _and _datasets/IDRID_detection/bottleneck_features_train_DenseNet121.npy')\n",
        "validation_data=np.load('/content/drive/MyDrive/My_projects _and _datasets/IDRID_detection/bottleneck_features_validation_DenseNet121.npy')\n",
        "test_data = np.load('/content/drive/MyDrive/My_projects _and _datasets/IDRID_detection/bottleneck_features_test_DenseNet121.npy')"
      ],
      "metadata": {
        "id": "R7L8EG4_L8T3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.shape)\n",
        "print(validation_data.shape)\n",
        "print(test_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgQ23bRjQaef",
        "outputId": "f3f99f1d-70fe-4775-c2fd-b3da378aced8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2628, 1024)\n",
            "(656, 1024)\n",
            "(378, 1024)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels=train_generator_Dense.classes\n",
        "train_labels=train_labels = to_categorical(train_labels, num_classes=2)\n",
        "validation_labels=val_generator_Dense.classes\n",
        "validation_labels = to_categorical(validation_labels, num_classes=2)\n",
        "test_labels=test_generator_Dense.classes\n",
        "test_labels=to_categorical(test_labels,num_classes=2)"
      ],
      "metadata": {
        "id": "573j3YQ-QeYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_labels.shape)\n",
        "print(validation_labels.shape)\n",
        "print(test_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnJuyZdNTSN3",
        "outputId": "870217b9-47c7-4f0b-aa83-1038095c904e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2628, 2)\n",
            "(656, 2)\n",
            "(378, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(112,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2,activation='sigmoid'))\n",
        "adam_opt2=Adam(lr = 0.001, beta_1=0.6, beta_2=0.8, amsgrad=True)\n",
        "\n",
        "model.compile(optimizer=adam_opt2, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_data, train_labels,\n",
        "                    epochs=1000,\n",
        "                    batch_size=batch_size,\n",
        "                    validation_data=(validation_data, validation_labels),\n",
        "                    verbose= 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGbdfdo9TWYz",
        "outputId": "1db49d42-ba2a-4854-febc-2daea8547b48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "83/83 [==============================] - 3s 8ms/step - loss: 0.3989 - accuracy: 0.8451 - val_loss: 0.2057 - val_accuracy: 0.9360\n",
            "Epoch 2/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.2711 - accuracy: 0.9049 - val_loss: 0.1624 - val_accuracy: 0.9421\n",
            "Epoch 3/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.2381 - accuracy: 0.9216 - val_loss: 0.1835 - val_accuracy: 0.9527\n",
            "Epoch 4/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.2194 - accuracy: 0.9266 - val_loss: 0.1320 - val_accuracy: 0.9527\n",
            "Epoch 5/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.1976 - accuracy: 0.9330 - val_loss: 0.1299 - val_accuracy: 0.9649\n",
            "Epoch 6/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.1922 - accuracy: 0.9330 - val_loss: 0.1227 - val_accuracy: 0.9604\n",
            "Epoch 7/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.1908 - accuracy: 0.9414 - val_loss: 0.1220 - val_accuracy: 0.9665\n",
            "Epoch 8/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.1770 - accuracy: 0.9403 - val_loss: 0.1096 - val_accuracy: 0.9665\n",
            "Epoch 9/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.1712 - accuracy: 0.9486 - val_loss: 0.1065 - val_accuracy: 0.9695\n",
            "Epoch 10/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.1621 - accuracy: 0.9479 - val_loss: 0.1357 - val_accuracy: 0.9634\n",
            "Epoch 11/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.1698 - accuracy: 0.9429 - val_loss: 0.1004 - val_accuracy: 0.9726\n",
            "Epoch 12/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.1558 - accuracy: 0.9513 - val_loss: 0.1259 - val_accuracy: 0.9634\n",
            "Epoch 13/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.1554 - accuracy: 0.9513 - val_loss: 0.0995 - val_accuracy: 0.9726\n",
            "Epoch 14/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.1492 - accuracy: 0.9536 - val_loss: 0.1124 - val_accuracy: 0.9665\n",
            "Epoch 15/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.1483 - accuracy: 0.9505 - val_loss: 0.0935 - val_accuracy: 0.9710\n",
            "Epoch 16/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.1444 - accuracy: 0.9505 - val_loss: 0.0968 - val_accuracy: 0.9771\n",
            "Epoch 17/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.1383 - accuracy: 0.9536 - val_loss: 0.0984 - val_accuracy: 0.9741\n",
            "Epoch 18/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.1347 - accuracy: 0.9524 - val_loss: 0.0938 - val_accuracy: 0.9771\n",
            "Epoch 19/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.1380 - accuracy: 0.9570 - val_loss: 0.0910 - val_accuracy: 0.9771\n",
            "Epoch 20/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.1310 - accuracy: 0.9559 - val_loss: 0.0945 - val_accuracy: 0.9741\n",
            "Epoch 21/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.1313 - accuracy: 0.9559 - val_loss: 0.1135 - val_accuracy: 0.9695\n",
            "Epoch 22/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.1316 - accuracy: 0.9570 - val_loss: 0.0917 - val_accuracy: 0.9741\n",
            "Epoch 23/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.1250 - accuracy: 0.9581 - val_loss: 0.0885 - val_accuracy: 0.9787\n",
            "Epoch 24/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.1269 - accuracy: 0.9566 - val_loss: 0.0864 - val_accuracy: 0.9741\n",
            "Epoch 25/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.1215 - accuracy: 0.9589 - val_loss: 0.0986 - val_accuracy: 0.9726\n",
            "Epoch 26/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.1254 - accuracy: 0.9555 - val_loss: 0.0984 - val_accuracy: 0.9695\n",
            "Epoch 27/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.1207 - accuracy: 0.9616 - val_loss: 0.0879 - val_accuracy: 0.9787\n",
            "Epoch 28/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.1156 - accuracy: 0.9642 - val_loss: 0.0894 - val_accuracy: 0.9756\n",
            "Epoch 29/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.1145 - accuracy: 0.9642 - val_loss: 0.0919 - val_accuracy: 0.9726\n",
            "Epoch 30/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.1087 - accuracy: 0.9646 - val_loss: 0.0893 - val_accuracy: 0.9741\n",
            "Epoch 31/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.1064 - accuracy: 0.9665 - val_loss: 0.0850 - val_accuracy: 0.9756\n",
            "Epoch 32/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.1143 - accuracy: 0.9642 - val_loss: 0.1198 - val_accuracy: 0.9680\n",
            "Epoch 33/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.1081 - accuracy: 0.9665 - val_loss: 0.1041 - val_accuracy: 0.9756\n",
            "Epoch 34/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.1078 - accuracy: 0.9650 - val_loss: 0.0831 - val_accuracy: 0.9802\n",
            "Epoch 35/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.1035 - accuracy: 0.9665 - val_loss: 0.0936 - val_accuracy: 0.9726\n",
            "Epoch 36/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.1039 - accuracy: 0.9680 - val_loss: 0.0899 - val_accuracy: 0.9756\n",
            "Epoch 37/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.1008 - accuracy: 0.9684 - val_loss: 0.0851 - val_accuracy: 0.9771\n",
            "Epoch 38/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.1043 - accuracy: 0.9677 - val_loss: 0.0897 - val_accuracy: 0.9726\n",
            "Epoch 39/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0997 - accuracy: 0.9673 - val_loss: 0.0808 - val_accuracy: 0.9741\n",
            "Epoch 40/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0955 - accuracy: 0.9680 - val_loss: 0.0822 - val_accuracy: 0.9787\n",
            "Epoch 41/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0982 - accuracy: 0.9703 - val_loss: 0.0808 - val_accuracy: 0.9787\n",
            "Epoch 42/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0935 - accuracy: 0.9696 - val_loss: 0.0837 - val_accuracy: 0.9741\n",
            "Epoch 43/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0969 - accuracy: 0.9711 - val_loss: 0.0848 - val_accuracy: 0.9726\n",
            "Epoch 44/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0974 - accuracy: 0.9658 - val_loss: 0.0859 - val_accuracy: 0.9741\n",
            "Epoch 45/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.1001 - accuracy: 0.9684 - val_loss: 0.0817 - val_accuracy: 0.9741\n",
            "Epoch 46/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0952 - accuracy: 0.9684 - val_loss: 0.0858 - val_accuracy: 0.9726\n",
            "Epoch 47/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0869 - accuracy: 0.9711 - val_loss: 0.0989 - val_accuracy: 0.9710\n",
            "Epoch 48/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0908 - accuracy: 0.9703 - val_loss: 0.0835 - val_accuracy: 0.9741\n",
            "Epoch 49/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0872 - accuracy: 0.9722 - val_loss: 0.0780 - val_accuracy: 0.9741\n",
            "Epoch 50/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0924 - accuracy: 0.9718 - val_loss: 0.0844 - val_accuracy: 0.9756\n",
            "Epoch 51/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0867 - accuracy: 0.9707 - val_loss: 0.0954 - val_accuracy: 0.9726\n",
            "Epoch 52/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0864 - accuracy: 0.9722 - val_loss: 0.0823 - val_accuracy: 0.9741\n",
            "Epoch 53/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0881 - accuracy: 0.9722 - val_loss: 0.0826 - val_accuracy: 0.9741\n",
            "Epoch 54/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0831 - accuracy: 0.9753 - val_loss: 0.0872 - val_accuracy: 0.9741\n",
            "Epoch 55/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0896 - accuracy: 0.9699 - val_loss: 0.0804 - val_accuracy: 0.9741\n",
            "Epoch 56/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0830 - accuracy: 0.9722 - val_loss: 0.0854 - val_accuracy: 0.9726\n",
            "Epoch 57/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0825 - accuracy: 0.9745 - val_loss: 0.0837 - val_accuracy: 0.9741\n",
            "Epoch 58/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0798 - accuracy: 0.9734 - val_loss: 0.0912 - val_accuracy: 0.9726\n",
            "Epoch 59/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0835 - accuracy: 0.9692 - val_loss: 0.0808 - val_accuracy: 0.9787\n",
            "Epoch 60/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0779 - accuracy: 0.9726 - val_loss: 0.0833 - val_accuracy: 0.9741\n",
            "Epoch 61/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0740 - accuracy: 0.9772 - val_loss: 0.0920 - val_accuracy: 0.9741\n",
            "Epoch 62/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0813 - accuracy: 0.9737 - val_loss: 0.0941 - val_accuracy: 0.9741\n",
            "Epoch 63/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0760 - accuracy: 0.9760 - val_loss: 0.0802 - val_accuracy: 0.9741\n",
            "Epoch 64/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0803 - accuracy: 0.9745 - val_loss: 0.0962 - val_accuracy: 0.9710\n",
            "Epoch 65/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0733 - accuracy: 0.9760 - val_loss: 0.0799 - val_accuracy: 0.9756\n",
            "Epoch 66/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0737 - accuracy: 0.9737 - val_loss: 0.0852 - val_accuracy: 0.9741\n",
            "Epoch 67/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0758 - accuracy: 0.9775 - val_loss: 0.0775 - val_accuracy: 0.9771\n",
            "Epoch 68/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0697 - accuracy: 0.9756 - val_loss: 0.0797 - val_accuracy: 0.9756\n",
            "Epoch 69/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0750 - accuracy: 0.9756 - val_loss: 0.0889 - val_accuracy: 0.9756\n",
            "Epoch 70/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0695 - accuracy: 0.9756 - val_loss: 0.0789 - val_accuracy: 0.9756\n",
            "Epoch 71/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0729 - accuracy: 0.9779 - val_loss: 0.0785 - val_accuracy: 0.9741\n",
            "Epoch 72/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0708 - accuracy: 0.9772 - val_loss: 0.0805 - val_accuracy: 0.9741\n",
            "Epoch 73/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0723 - accuracy: 0.9772 - val_loss: 0.0797 - val_accuracy: 0.9741\n",
            "Epoch 74/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0703 - accuracy: 0.9768 - val_loss: 0.0805 - val_accuracy: 0.9726\n",
            "Epoch 75/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0657 - accuracy: 0.9817 - val_loss: 0.0886 - val_accuracy: 0.9756\n",
            "Epoch 76/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0671 - accuracy: 0.9768 - val_loss: 0.0798 - val_accuracy: 0.9726\n",
            "Epoch 77/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0673 - accuracy: 0.9772 - val_loss: 0.0837 - val_accuracy: 0.9741\n",
            "Epoch 78/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0636 - accuracy: 0.9806 - val_loss: 0.0824 - val_accuracy: 0.9726\n",
            "Epoch 79/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0671 - accuracy: 0.9802 - val_loss: 0.0759 - val_accuracy: 0.9756\n",
            "Epoch 80/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0647 - accuracy: 0.9810 - val_loss: 0.0760 - val_accuracy: 0.9756\n",
            "Epoch 81/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0659 - accuracy: 0.9795 - val_loss: 0.0789 - val_accuracy: 0.9741\n",
            "Epoch 82/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0620 - accuracy: 0.9821 - val_loss: 0.0944 - val_accuracy: 0.9710\n",
            "Epoch 83/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0649 - accuracy: 0.9787 - val_loss: 0.0769 - val_accuracy: 0.9771\n",
            "Epoch 84/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0604 - accuracy: 0.9806 - val_loss: 0.0775 - val_accuracy: 0.9756\n",
            "Epoch 85/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0614 - accuracy: 0.9810 - val_loss: 0.0765 - val_accuracy: 0.9756\n",
            "Epoch 86/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0615 - accuracy: 0.9814 - val_loss: 0.0792 - val_accuracy: 0.9756\n",
            "Epoch 87/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0628 - accuracy: 0.9817 - val_loss: 0.0770 - val_accuracy: 0.9756\n",
            "Epoch 88/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0571 - accuracy: 0.9825 - val_loss: 0.0985 - val_accuracy: 0.9695\n",
            "Epoch 89/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0609 - accuracy: 0.9787 - val_loss: 0.0975 - val_accuracy: 0.9665\n",
            "Epoch 90/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0601 - accuracy: 0.9825 - val_loss: 0.0836 - val_accuracy: 0.9726\n",
            "Epoch 91/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0563 - accuracy: 0.9833 - val_loss: 0.0840 - val_accuracy: 0.9741\n",
            "Epoch 92/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0567 - accuracy: 0.9825 - val_loss: 0.0824 - val_accuracy: 0.9741\n",
            "Epoch 93/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0588 - accuracy: 0.9802 - val_loss: 0.0907 - val_accuracy: 0.9741\n",
            "Epoch 94/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0592 - accuracy: 0.9829 - val_loss: 0.0823 - val_accuracy: 0.9741\n",
            "Epoch 95/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0551 - accuracy: 0.9791 - val_loss: 0.0772 - val_accuracy: 0.9741\n",
            "Epoch 96/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0573 - accuracy: 0.9829 - val_loss: 0.0830 - val_accuracy: 0.9726\n",
            "Epoch 97/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0533 - accuracy: 0.9840 - val_loss: 0.0827 - val_accuracy: 0.9756\n",
            "Epoch 98/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0576 - accuracy: 0.9802 - val_loss: 0.0836 - val_accuracy: 0.9741\n",
            "Epoch 99/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0555 - accuracy: 0.9806 - val_loss: 0.0835 - val_accuracy: 0.9726\n",
            "Epoch 100/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0514 - accuracy: 0.9863 - val_loss: 0.0811 - val_accuracy: 0.9741\n",
            "Epoch 101/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0524 - accuracy: 0.9833 - val_loss: 0.0840 - val_accuracy: 0.9726\n",
            "Epoch 102/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0541 - accuracy: 0.9817 - val_loss: 0.0937 - val_accuracy: 0.9695\n",
            "Epoch 103/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0490 - accuracy: 0.9852 - val_loss: 0.0864 - val_accuracy: 0.9710\n",
            "Epoch 104/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0483 - accuracy: 0.9867 - val_loss: 0.0885 - val_accuracy: 0.9726\n",
            "Epoch 105/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0520 - accuracy: 0.9821 - val_loss: 0.0784 - val_accuracy: 0.9741\n",
            "Epoch 106/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0515 - accuracy: 0.9829 - val_loss: 0.0887 - val_accuracy: 0.9726\n",
            "Epoch 107/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0535 - accuracy: 0.9836 - val_loss: 0.1017 - val_accuracy: 0.9649\n",
            "Epoch 108/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0509 - accuracy: 0.9844 - val_loss: 0.0904 - val_accuracy: 0.9726\n",
            "Epoch 109/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0477 - accuracy: 0.9833 - val_loss: 0.0977 - val_accuracy: 0.9695\n",
            "Epoch 110/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0487 - accuracy: 0.9840 - val_loss: 0.0791 - val_accuracy: 0.9741\n",
            "Epoch 111/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0465 - accuracy: 0.9855 - val_loss: 0.0774 - val_accuracy: 0.9726\n",
            "Epoch 112/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0487 - accuracy: 0.9825 - val_loss: 0.0816 - val_accuracy: 0.9756\n",
            "Epoch 113/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0473 - accuracy: 0.9863 - val_loss: 0.0866 - val_accuracy: 0.9756\n",
            "Epoch 114/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0476 - accuracy: 0.9844 - val_loss: 0.0953 - val_accuracy: 0.9726\n",
            "Epoch 115/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0452 - accuracy: 0.9874 - val_loss: 0.0828 - val_accuracy: 0.9756\n",
            "Epoch 116/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0435 - accuracy: 0.9882 - val_loss: 0.0784 - val_accuracy: 0.9741\n",
            "Epoch 117/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0446 - accuracy: 0.9871 - val_loss: 0.0827 - val_accuracy: 0.9741\n",
            "Epoch 118/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0436 - accuracy: 0.9886 - val_loss: 0.0796 - val_accuracy: 0.9741\n",
            "Epoch 119/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0462 - accuracy: 0.9852 - val_loss: 0.0810 - val_accuracy: 0.9741\n",
            "Epoch 120/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0470 - accuracy: 0.9859 - val_loss: 0.0845 - val_accuracy: 0.9741\n",
            "Epoch 121/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0446 - accuracy: 0.9863 - val_loss: 0.0834 - val_accuracy: 0.9741\n",
            "Epoch 122/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0420 - accuracy: 0.9886 - val_loss: 0.0843 - val_accuracy: 0.9710\n",
            "Epoch 123/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0426 - accuracy: 0.9871 - val_loss: 0.0804 - val_accuracy: 0.9741\n",
            "Epoch 124/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0440 - accuracy: 0.9855 - val_loss: 0.1091 - val_accuracy: 0.9634\n",
            "Epoch 125/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0459 - accuracy: 0.9871 - val_loss: 0.0828 - val_accuracy: 0.9726\n",
            "Epoch 126/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0442 - accuracy: 0.9848 - val_loss: 0.0827 - val_accuracy: 0.9726\n",
            "Epoch 127/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0402 - accuracy: 0.9878 - val_loss: 0.0891 - val_accuracy: 0.9741\n",
            "Epoch 128/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0423 - accuracy: 0.9863 - val_loss: 0.0794 - val_accuracy: 0.9741\n",
            "Epoch 129/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0412 - accuracy: 0.9882 - val_loss: 0.0796 - val_accuracy: 0.9741\n",
            "Epoch 130/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0417 - accuracy: 0.9874 - val_loss: 0.0840 - val_accuracy: 0.9741\n",
            "Epoch 131/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0417 - accuracy: 0.9867 - val_loss: 0.0880 - val_accuracy: 0.9756\n",
            "Epoch 132/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0386 - accuracy: 0.9890 - val_loss: 0.0837 - val_accuracy: 0.9741\n",
            "Epoch 133/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0382 - accuracy: 0.9893 - val_loss: 0.0835 - val_accuracy: 0.9741\n",
            "Epoch 134/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0377 - accuracy: 0.9897 - val_loss: 0.0897 - val_accuracy: 0.9726\n",
            "Epoch 135/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0402 - accuracy: 0.9890 - val_loss: 0.0852 - val_accuracy: 0.9726\n",
            "Epoch 136/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0376 - accuracy: 0.9886 - val_loss: 0.0806 - val_accuracy: 0.9756\n",
            "Epoch 137/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0391 - accuracy: 0.9890 - val_loss: 0.0806 - val_accuracy: 0.9741\n",
            "Epoch 138/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0402 - accuracy: 0.9871 - val_loss: 0.0819 - val_accuracy: 0.9756\n",
            "Epoch 139/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0370 - accuracy: 0.9897 - val_loss: 0.0862 - val_accuracy: 0.9710\n",
            "Epoch 140/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0372 - accuracy: 0.9882 - val_loss: 0.0839 - val_accuracy: 0.9756\n",
            "Epoch 141/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0407 - accuracy: 0.9871 - val_loss: 0.0798 - val_accuracy: 0.9741\n",
            "Epoch 142/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0386 - accuracy: 0.9874 - val_loss: 0.0854 - val_accuracy: 0.9741\n",
            "Epoch 143/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0380 - accuracy: 0.9878 - val_loss: 0.0867 - val_accuracy: 0.9741\n",
            "Epoch 144/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0397 - accuracy: 0.9882 - val_loss: 0.0808 - val_accuracy: 0.9741\n",
            "Epoch 145/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0323 - accuracy: 0.9916 - val_loss: 0.0796 - val_accuracy: 0.9726\n",
            "Epoch 146/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0337 - accuracy: 0.9924 - val_loss: 0.0847 - val_accuracy: 0.9756\n",
            "Epoch 147/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0371 - accuracy: 0.9901 - val_loss: 0.0772 - val_accuracy: 0.9741\n",
            "Epoch 148/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0368 - accuracy: 0.9905 - val_loss: 0.0877 - val_accuracy: 0.9756\n",
            "Epoch 149/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0352 - accuracy: 0.9901 - val_loss: 0.0891 - val_accuracy: 0.9726\n",
            "Epoch 150/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0339 - accuracy: 0.9912 - val_loss: 0.0847 - val_accuracy: 0.9756\n",
            "Epoch 151/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0360 - accuracy: 0.9909 - val_loss: 0.0808 - val_accuracy: 0.9726\n",
            "Epoch 152/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0343 - accuracy: 0.9912 - val_loss: 0.0802 - val_accuracy: 0.9756\n",
            "Epoch 153/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0339 - accuracy: 0.9924 - val_loss: 0.0815 - val_accuracy: 0.9726\n",
            "Epoch 154/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0327 - accuracy: 0.9916 - val_loss: 0.0819 - val_accuracy: 0.9726\n",
            "Epoch 155/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0338 - accuracy: 0.9897 - val_loss: 0.0870 - val_accuracy: 0.9710\n",
            "Epoch 156/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0321 - accuracy: 0.9920 - val_loss: 0.0821 - val_accuracy: 0.9741\n",
            "Epoch 157/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0333 - accuracy: 0.9920 - val_loss: 0.0815 - val_accuracy: 0.9726\n",
            "Epoch 158/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0337 - accuracy: 0.9886 - val_loss: 0.0890 - val_accuracy: 0.9710\n",
            "Epoch 159/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0334 - accuracy: 0.9928 - val_loss: 0.0855 - val_accuracy: 0.9710\n",
            "Epoch 160/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0296 - accuracy: 0.9935 - val_loss: 0.0962 - val_accuracy: 0.9726\n",
            "Epoch 161/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0315 - accuracy: 0.9893 - val_loss: 0.0894 - val_accuracy: 0.9726\n",
            "Epoch 162/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0317 - accuracy: 0.9928 - val_loss: 0.0849 - val_accuracy: 0.9741\n",
            "Epoch 163/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0305 - accuracy: 0.9924 - val_loss: 0.0813 - val_accuracy: 0.9741\n",
            "Epoch 164/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0292 - accuracy: 0.9916 - val_loss: 0.0827 - val_accuracy: 0.9756\n",
            "Epoch 165/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0333 - accuracy: 0.9909 - val_loss: 0.0823 - val_accuracy: 0.9756\n",
            "Epoch 166/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0281 - accuracy: 0.9932 - val_loss: 0.0896 - val_accuracy: 0.9741\n",
            "Epoch 167/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0305 - accuracy: 0.9916 - val_loss: 0.0859 - val_accuracy: 0.9756\n",
            "Epoch 168/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0291 - accuracy: 0.9939 - val_loss: 0.0817 - val_accuracy: 0.9726\n",
            "Epoch 169/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0291 - accuracy: 0.9928 - val_loss: 0.0834 - val_accuracy: 0.9726\n",
            "Epoch 170/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0310 - accuracy: 0.9909 - val_loss: 0.0933 - val_accuracy: 0.9726\n",
            "Epoch 171/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0294 - accuracy: 0.9909 - val_loss: 0.0790 - val_accuracy: 0.9741\n",
            "Epoch 172/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0291 - accuracy: 0.9924 - val_loss: 0.0924 - val_accuracy: 0.9726\n",
            "Epoch 173/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0319 - accuracy: 0.9920 - val_loss: 0.0881 - val_accuracy: 0.9741\n",
            "Epoch 174/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0255 - accuracy: 0.9943 - val_loss: 0.0815 - val_accuracy: 0.9726\n",
            "Epoch 175/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0282 - accuracy: 0.9932 - val_loss: 0.0832 - val_accuracy: 0.9726\n",
            "Epoch 176/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0278 - accuracy: 0.9920 - val_loss: 0.0843 - val_accuracy: 0.9741\n",
            "Epoch 177/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0271 - accuracy: 0.9935 - val_loss: 0.0897 - val_accuracy: 0.9710\n",
            "Epoch 178/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0293 - accuracy: 0.9920 - val_loss: 0.0880 - val_accuracy: 0.9741\n",
            "Epoch 179/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0274 - accuracy: 0.9939 - val_loss: 0.0858 - val_accuracy: 0.9726\n",
            "Epoch 180/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0254 - accuracy: 0.9932 - val_loss: 0.0902 - val_accuracy: 0.9741\n",
            "Epoch 181/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0264 - accuracy: 0.9935 - val_loss: 0.0879 - val_accuracy: 0.9710\n",
            "Epoch 182/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0277 - accuracy: 0.9924 - val_loss: 0.0854 - val_accuracy: 0.9726\n",
            "Epoch 183/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0261 - accuracy: 0.9943 - val_loss: 0.0861 - val_accuracy: 0.9726\n",
            "Epoch 184/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0274 - accuracy: 0.9928 - val_loss: 0.0818 - val_accuracy: 0.9771\n",
            "Epoch 185/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0342 - accuracy: 0.9893 - val_loss: 0.0947 - val_accuracy: 0.9726\n",
            "Epoch 186/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0289 - accuracy: 0.9920 - val_loss: 0.0880 - val_accuracy: 0.9741\n",
            "Epoch 187/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0273 - accuracy: 0.9924 - val_loss: 0.0842 - val_accuracy: 0.9726\n",
            "Epoch 188/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0233 - accuracy: 0.9951 - val_loss: 0.0823 - val_accuracy: 0.9726\n",
            "Epoch 189/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0235 - accuracy: 0.9951 - val_loss: 0.0926 - val_accuracy: 0.9726\n",
            "Epoch 190/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0250 - accuracy: 0.9943 - val_loss: 0.0922 - val_accuracy: 0.9710\n",
            "Epoch 191/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0256 - accuracy: 0.9951 - val_loss: 0.0844 - val_accuracy: 0.9726\n",
            "Epoch 192/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0265 - accuracy: 0.9951 - val_loss: 0.0917 - val_accuracy: 0.9710\n",
            "Epoch 193/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0246 - accuracy: 0.9954 - val_loss: 0.0938 - val_accuracy: 0.9695\n",
            "Epoch 194/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0260 - accuracy: 0.9939 - val_loss: 0.0885 - val_accuracy: 0.9726\n",
            "Epoch 195/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0220 - accuracy: 0.9958 - val_loss: 0.0872 - val_accuracy: 0.9726\n",
            "Epoch 196/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0239 - accuracy: 0.9954 - val_loss: 0.0877 - val_accuracy: 0.9726\n",
            "Epoch 197/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0241 - accuracy: 0.9951 - val_loss: 0.0842 - val_accuracy: 0.9726\n",
            "Epoch 198/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0229 - accuracy: 0.9947 - val_loss: 0.0890 - val_accuracy: 0.9726\n",
            "Epoch 199/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0239 - accuracy: 0.9947 - val_loss: 0.0870 - val_accuracy: 0.9726\n",
            "Epoch 200/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0279 - accuracy: 0.9939 - val_loss: 0.1064 - val_accuracy: 0.9680\n",
            "Epoch 201/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0292 - accuracy: 0.9935 - val_loss: 0.1015 - val_accuracy: 0.9695\n",
            "Epoch 202/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0245 - accuracy: 0.9954 - val_loss: 0.0881 - val_accuracy: 0.9710\n",
            "Epoch 203/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0223 - accuracy: 0.9954 - val_loss: 0.0901 - val_accuracy: 0.9726\n",
            "Epoch 204/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0224 - accuracy: 0.9951 - val_loss: 0.0917 - val_accuracy: 0.9756\n",
            "Epoch 205/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0233 - accuracy: 0.9943 - val_loss: 0.0858 - val_accuracy: 0.9741\n",
            "Epoch 206/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0223 - accuracy: 0.9947 - val_loss: 0.0881 - val_accuracy: 0.9726\n",
            "Epoch 207/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0251 - accuracy: 0.9939 - val_loss: 0.0912 - val_accuracy: 0.9726\n",
            "Epoch 208/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0233 - accuracy: 0.9947 - val_loss: 0.0920 - val_accuracy: 0.9695\n",
            "Epoch 209/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0221 - accuracy: 0.9973 - val_loss: 0.0893 - val_accuracy: 0.9710\n",
            "Epoch 210/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0232 - accuracy: 0.9932 - val_loss: 0.0902 - val_accuracy: 0.9741\n",
            "Epoch 211/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0208 - accuracy: 0.9954 - val_loss: 0.0952 - val_accuracy: 0.9710\n",
            "Epoch 212/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0223 - accuracy: 0.9954 - val_loss: 0.0875 - val_accuracy: 0.9726\n",
            "Epoch 213/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0232 - accuracy: 0.9947 - val_loss: 0.0869 - val_accuracy: 0.9741\n",
            "Epoch 214/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0197 - accuracy: 0.9970 - val_loss: 0.0907 - val_accuracy: 0.9741\n",
            "Epoch 215/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0200 - accuracy: 0.9973 - val_loss: 0.0887 - val_accuracy: 0.9726\n",
            "Epoch 216/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0201 - accuracy: 0.9954 - val_loss: 0.0931 - val_accuracy: 0.9726\n",
            "Epoch 217/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0224 - accuracy: 0.9951 - val_loss: 0.0956 - val_accuracy: 0.9710\n",
            "Epoch 218/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0225 - accuracy: 0.9951 - val_loss: 0.0897 - val_accuracy: 0.9710\n",
            "Epoch 219/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0248 - accuracy: 0.9939 - val_loss: 0.0910 - val_accuracy: 0.9710\n",
            "Epoch 220/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0232 - accuracy: 0.9939 - val_loss: 0.0869 - val_accuracy: 0.9726\n",
            "Epoch 221/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0210 - accuracy: 0.9958 - val_loss: 0.0952 - val_accuracy: 0.9726\n",
            "Epoch 222/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0204 - accuracy: 0.9951 - val_loss: 0.0912 - val_accuracy: 0.9710\n",
            "Epoch 223/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0196 - accuracy: 0.9962 - val_loss: 0.0895 - val_accuracy: 0.9710\n",
            "Epoch 224/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0198 - accuracy: 0.9958 - val_loss: 0.0970 - val_accuracy: 0.9710\n",
            "Epoch 225/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0197 - accuracy: 0.9970 - val_loss: 0.0916 - val_accuracy: 0.9695\n",
            "Epoch 226/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0204 - accuracy: 0.9951 - val_loss: 0.0937 - val_accuracy: 0.9756\n",
            "Epoch 227/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0192 - accuracy: 0.9958 - val_loss: 0.0876 - val_accuracy: 0.9726\n",
            "Epoch 228/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0200 - accuracy: 0.9962 - val_loss: 0.0914 - val_accuracy: 0.9710\n",
            "Epoch 229/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0184 - accuracy: 0.9958 - val_loss: 0.0887 - val_accuracy: 0.9726\n",
            "Epoch 230/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0204 - accuracy: 0.9966 - val_loss: 0.0927 - val_accuracy: 0.9726\n",
            "Epoch 231/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0212 - accuracy: 0.9954 - val_loss: 0.0865 - val_accuracy: 0.9726\n",
            "Epoch 232/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0209 - accuracy: 0.9951 - val_loss: 0.0893 - val_accuracy: 0.9726\n",
            "Epoch 233/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0206 - accuracy: 0.9951 - val_loss: 0.0892 - val_accuracy: 0.9710\n",
            "Epoch 234/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0196 - accuracy: 0.9958 - val_loss: 0.0904 - val_accuracy: 0.9710\n",
            "Epoch 235/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0182 - accuracy: 0.9981 - val_loss: 0.0928 - val_accuracy: 0.9726\n",
            "Epoch 236/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0168 - accuracy: 0.9981 - val_loss: 0.0888 - val_accuracy: 0.9695\n",
            "Epoch 237/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0196 - accuracy: 0.9951 - val_loss: 0.0885 - val_accuracy: 0.9710\n",
            "Epoch 238/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0182 - accuracy: 0.9951 - val_loss: 0.0932 - val_accuracy: 0.9726\n",
            "Epoch 239/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0181 - accuracy: 0.9973 - val_loss: 0.0909 - val_accuracy: 0.9710\n",
            "Epoch 240/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0177 - accuracy: 0.9962 - val_loss: 0.0932 - val_accuracy: 0.9710\n",
            "Epoch 241/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0197 - accuracy: 0.9951 - val_loss: 0.0861 - val_accuracy: 0.9726\n",
            "Epoch 242/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0226 - accuracy: 0.9958 - val_loss: 0.0946 - val_accuracy: 0.9695\n",
            "Epoch 243/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0187 - accuracy: 0.9970 - val_loss: 0.0890 - val_accuracy: 0.9710\n",
            "Epoch 244/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0166 - accuracy: 0.9970 - val_loss: 0.0914 - val_accuracy: 0.9726\n",
            "Epoch 245/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0192 - accuracy: 0.9966 - val_loss: 0.0840 - val_accuracy: 0.9771\n",
            "Epoch 246/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0181 - accuracy: 0.9973 - val_loss: 0.0964 - val_accuracy: 0.9710\n",
            "Epoch 247/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0166 - accuracy: 0.9973 - val_loss: 0.0895 - val_accuracy: 0.9695\n",
            "Epoch 248/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0178 - accuracy: 0.9970 - val_loss: 0.0955 - val_accuracy: 0.9710\n",
            "Epoch 249/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0181 - accuracy: 0.9973 - val_loss: 0.0952 - val_accuracy: 0.9710\n",
            "Epoch 250/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0201 - accuracy: 0.9958 - val_loss: 0.0881 - val_accuracy: 0.9726\n",
            "Epoch 251/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0185 - accuracy: 0.9977 - val_loss: 0.0973 - val_accuracy: 0.9710\n",
            "Epoch 252/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0175 - accuracy: 0.9962 - val_loss: 0.0898 - val_accuracy: 0.9710\n",
            "Epoch 253/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0189 - accuracy: 0.9970 - val_loss: 0.0905 - val_accuracy: 0.9710\n",
            "Epoch 254/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0151 - accuracy: 0.9977 - val_loss: 0.0898 - val_accuracy: 0.9710\n",
            "Epoch 255/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0156 - accuracy: 0.9977 - val_loss: 0.0979 - val_accuracy: 0.9710\n",
            "Epoch 256/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0171 - accuracy: 0.9973 - val_loss: 0.0887 - val_accuracy: 0.9726\n",
            "Epoch 257/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0167 - accuracy: 0.9958 - val_loss: 0.0873 - val_accuracy: 0.9726\n",
            "Epoch 258/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0157 - accuracy: 0.9977 - val_loss: 0.0964 - val_accuracy: 0.9710\n",
            "Epoch 259/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0178 - accuracy: 0.9973 - val_loss: 0.0880 - val_accuracy: 0.9726\n",
            "Epoch 260/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0176 - accuracy: 0.9973 - val_loss: 0.0932 - val_accuracy: 0.9710\n",
            "Epoch 261/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0156 - accuracy: 0.9962 - val_loss: 0.0942 - val_accuracy: 0.9726\n",
            "Epoch 262/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0167 - accuracy: 0.9962 - val_loss: 0.0932 - val_accuracy: 0.9695\n",
            "Epoch 263/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0172 - accuracy: 0.9958 - val_loss: 0.0932 - val_accuracy: 0.9710\n",
            "Epoch 264/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0170 - accuracy: 0.9966 - val_loss: 0.0927 - val_accuracy: 0.9710\n",
            "Epoch 265/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0172 - accuracy: 0.9966 - val_loss: 0.0903 - val_accuracy: 0.9710\n",
            "Epoch 266/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0185 - accuracy: 0.9951 - val_loss: 0.0924 - val_accuracy: 0.9710\n",
            "Epoch 267/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0159 - accuracy: 0.9985 - val_loss: 0.0959 - val_accuracy: 0.9710\n",
            "Epoch 268/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0164 - accuracy: 0.9973 - val_loss: 0.0927 - val_accuracy: 0.9726\n",
            "Epoch 269/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0159 - accuracy: 0.9977 - val_loss: 0.0920 - val_accuracy: 0.9710\n",
            "Epoch 270/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0176 - accuracy: 0.9973 - val_loss: 0.0899 - val_accuracy: 0.9726\n",
            "Epoch 271/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0145 - accuracy: 0.9973 - val_loss: 0.1013 - val_accuracy: 0.9710\n",
            "Epoch 272/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0145 - accuracy: 0.9973 - val_loss: 0.0938 - val_accuracy: 0.9710\n",
            "Epoch 273/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0174 - accuracy: 0.9954 - val_loss: 0.0890 - val_accuracy: 0.9710\n",
            "Epoch 274/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0166 - accuracy: 0.9962 - val_loss: 0.0976 - val_accuracy: 0.9695\n",
            "Epoch 275/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0175 - accuracy: 0.9977 - val_loss: 0.0936 - val_accuracy: 0.9710\n",
            "Epoch 276/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0158 - accuracy: 0.9981 - val_loss: 0.0956 - val_accuracy: 0.9710\n",
            "Epoch 277/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0155 - accuracy: 0.9970 - val_loss: 0.0953 - val_accuracy: 0.9710\n",
            "Epoch 278/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0159 - accuracy: 0.9970 - val_loss: 0.0903 - val_accuracy: 0.9741\n",
            "Epoch 279/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0155 - accuracy: 0.9973 - val_loss: 0.0963 - val_accuracy: 0.9695\n",
            "Epoch 280/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0175 - accuracy: 0.9966 - val_loss: 0.0932 - val_accuracy: 0.9710\n",
            "Epoch 281/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0159 - accuracy: 0.9973 - val_loss: 0.0972 - val_accuracy: 0.9726\n",
            "Epoch 282/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0153 - accuracy: 0.9966 - val_loss: 0.0899 - val_accuracy: 0.9726\n",
            "Epoch 283/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0136 - accuracy: 0.9981 - val_loss: 0.0915 - val_accuracy: 0.9741\n",
            "Epoch 284/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0155 - accuracy: 0.9977 - val_loss: 0.0933 - val_accuracy: 0.9710\n",
            "Epoch 285/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0160 - accuracy: 0.9970 - val_loss: 0.0965 - val_accuracy: 0.9710\n",
            "Epoch 286/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0147 - accuracy: 0.9970 - val_loss: 0.0939 - val_accuracy: 0.9710\n",
            "Epoch 287/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0139 - accuracy: 0.9970 - val_loss: 0.0921 - val_accuracy: 0.9726\n",
            "Epoch 288/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0165 - accuracy: 0.9962 - val_loss: 0.0927 - val_accuracy: 0.9726\n",
            "Epoch 289/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0163 - accuracy: 0.9973 - val_loss: 0.0962 - val_accuracy: 0.9726\n",
            "Epoch 290/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0153 - accuracy: 0.9981 - val_loss: 0.0904 - val_accuracy: 0.9726\n",
            "Epoch 291/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0134 - accuracy: 0.9989 - val_loss: 0.0923 - val_accuracy: 0.9695\n",
            "Epoch 292/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0152 - accuracy: 0.9977 - val_loss: 0.0934 - val_accuracy: 0.9710\n",
            "Epoch 293/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0130 - accuracy: 0.9977 - val_loss: 0.0895 - val_accuracy: 0.9741\n",
            "Epoch 294/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0149 - accuracy: 0.9977 - val_loss: 0.0915 - val_accuracy: 0.9726\n",
            "Epoch 295/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0151 - accuracy: 0.9962 - val_loss: 0.0964 - val_accuracy: 0.9710\n",
            "Epoch 296/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0130 - accuracy: 0.9977 - val_loss: 0.0966 - val_accuracy: 0.9710\n",
            "Epoch 297/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0129 - accuracy: 0.9981 - val_loss: 0.1014 - val_accuracy: 0.9680\n",
            "Epoch 298/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0138 - accuracy: 0.9977 - val_loss: 0.0963 - val_accuracy: 0.9710\n",
            "Epoch 299/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0150 - accuracy: 0.9981 - val_loss: 0.0950 - val_accuracy: 0.9710\n",
            "Epoch 300/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0145 - accuracy: 0.9989 - val_loss: 0.0958 - val_accuracy: 0.9695\n",
            "Epoch 301/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0125 - accuracy: 0.9992 - val_loss: 0.0959 - val_accuracy: 0.9710\n",
            "Epoch 302/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0125 - accuracy: 0.9981 - val_loss: 0.0988 - val_accuracy: 0.9695\n",
            "Epoch 303/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0147 - accuracy: 0.9973 - val_loss: 0.0963 - val_accuracy: 0.9695\n",
            "Epoch 304/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0126 - accuracy: 0.9977 - val_loss: 0.1026 - val_accuracy: 0.9665\n",
            "Epoch 305/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0133 - accuracy: 0.9977 - val_loss: 0.0950 - val_accuracy: 0.9695\n",
            "Epoch 306/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0123 - accuracy: 0.9992 - val_loss: 0.0980 - val_accuracy: 0.9710\n",
            "Epoch 307/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0143 - accuracy: 0.9989 - val_loss: 0.1008 - val_accuracy: 0.9710\n",
            "Epoch 308/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0126 - accuracy: 0.9985 - val_loss: 0.0948 - val_accuracy: 0.9695\n",
            "Epoch 309/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0127 - accuracy: 0.9977 - val_loss: 0.0969 - val_accuracy: 0.9695\n",
            "Epoch 310/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0125 - accuracy: 0.9973 - val_loss: 0.0974 - val_accuracy: 0.9695\n",
            "Epoch 311/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0134 - accuracy: 0.9985 - val_loss: 0.0935 - val_accuracy: 0.9756\n",
            "Epoch 312/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0132 - accuracy: 0.9977 - val_loss: 0.0991 - val_accuracy: 0.9710\n",
            "Epoch 313/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0137 - accuracy: 0.9985 - val_loss: 0.0984 - val_accuracy: 0.9680\n",
            "Epoch 314/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0117 - accuracy: 0.9989 - val_loss: 0.0968 - val_accuracy: 0.9695\n",
            "Epoch 315/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0125 - accuracy: 0.9973 - val_loss: 0.0937 - val_accuracy: 0.9695\n",
            "Epoch 316/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0118 - accuracy: 0.9989 - val_loss: 0.1028 - val_accuracy: 0.9680\n",
            "Epoch 317/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0121 - accuracy: 0.9977 - val_loss: 0.0972 - val_accuracy: 0.9710\n",
            "Epoch 318/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0138 - accuracy: 0.9977 - val_loss: 0.1008 - val_accuracy: 0.9695\n",
            "Epoch 319/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0120 - accuracy: 0.9989 - val_loss: 0.1078 - val_accuracy: 0.9680\n",
            "Epoch 320/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0160 - accuracy: 0.9962 - val_loss: 0.0979 - val_accuracy: 0.9710\n",
            "Epoch 321/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0139 - accuracy: 0.9985 - val_loss: 0.0973 - val_accuracy: 0.9710\n",
            "Epoch 322/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0123 - accuracy: 0.9985 - val_loss: 0.1062 - val_accuracy: 0.9695\n",
            "Epoch 323/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0125 - accuracy: 0.9981 - val_loss: 0.0961 - val_accuracy: 0.9695\n",
            "Epoch 324/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0129 - accuracy: 0.9973 - val_loss: 0.1004 - val_accuracy: 0.9695\n",
            "Epoch 325/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0138 - accuracy: 0.9973 - val_loss: 0.0988 - val_accuracy: 0.9695\n",
            "Epoch 326/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0115 - accuracy: 0.9985 - val_loss: 0.0994 - val_accuracy: 0.9695\n",
            "Epoch 327/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0137 - accuracy: 0.9981 - val_loss: 0.0977 - val_accuracy: 0.9726\n",
            "Epoch 328/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0126 - accuracy: 0.9981 - val_loss: 0.0991 - val_accuracy: 0.9695\n",
            "Epoch 329/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0106 - accuracy: 0.9996 - val_loss: 0.0994 - val_accuracy: 0.9710\n",
            "Epoch 330/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0129 - accuracy: 0.9981 - val_loss: 0.1009 - val_accuracy: 0.9695\n",
            "Epoch 331/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0104 - accuracy: 0.9989 - val_loss: 0.0971 - val_accuracy: 0.9741\n",
            "Epoch 332/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0121 - accuracy: 0.9977 - val_loss: 0.0992 - val_accuracy: 0.9710\n",
            "Epoch 333/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0113 - accuracy: 0.9989 - val_loss: 0.0973 - val_accuracy: 0.9710\n",
            "Epoch 334/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0117 - accuracy: 0.9977 - val_loss: 0.0991 - val_accuracy: 0.9710\n",
            "Epoch 335/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0133 - accuracy: 0.9985 - val_loss: 0.1022 - val_accuracy: 0.9710\n",
            "Epoch 336/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0109 - accuracy: 0.9992 - val_loss: 0.0990 - val_accuracy: 0.9710\n",
            "Epoch 337/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0120 - accuracy: 0.9977 - val_loss: 0.1039 - val_accuracy: 0.9710\n",
            "Epoch 338/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0115 - accuracy: 0.9981 - val_loss: 0.1005 - val_accuracy: 0.9710\n",
            "Epoch 339/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0108 - accuracy: 0.9992 - val_loss: 0.1051 - val_accuracy: 0.9710\n",
            "Epoch 340/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0139 - accuracy: 0.9970 - val_loss: 0.1012 - val_accuracy: 0.9710\n",
            "Epoch 341/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0125 - accuracy: 0.9981 - val_loss: 0.1000 - val_accuracy: 0.9695\n",
            "Epoch 342/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0119 - accuracy: 0.9981 - val_loss: 0.0970 - val_accuracy: 0.9695\n",
            "Epoch 343/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0120 - accuracy: 0.9989 - val_loss: 0.0977 - val_accuracy: 0.9726\n",
            "Epoch 344/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0107 - accuracy: 0.9989 - val_loss: 0.0995 - val_accuracy: 0.9710\n",
            "Epoch 345/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0135 - accuracy: 0.9970 - val_loss: 0.1005 - val_accuracy: 0.9695\n",
            "Epoch 346/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0129 - accuracy: 0.9973 - val_loss: 0.1014 - val_accuracy: 0.9710\n",
            "Epoch 347/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0119 - accuracy: 0.9985 - val_loss: 0.1018 - val_accuracy: 0.9710\n",
            "Epoch 348/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0114 - accuracy: 0.9973 - val_loss: 0.0976 - val_accuracy: 0.9710\n",
            "Epoch 349/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0126 - accuracy: 0.9977 - val_loss: 0.1032 - val_accuracy: 0.9726\n",
            "Epoch 350/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0111 - accuracy: 0.9981 - val_loss: 0.1032 - val_accuracy: 0.9710\n",
            "Epoch 351/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0105 - accuracy: 0.9985 - val_loss: 0.0990 - val_accuracy: 0.9695\n",
            "Epoch 352/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0104 - accuracy: 0.9992 - val_loss: 0.1018 - val_accuracy: 0.9710\n",
            "Epoch 353/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0114 - accuracy: 0.9989 - val_loss: 0.0988 - val_accuracy: 0.9710\n",
            "Epoch 354/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0109 - accuracy: 0.9992 - val_loss: 0.0998 - val_accuracy: 0.9710\n",
            "Epoch 355/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0097 - accuracy: 0.9989 - val_loss: 0.0971 - val_accuracy: 0.9726\n",
            "Epoch 356/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0092 - accuracy: 0.9992 - val_loss: 0.1029 - val_accuracy: 0.9710\n",
            "Epoch 357/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0106 - accuracy: 0.9989 - val_loss: 0.1006 - val_accuracy: 0.9710\n",
            "Epoch 358/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0109 - accuracy: 0.9989 - val_loss: 0.0999 - val_accuracy: 0.9741\n",
            "Epoch 359/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0094 - accuracy: 0.9985 - val_loss: 0.0989 - val_accuracy: 0.9726\n",
            "Epoch 360/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0103 - accuracy: 0.9996 - val_loss: 0.1033 - val_accuracy: 0.9695\n",
            "Epoch 361/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0106 - accuracy: 0.9992 - val_loss: 0.0961 - val_accuracy: 0.9756\n",
            "Epoch 362/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0098 - accuracy: 0.9996 - val_loss: 0.0979 - val_accuracy: 0.9710\n",
            "Epoch 363/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0104 - accuracy: 0.9981 - val_loss: 0.1047 - val_accuracy: 0.9680\n",
            "Epoch 364/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0111 - accuracy: 0.9985 - val_loss: 0.0973 - val_accuracy: 0.9726\n",
            "Epoch 365/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0115 - accuracy: 0.9966 - val_loss: 0.1017 - val_accuracy: 0.9695\n",
            "Epoch 366/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0175 - accuracy: 0.9962 - val_loss: 0.0983 - val_accuracy: 0.9695\n",
            "Epoch 367/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.0986 - val_accuracy: 0.9756\n",
            "Epoch 368/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0115 - accuracy: 0.9989 - val_loss: 0.0998 - val_accuracy: 0.9710\n",
            "Epoch 369/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0104 - accuracy: 0.9985 - val_loss: 0.1007 - val_accuracy: 0.9741\n",
            "Epoch 370/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0103 - accuracy: 0.9981 - val_loss: 0.1003 - val_accuracy: 0.9710\n",
            "Epoch 371/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0107 - accuracy: 0.9981 - val_loss: 0.0983 - val_accuracy: 0.9710\n",
            "Epoch 372/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0104 - accuracy: 0.9985 - val_loss: 0.1052 - val_accuracy: 0.9726\n",
            "Epoch 373/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0105 - accuracy: 0.9989 - val_loss: 0.0985 - val_accuracy: 0.9756\n",
            "Epoch 374/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0106 - accuracy: 0.9977 - val_loss: 0.1048 - val_accuracy: 0.9710\n",
            "Epoch 375/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0106 - accuracy: 0.9989 - val_loss: 0.1002 - val_accuracy: 0.9710\n",
            "Epoch 376/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0118 - accuracy: 0.9981 - val_loss: 0.1028 - val_accuracy: 0.9726\n",
            "Epoch 377/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0090 - accuracy: 0.9996 - val_loss: 0.0999 - val_accuracy: 0.9710\n",
            "Epoch 378/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0104 - accuracy: 0.9992 - val_loss: 0.1020 - val_accuracy: 0.9710\n",
            "Epoch 379/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.1049 - val_accuracy: 0.9695\n",
            "Epoch 380/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0113 - accuracy: 0.9985 - val_loss: 0.0983 - val_accuracy: 0.9726\n",
            "Epoch 381/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0104 - accuracy: 0.9985 - val_loss: 0.0991 - val_accuracy: 0.9710\n",
            "Epoch 382/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0115 - accuracy: 0.9981 - val_loss: 0.1012 - val_accuracy: 0.9710\n",
            "Epoch 383/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0110 - accuracy: 0.9981 - val_loss: 0.1007 - val_accuracy: 0.9710\n",
            "Epoch 384/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0092 - accuracy: 0.9989 - val_loss: 0.1016 - val_accuracy: 0.9710\n",
            "Epoch 385/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.1061 - val_accuracy: 0.9695\n",
            "Epoch 386/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0087 - accuracy: 0.9985 - val_loss: 0.1012 - val_accuracy: 0.9710\n",
            "Epoch 387/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0087 - accuracy: 0.9992 - val_loss: 0.0988 - val_accuracy: 0.9741\n",
            "Epoch 388/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0107 - accuracy: 0.9985 - val_loss: 0.1004 - val_accuracy: 0.9726\n",
            "Epoch 389/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0087 - accuracy: 0.9996 - val_loss: 0.1037 - val_accuracy: 0.9710\n",
            "Epoch 390/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.1054 - val_accuracy: 0.9710\n",
            "Epoch 391/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0101 - accuracy: 0.9981 - val_loss: 0.1018 - val_accuracy: 0.9710\n",
            "Epoch 392/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0101 - accuracy: 0.9981 - val_loss: 0.1000 - val_accuracy: 0.9680\n",
            "Epoch 393/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0104 - accuracy: 0.9985 - val_loss: 0.1034 - val_accuracy: 0.9695\n",
            "Epoch 394/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0091 - accuracy: 0.9989 - val_loss: 0.1052 - val_accuracy: 0.9695\n",
            "Epoch 395/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0095 - accuracy: 0.9989 - val_loss: 0.1056 - val_accuracy: 0.9695\n",
            "Epoch 396/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0095 - accuracy: 0.9981 - val_loss: 0.0992 - val_accuracy: 0.9756\n",
            "Epoch 397/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0095 - accuracy: 0.9989 - val_loss: 0.1043 - val_accuracy: 0.9710\n",
            "Epoch 398/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0103 - accuracy: 0.9985 - val_loss: 0.1102 - val_accuracy: 0.9695\n",
            "Epoch 399/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0081 - accuracy: 0.9992 - val_loss: 0.1027 - val_accuracy: 0.9710\n",
            "Epoch 400/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0103 - accuracy: 0.9977 - val_loss: 0.1012 - val_accuracy: 0.9710\n",
            "Epoch 401/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0092 - accuracy: 0.9992 - val_loss: 0.1008 - val_accuracy: 0.9710\n",
            "Epoch 402/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0093 - accuracy: 0.9992 - val_loss: 0.1018 - val_accuracy: 0.9710\n",
            "Epoch 403/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0090 - accuracy: 0.9996 - val_loss: 0.1002 - val_accuracy: 0.9756\n",
            "Epoch 404/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0088 - accuracy: 0.9985 - val_loss: 0.1034 - val_accuracy: 0.9710\n",
            "Epoch 405/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0085 - accuracy: 0.9992 - val_loss: 0.1039 - val_accuracy: 0.9741\n",
            "Epoch 406/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0091 - accuracy: 0.9989 - val_loss: 0.1039 - val_accuracy: 0.9710\n",
            "Epoch 407/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0099 - accuracy: 0.9989 - val_loss: 0.0998 - val_accuracy: 0.9726\n",
            "Epoch 408/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0085 - accuracy: 0.9992 - val_loss: 0.1034 - val_accuracy: 0.9726\n",
            "Epoch 409/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0089 - accuracy: 0.9985 - val_loss: 0.1031 - val_accuracy: 0.9726\n",
            "Epoch 410/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0085 - accuracy: 0.9992 - val_loss: 0.1044 - val_accuracy: 0.9726\n",
            "Epoch 411/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0077 - accuracy: 0.9992 - val_loss: 0.1034 - val_accuracy: 0.9710\n",
            "Epoch 412/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0081 - accuracy: 0.9989 - val_loss: 0.1027 - val_accuracy: 0.9756\n",
            "Epoch 413/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0090 - accuracy: 0.9981 - val_loss: 0.1085 - val_accuracy: 0.9710\n",
            "Epoch 414/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0099 - accuracy: 0.9985 - val_loss: 0.1062 - val_accuracy: 0.9710\n",
            "Epoch 415/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0088 - accuracy: 0.9996 - val_loss: 0.1053 - val_accuracy: 0.9710\n",
            "Epoch 416/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0090 - accuracy: 0.9996 - val_loss: 0.1042 - val_accuracy: 0.9710\n",
            "Epoch 417/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.1066 - val_accuracy: 0.9710\n",
            "Epoch 418/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0084 - accuracy: 0.9989 - val_loss: 0.1023 - val_accuracy: 0.9741\n",
            "Epoch 419/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0089 - accuracy: 0.9992 - val_loss: 0.1037 - val_accuracy: 0.9726\n",
            "Epoch 420/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0082 - accuracy: 0.9992 - val_loss: 0.1063 - val_accuracy: 0.9726\n",
            "Epoch 421/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0073 - accuracy: 0.9996 - val_loss: 0.1053 - val_accuracy: 0.9710\n",
            "Epoch 422/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0074 - accuracy: 0.9996 - val_loss: 0.1052 - val_accuracy: 0.9741\n",
            "Epoch 423/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0088 - accuracy: 0.9989 - val_loss: 0.1008 - val_accuracy: 0.9771\n",
            "Epoch 424/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0072 - accuracy: 0.9996 - val_loss: 0.1044 - val_accuracy: 0.9710\n",
            "Epoch 425/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0084 - accuracy: 0.9989 - val_loss: 0.1093 - val_accuracy: 0.9710\n",
            "Epoch 426/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0082 - accuracy: 0.9985 - val_loss: 0.1042 - val_accuracy: 0.9741\n",
            "Epoch 427/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0087 - accuracy: 0.9985 - val_loss: 0.1049 - val_accuracy: 0.9726\n",
            "Epoch 428/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0106 - accuracy: 0.9977 - val_loss: 0.1035 - val_accuracy: 0.9710\n",
            "Epoch 429/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0081 - accuracy: 0.9996 - val_loss: 0.1019 - val_accuracy: 0.9741\n",
            "Epoch 430/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0078 - accuracy: 0.9992 - val_loss: 0.1036 - val_accuracy: 0.9710\n",
            "Epoch 431/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0092 - accuracy: 0.9981 - val_loss: 0.1064 - val_accuracy: 0.9695\n",
            "Epoch 432/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0074 - accuracy: 0.9989 - val_loss: 0.1036 - val_accuracy: 0.9710\n",
            "Epoch 433/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0073 - accuracy: 0.9996 - val_loss: 0.1101 - val_accuracy: 0.9695\n",
            "Epoch 434/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0085 - accuracy: 0.9989 - val_loss: 0.1051 - val_accuracy: 0.9726\n",
            "Epoch 435/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0088 - accuracy: 0.9981 - val_loss: 0.1040 - val_accuracy: 0.9710\n",
            "Epoch 436/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0082 - accuracy: 0.9996 - val_loss: 0.1054 - val_accuracy: 0.9710\n",
            "Epoch 437/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0089 - accuracy: 0.9985 - val_loss: 0.1043 - val_accuracy: 0.9726\n",
            "Epoch 438/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0079 - accuracy: 0.9996 - val_loss: 0.1064 - val_accuracy: 0.9710\n",
            "Epoch 439/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0085 - accuracy: 0.9985 - val_loss: 0.1052 - val_accuracy: 0.9726\n",
            "Epoch 440/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0078 - accuracy: 0.9992 - val_loss: 0.1013 - val_accuracy: 0.9756\n",
            "Epoch 441/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0091 - accuracy: 0.9989 - val_loss: 0.1088 - val_accuracy: 0.9726\n",
            "Epoch 442/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0076 - accuracy: 0.9996 - val_loss: 0.1076 - val_accuracy: 0.9710\n",
            "Epoch 443/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0076 - accuracy: 0.9992 - val_loss: 0.1071 - val_accuracy: 0.9710\n",
            "Epoch 444/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0076 - accuracy: 0.9992 - val_loss: 0.1071 - val_accuracy: 0.9710\n",
            "Epoch 445/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0081 - accuracy: 0.9992 - val_loss: 0.1035 - val_accuracy: 0.9726\n",
            "Epoch 446/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0083 - accuracy: 0.9989 - val_loss: 0.1105 - val_accuracy: 0.9710\n",
            "Epoch 447/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0073 - accuracy: 0.9992 - val_loss: 0.1085 - val_accuracy: 0.9710\n",
            "Epoch 448/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0082 - accuracy: 0.9989 - val_loss: 0.1047 - val_accuracy: 0.9710\n",
            "Epoch 449/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0088 - accuracy: 0.9985 - val_loss: 0.1059 - val_accuracy: 0.9710\n",
            "Epoch 450/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0078 - accuracy: 0.9992 - val_loss: 0.1077 - val_accuracy: 0.9710\n",
            "Epoch 451/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0082 - accuracy: 0.9985 - val_loss: 0.1033 - val_accuracy: 0.9756\n",
            "Epoch 452/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0083 - accuracy: 0.9996 - val_loss: 0.1098 - val_accuracy: 0.9710\n",
            "Epoch 453/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0075 - accuracy: 0.9989 - val_loss: 0.1056 - val_accuracy: 0.9710\n",
            "Epoch 454/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0080 - accuracy: 0.9989 - val_loss: 0.1052 - val_accuracy: 0.9726\n",
            "Epoch 455/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0076 - accuracy: 0.9996 - val_loss: 0.1084 - val_accuracy: 0.9710\n",
            "Epoch 456/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0068 - accuracy: 0.9996 - val_loss: 0.1061 - val_accuracy: 0.9710\n",
            "Epoch 457/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0079 - accuracy: 0.9992 - val_loss: 0.1064 - val_accuracy: 0.9710\n",
            "Epoch 458/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0084 - accuracy: 0.9989 - val_loss: 0.1051 - val_accuracy: 0.9726\n",
            "Epoch 459/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0080 - accuracy: 0.9989 - val_loss: 0.1055 - val_accuracy: 0.9710\n",
            "Epoch 460/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0094 - accuracy: 0.9989 - val_loss: 0.1028 - val_accuracy: 0.9710\n",
            "Epoch 461/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0080 - accuracy: 0.9989 - val_loss: 0.1047 - val_accuracy: 0.9710\n",
            "Epoch 462/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0087 - accuracy: 0.9989 - val_loss: 0.1072 - val_accuracy: 0.9710\n",
            "Epoch 463/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0089 - accuracy: 0.9985 - val_loss: 0.1033 - val_accuracy: 0.9710\n",
            "Epoch 464/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0074 - accuracy: 0.9996 - val_loss: 0.1038 - val_accuracy: 0.9726\n",
            "Epoch 465/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0073 - accuracy: 0.9992 - val_loss: 0.1038 - val_accuracy: 0.9726\n",
            "Epoch 466/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0087 - accuracy: 0.9989 - val_loss: 0.1083 - val_accuracy: 0.9726\n",
            "Epoch 467/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0079 - accuracy: 0.9989 - val_loss: 0.1074 - val_accuracy: 0.9710\n",
            "Epoch 468/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0080 - accuracy: 0.9985 - val_loss: 0.1020 - val_accuracy: 0.9726\n",
            "Epoch 469/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0070 - accuracy: 0.9996 - val_loss: 0.1106 - val_accuracy: 0.9726\n",
            "Epoch 470/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0076 - accuracy: 0.9992 - val_loss: 0.1067 - val_accuracy: 0.9726\n",
            "Epoch 471/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0072 - accuracy: 0.9996 - val_loss: 0.1071 - val_accuracy: 0.9710\n",
            "Epoch 472/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0091 - accuracy: 0.9989 - val_loss: 0.1050 - val_accuracy: 0.9726\n",
            "Epoch 473/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0076 - accuracy: 0.9992 - val_loss: 0.1063 - val_accuracy: 0.9710\n",
            "Epoch 474/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0062 - accuracy: 0.9996 - val_loss: 0.1074 - val_accuracy: 0.9710\n",
            "Epoch 475/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0071 - accuracy: 0.9985 - val_loss: 0.1101 - val_accuracy: 0.9710\n",
            "Epoch 476/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0065 - accuracy: 0.9992 - val_loss: 0.1102 - val_accuracy: 0.9726\n",
            "Epoch 477/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0074 - accuracy: 0.9992 - val_loss: 0.1067 - val_accuracy: 0.9771\n",
            "Epoch 478/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0073 - accuracy: 0.9989 - val_loss: 0.1046 - val_accuracy: 0.9741\n",
            "Epoch 479/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0075 - accuracy: 0.9989 - val_loss: 0.1085 - val_accuracy: 0.9710\n",
            "Epoch 480/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0073 - accuracy: 0.9996 - val_loss: 0.1100 - val_accuracy: 0.9726\n",
            "Epoch 481/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0072 - accuracy: 0.9992 - val_loss: 0.1093 - val_accuracy: 0.9695\n",
            "Epoch 482/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0066 - accuracy: 0.9992 - val_loss: 0.1079 - val_accuracy: 0.9710\n",
            "Epoch 483/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0069 - accuracy: 0.9992 - val_loss: 0.1063 - val_accuracy: 0.9726\n",
            "Epoch 484/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0076 - accuracy: 0.9989 - val_loss: 0.1219 - val_accuracy: 0.9680\n",
            "Epoch 485/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0102 - accuracy: 0.9973 - val_loss: 0.1039 - val_accuracy: 0.9726\n",
            "Epoch 486/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.1085 - val_accuracy: 0.9710\n",
            "Epoch 487/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0063 - accuracy: 0.9996 - val_loss: 0.1097 - val_accuracy: 0.9710\n",
            "Epoch 488/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0077 - accuracy: 0.9985 - val_loss: 0.1078 - val_accuracy: 0.9710\n",
            "Epoch 489/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0064 - accuracy: 0.9989 - val_loss: 0.1095 - val_accuracy: 0.9695\n",
            "Epoch 490/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0082 - accuracy: 0.9985 - val_loss: 0.1066 - val_accuracy: 0.9756\n",
            "Epoch 491/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0063 - accuracy: 0.9996 - val_loss: 0.1076 - val_accuracy: 0.9741\n",
            "Epoch 492/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0082 - accuracy: 0.9989 - val_loss: 0.1089 - val_accuracy: 0.9710\n",
            "Epoch 493/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0076 - accuracy: 0.9985 - val_loss: 0.1080 - val_accuracy: 0.9710\n",
            "Epoch 494/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0071 - accuracy: 0.9996 - val_loss: 0.1067 - val_accuracy: 0.9726\n",
            "Epoch 495/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0079 - accuracy: 0.9996 - val_loss: 0.1090 - val_accuracy: 0.9710\n",
            "Epoch 496/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0057 - accuracy: 0.9996 - val_loss: 0.1076 - val_accuracy: 0.9726\n",
            "Epoch 497/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0084 - accuracy: 0.9985 - val_loss: 0.1048 - val_accuracy: 0.9756\n",
            "Epoch 498/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0082 - accuracy: 0.9992 - val_loss: 0.1131 - val_accuracy: 0.9710\n",
            "Epoch 499/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0066 - accuracy: 0.9996 - val_loss: 0.1086 - val_accuracy: 0.9710\n",
            "Epoch 500/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0064 - accuracy: 0.9996 - val_loss: 0.1080 - val_accuracy: 0.9726\n",
            "Epoch 501/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0080 - accuracy: 0.9989 - val_loss: 0.1068 - val_accuracy: 0.9726\n",
            "Epoch 502/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.1075 - val_accuracy: 0.9726\n",
            "Epoch 503/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0066 - accuracy: 0.9992 - val_loss: 0.1085 - val_accuracy: 0.9710\n",
            "Epoch 504/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0071 - accuracy: 0.9992 - val_loss: 0.1109 - val_accuracy: 0.9710\n",
            "Epoch 505/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0075 - accuracy: 0.9992 - val_loss: 0.1056 - val_accuracy: 0.9726\n",
            "Epoch 506/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.1072 - val_accuracy: 0.9771\n",
            "Epoch 507/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0066 - accuracy: 0.9992 - val_loss: 0.1061 - val_accuracy: 0.9756\n",
            "Epoch 508/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0068 - accuracy: 0.9996 - val_loss: 0.1107 - val_accuracy: 0.9695\n",
            "Epoch 509/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0065 - accuracy: 0.9996 - val_loss: 0.1100 - val_accuracy: 0.9695\n",
            "Epoch 510/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0076 - accuracy: 0.9989 - val_loss: 0.1078 - val_accuracy: 0.9741\n",
            "Epoch 511/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0067 - accuracy: 0.9989 - val_loss: 0.1069 - val_accuracy: 0.9710\n",
            "Epoch 512/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0068 - accuracy: 0.9996 - val_loss: 0.1055 - val_accuracy: 0.9741\n",
            "Epoch 513/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0065 - accuracy: 0.9992 - val_loss: 0.1108 - val_accuracy: 0.9710\n",
            "Epoch 514/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0066 - accuracy: 0.9996 - val_loss: 0.1139 - val_accuracy: 0.9710\n",
            "Epoch 515/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0075 - accuracy: 0.9996 - val_loss: 0.1077 - val_accuracy: 0.9726\n",
            "Epoch 516/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0076 - accuracy: 0.9989 - val_loss: 0.1060 - val_accuracy: 0.9726\n",
            "Epoch 517/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0066 - accuracy: 0.9992 - val_loss: 0.1074 - val_accuracy: 0.9741\n",
            "Epoch 518/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.1094 - val_accuracy: 0.9726\n",
            "Epoch 519/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0076 - accuracy: 0.9981 - val_loss: 0.1082 - val_accuracy: 0.9726\n",
            "Epoch 520/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0070 - accuracy: 0.9992 - val_loss: 0.1117 - val_accuracy: 0.9710\n",
            "Epoch 521/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0066 - accuracy: 0.9992 - val_loss: 0.1071 - val_accuracy: 0.9726\n",
            "Epoch 522/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0064 - accuracy: 0.9996 - val_loss: 0.1102 - val_accuracy: 0.9710\n",
            "Epoch 523/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.1070 - val_accuracy: 0.9726\n",
            "Epoch 524/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0073 - accuracy: 0.9989 - val_loss: 0.1065 - val_accuracy: 0.9741\n",
            "Epoch 525/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0054 - accuracy: 0.9996 - val_loss: 0.1074 - val_accuracy: 0.9756\n",
            "Epoch 526/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0062 - accuracy: 0.9996 - val_loss: 0.1098 - val_accuracy: 0.9695\n",
            "Epoch 527/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0064 - accuracy: 0.9996 - val_loss: 0.1082 - val_accuracy: 0.9771\n",
            "Epoch 528/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0070 - accuracy: 0.9992 - val_loss: 0.1082 - val_accuracy: 0.9741\n",
            "Epoch 529/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0061 - accuracy: 0.9989 - val_loss: 0.1132 - val_accuracy: 0.9710\n",
            "Epoch 530/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0057 - accuracy: 0.9996 - val_loss: 0.1094 - val_accuracy: 0.9710\n",
            "Epoch 531/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0063 - accuracy: 0.9996 - val_loss: 0.1160 - val_accuracy: 0.9695\n",
            "Epoch 532/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0073 - accuracy: 0.9985 - val_loss: 0.1111 - val_accuracy: 0.9695\n",
            "Epoch 533/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0073 - accuracy: 0.9992 - val_loss: 0.1072 - val_accuracy: 0.9741\n",
            "Epoch 534/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0056 - accuracy: 0.9996 - val_loss: 0.1090 - val_accuracy: 0.9710\n",
            "Epoch 535/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.1154 - val_accuracy: 0.9695\n",
            "Epoch 536/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0061 - accuracy: 0.9996 - val_loss: 0.1113 - val_accuracy: 0.9695\n",
            "Epoch 537/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0069 - accuracy: 0.9992 - val_loss: 0.1105 - val_accuracy: 0.9695\n",
            "Epoch 538/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0065 - accuracy: 0.9996 - val_loss: 0.1195 - val_accuracy: 0.9680\n",
            "Epoch 539/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0077 - accuracy: 0.9989 - val_loss: 0.1096 - val_accuracy: 0.9726\n",
            "Epoch 540/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0067 - accuracy: 0.9989 - val_loss: 0.1092 - val_accuracy: 0.9710\n",
            "Epoch 541/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0069 - accuracy: 0.9989 - val_loss: 0.1070 - val_accuracy: 0.9726\n",
            "Epoch 542/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0056 - accuracy: 0.9996 - val_loss: 0.1104 - val_accuracy: 0.9726\n",
            "Epoch 543/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0061 - accuracy: 0.9996 - val_loss: 0.1109 - val_accuracy: 0.9710\n",
            "Epoch 544/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0056 - accuracy: 0.9996 - val_loss: 0.1114 - val_accuracy: 0.9710\n",
            "Epoch 545/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0050 - accuracy: 0.9992 - val_loss: 0.1064 - val_accuracy: 0.9756\n",
            "Epoch 546/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0073 - accuracy: 0.9989 - val_loss: 0.1085 - val_accuracy: 0.9726\n",
            "Epoch 547/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0055 - accuracy: 0.9996 - val_loss: 0.1133 - val_accuracy: 0.9710\n",
            "Epoch 548/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.1115 - val_accuracy: 0.9710\n",
            "Epoch 549/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0054 - accuracy: 0.9996 - val_loss: 0.1139 - val_accuracy: 0.9695\n",
            "Epoch 550/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0072 - accuracy: 0.9996 - val_loss: 0.1115 - val_accuracy: 0.9710\n",
            "Epoch 551/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0068 - accuracy: 0.9985 - val_loss: 0.1102 - val_accuracy: 0.9741\n",
            "Epoch 552/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.1113 - val_accuracy: 0.9695\n",
            "Epoch 553/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0054 - accuracy: 0.9996 - val_loss: 0.1103 - val_accuracy: 0.9710\n",
            "Epoch 554/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0050 - accuracy: 0.9996 - val_loss: 0.1134 - val_accuracy: 0.9695\n",
            "Epoch 555/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0063 - accuracy: 0.9989 - val_loss: 0.1147 - val_accuracy: 0.9680\n",
            "Epoch 556/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0067 - accuracy: 0.9992 - val_loss: 0.1124 - val_accuracy: 0.9726\n",
            "Epoch 557/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0057 - accuracy: 0.9992 - val_loss: 0.1137 - val_accuracy: 0.9710\n",
            "Epoch 558/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0058 - accuracy: 0.9996 - val_loss: 0.1166 - val_accuracy: 0.9680\n",
            "Epoch 559/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0087 - accuracy: 0.9981 - val_loss: 0.1078 - val_accuracy: 0.9756\n",
            "Epoch 560/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0064 - accuracy: 0.9992 - val_loss: 0.1082 - val_accuracy: 0.9726\n",
            "Epoch 561/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0056 - accuracy: 0.9992 - val_loss: 0.1090 - val_accuracy: 0.9726\n",
            "Epoch 562/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0069 - accuracy: 0.9989 - val_loss: 0.1091 - val_accuracy: 0.9741\n",
            "Epoch 563/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.1121 - val_accuracy: 0.9726\n",
            "Epoch 564/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0069 - accuracy: 0.9992 - val_loss: 0.1139 - val_accuracy: 0.9710\n",
            "Epoch 565/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0063 - accuracy: 0.9996 - val_loss: 0.1131 - val_accuracy: 0.9695\n",
            "Epoch 566/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0062 - accuracy: 0.9992 - val_loss: 0.1124 - val_accuracy: 0.9741\n",
            "Epoch 567/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.1136 - val_accuracy: 0.9695\n",
            "Epoch 568/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0064 - accuracy: 0.9996 - val_loss: 0.1152 - val_accuracy: 0.9695\n",
            "Epoch 569/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0051 - accuracy: 0.9996 - val_loss: 0.1086 - val_accuracy: 0.9741\n",
            "Epoch 570/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0052 - accuracy: 0.9996 - val_loss: 0.1107 - val_accuracy: 0.9726\n",
            "Epoch 571/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0052 - accuracy: 0.9996 - val_loss: 0.1121 - val_accuracy: 0.9726\n",
            "Epoch 572/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0051 - accuracy: 0.9996 - val_loss: 0.1126 - val_accuracy: 0.9710\n",
            "Epoch 573/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0057 - accuracy: 0.9996 - val_loss: 0.1088 - val_accuracy: 0.9741\n",
            "Epoch 574/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0073 - accuracy: 0.9992 - val_loss: 0.1106 - val_accuracy: 0.9741\n",
            "Epoch 575/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.1108 - val_accuracy: 0.9726\n",
            "Epoch 576/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0058 - accuracy: 0.9992 - val_loss: 0.1132 - val_accuracy: 0.9695\n",
            "Epoch 577/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0055 - accuracy: 0.9996 - val_loss: 0.1113 - val_accuracy: 0.9726\n",
            "Epoch 578/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0061 - accuracy: 0.9992 - val_loss: 0.1116 - val_accuracy: 0.9726\n",
            "Epoch 579/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0065 - accuracy: 0.9985 - val_loss: 0.1133 - val_accuracy: 0.9710\n",
            "Epoch 580/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.1122 - val_accuracy: 0.9710\n",
            "Epoch 581/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1156 - val_accuracy: 0.9710\n",
            "Epoch 582/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0047 - accuracy: 0.9996 - val_loss: 0.1122 - val_accuracy: 0.9726\n",
            "Epoch 583/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 0.1129 - val_accuracy: 0.9726\n",
            "Epoch 584/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1140 - val_accuracy: 0.9726\n",
            "Epoch 585/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1134 - val_accuracy: 0.9726\n",
            "Epoch 586/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0069 - accuracy: 0.9992 - val_loss: 0.1141 - val_accuracy: 0.9726\n",
            "Epoch 587/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0053 - accuracy: 0.9996 - val_loss: 0.1127 - val_accuracy: 0.9726\n",
            "Epoch 588/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0059 - accuracy: 0.9992 - val_loss: 0.1103 - val_accuracy: 0.9741\n",
            "Epoch 589/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0069 - accuracy: 0.9989 - val_loss: 0.1105 - val_accuracy: 0.9726\n",
            "Epoch 590/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0064 - accuracy: 0.9989 - val_loss: 0.1121 - val_accuracy: 0.9710\n",
            "Epoch 591/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0055 - accuracy: 0.9992 - val_loss: 0.1135 - val_accuracy: 0.9710\n",
            "Epoch 592/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0053 - accuracy: 0.9996 - val_loss: 0.1112 - val_accuracy: 0.9726\n",
            "Epoch 593/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0048 - accuracy: 0.9996 - val_loss: 0.1145 - val_accuracy: 0.9710\n",
            "Epoch 594/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 0.9996 - val_loss: 0.1130 - val_accuracy: 0.9726\n",
            "Epoch 595/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.1161 - val_accuracy: 0.9695\n",
            "Epoch 596/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0060 - accuracy: 0.9996 - val_loss: 0.1074 - val_accuracy: 0.9741\n",
            "Epoch 597/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0063 - accuracy: 0.9989 - val_loss: 0.1106 - val_accuracy: 0.9741\n",
            "Epoch 598/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0056 - accuracy: 0.9992 - val_loss: 0.1104 - val_accuracy: 0.9726\n",
            "Epoch 599/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0064 - accuracy: 0.9992 - val_loss: 0.1118 - val_accuracy: 0.9710\n",
            "Epoch 600/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 0.9996 - val_loss: 0.1121 - val_accuracy: 0.9726\n",
            "Epoch 601/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1129 - val_accuracy: 0.9726\n",
            "Epoch 602/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0052 - accuracy: 0.9996 - val_loss: 0.1130 - val_accuracy: 0.9726\n",
            "Epoch 603/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.1151 - val_accuracy: 0.9695\n",
            "Epoch 604/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0055 - accuracy: 0.9992 - val_loss: 0.1049 - val_accuracy: 0.9756\n",
            "Epoch 605/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0098 - accuracy: 0.9981 - val_loss: 0.1007 - val_accuracy: 0.9741\n",
            "Epoch 606/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0088 - accuracy: 0.9985 - val_loss: 0.1075 - val_accuracy: 0.9726\n",
            "Epoch 607/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0054 - accuracy: 0.9996 - val_loss: 0.1113 - val_accuracy: 0.9695\n",
            "Epoch 608/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0055 - accuracy: 0.9992 - val_loss: 0.1104 - val_accuracy: 0.9726\n",
            "Epoch 609/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0062 - accuracy: 0.9996 - val_loss: 0.1097 - val_accuracy: 0.9710\n",
            "Epoch 610/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0060 - accuracy: 0.9996 - val_loss: 0.1119 - val_accuracy: 0.9710\n",
            "Epoch 611/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.1100 - val_accuracy: 0.9787\n",
            "Epoch 612/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0058 - accuracy: 0.9992 - val_loss: 0.1151 - val_accuracy: 0.9726\n",
            "Epoch 613/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0050 - accuracy: 0.9996 - val_loss: 0.1141 - val_accuracy: 0.9710\n",
            "Epoch 614/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 0.9996 - val_loss: 0.1148 - val_accuracy: 0.9726\n",
            "Epoch 615/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0053 - accuracy: 0.9992 - val_loss: 0.1137 - val_accuracy: 0.9710\n",
            "Epoch 616/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1152 - val_accuracy: 0.9710\n",
            "Epoch 617/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0047 - accuracy: 0.9996 - val_loss: 0.1193 - val_accuracy: 0.9710\n",
            "Epoch 618/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0057 - accuracy: 0.9996 - val_loss: 0.1133 - val_accuracy: 0.9710\n",
            "Epoch 619/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 0.9992 - val_loss: 0.1162 - val_accuracy: 0.9695\n",
            "Epoch 620/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1183 - val_accuracy: 0.9710\n",
            "Epoch 621/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 0.9992 - val_loss: 0.1135 - val_accuracy: 0.9726\n",
            "Epoch 622/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1157 - val_accuracy: 0.9726\n",
            "Epoch 623/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0055 - accuracy: 0.9992 - val_loss: 0.1119 - val_accuracy: 0.9726\n",
            "Epoch 624/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0051 - accuracy: 0.9992 - val_loss: 0.1142 - val_accuracy: 0.9710\n",
            "Epoch 625/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0058 - accuracy: 0.9989 - val_loss: 0.1141 - val_accuracy: 0.9710\n",
            "Epoch 626/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0055 - accuracy: 0.9996 - val_loss: 0.1153 - val_accuracy: 0.9741\n",
            "Epoch 627/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.1145 - val_accuracy: 0.9710\n",
            "Epoch 628/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.1143 - val_accuracy: 0.9726\n",
            "Epoch 629/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1161 - val_accuracy: 0.9710\n",
            "Epoch 630/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0050 - accuracy: 0.9996 - val_loss: 0.1145 - val_accuracy: 0.9710\n",
            "Epoch 631/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1155 - val_accuracy: 0.9695\n",
            "Epoch 632/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0053 - accuracy: 0.9992 - val_loss: 0.1142 - val_accuracy: 0.9710\n",
            "Epoch 633/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0062 - accuracy: 0.9985 - val_loss: 0.1156 - val_accuracy: 0.9695\n",
            "Epoch 634/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.1141 - val_accuracy: 0.9710\n",
            "Epoch 635/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1149 - val_accuracy: 0.9710\n",
            "Epoch 636/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0043 - accuracy: 0.9996 - val_loss: 0.1193 - val_accuracy: 0.9695\n",
            "Epoch 637/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.1147 - val_accuracy: 0.9710\n",
            "Epoch 638/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.1142 - val_accuracy: 0.9741\n",
            "Epoch 639/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0061 - accuracy: 0.9992 - val_loss: 0.1146 - val_accuracy: 0.9710\n",
            "Epoch 640/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1144 - val_accuracy: 0.9726\n",
            "Epoch 641/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.1174 - val_accuracy: 0.9695\n",
            "Epoch 642/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1150 - val_accuracy: 0.9710\n",
            "Epoch 643/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1184 - val_accuracy: 0.9710\n",
            "Epoch 644/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0051 - accuracy: 0.9992 - val_loss: 0.1157 - val_accuracy: 0.9726\n",
            "Epoch 645/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1187 - val_accuracy: 0.9710\n",
            "Epoch 646/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0052 - accuracy: 0.9996 - val_loss: 0.1164 - val_accuracy: 0.9710\n",
            "Epoch 647/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0049 - accuracy: 0.9992 - val_loss: 0.1178 - val_accuracy: 0.9710\n",
            "Epoch 648/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0055 - accuracy: 0.9992 - val_loss: 0.1155 - val_accuracy: 0.9710\n",
            "Epoch 649/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0049 - accuracy: 0.9992 - val_loss: 0.1120 - val_accuracy: 0.9741\n",
            "Epoch 650/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.1123 - val_accuracy: 0.9741\n",
            "Epoch 651/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1151 - val_accuracy: 0.9726\n",
            "Epoch 652/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0054 - accuracy: 0.9992 - val_loss: 0.1146 - val_accuracy: 0.9741\n",
            "Epoch 653/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1173 - val_accuracy: 0.9695\n",
            "Epoch 654/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0054 - accuracy: 0.9996 - val_loss: 0.1172 - val_accuracy: 0.9710\n",
            "Epoch 655/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0051 - accuracy: 0.9992 - val_loss: 0.1171 - val_accuracy: 0.9710\n",
            "Epoch 656/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1191 - val_accuracy: 0.9710\n",
            "Epoch 657/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0049 - accuracy: 0.9996 - val_loss: 0.1160 - val_accuracy: 0.9726\n",
            "Epoch 658/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0049 - accuracy: 0.9992 - val_loss: 0.1150 - val_accuracy: 0.9741\n",
            "Epoch 659/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.1172 - val_accuracy: 0.9726\n",
            "Epoch 660/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0048 - accuracy: 0.9996 - val_loss: 0.1147 - val_accuracy: 0.9710\n",
            "Epoch 661/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.1137 - val_accuracy: 0.9741\n",
            "Epoch 662/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0048 - accuracy: 0.9996 - val_loss: 0.1189 - val_accuracy: 0.9710\n",
            "Epoch 663/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0045 - accuracy: 0.9996 - val_loss: 0.1184 - val_accuracy: 0.9710\n",
            "Epoch 664/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0054 - accuracy: 0.9981 - val_loss: 0.1129 - val_accuracy: 0.9756\n",
            "Epoch 665/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0050 - accuracy: 0.9996 - val_loss: 0.1142 - val_accuracy: 0.9726\n",
            "Epoch 666/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1156 - val_accuracy: 0.9726\n",
            "Epoch 667/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0043 - accuracy: 0.9996 - val_loss: 0.1164 - val_accuracy: 0.9726\n",
            "Epoch 668/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.1158 - val_accuracy: 0.9710\n",
            "Epoch 669/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0059 - accuracy: 0.9996 - val_loss: 0.1134 - val_accuracy: 0.9741\n",
            "Epoch 670/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0047 - accuracy: 0.9996 - val_loss: 0.1145 - val_accuracy: 0.9726\n",
            "Epoch 671/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0049 - accuracy: 0.9992 - val_loss: 0.1165 - val_accuracy: 0.9710\n",
            "Epoch 672/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0048 - accuracy: 0.9996 - val_loss: 0.1173 - val_accuracy: 0.9726\n",
            "Epoch 673/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0058 - accuracy: 0.9989 - val_loss: 0.1150 - val_accuracy: 0.9726\n",
            "Epoch 674/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0050 - accuracy: 0.9996 - val_loss: 0.1189 - val_accuracy: 0.9680\n",
            "Epoch 675/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0058 - accuracy: 0.9996 - val_loss: 0.1163 - val_accuracy: 0.9695\n",
            "Epoch 676/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1158 - val_accuracy: 0.9710\n",
            "Epoch 677/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 0.1163 - val_accuracy: 0.9710\n",
            "Epoch 678/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.1141 - val_accuracy: 0.9741\n",
            "Epoch 679/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0049 - accuracy: 0.9992 - val_loss: 0.1156 - val_accuracy: 0.9710\n",
            "Epoch 680/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1182 - val_accuracy: 0.9710\n",
            "Epoch 681/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.1171 - val_accuracy: 0.9695\n",
            "Epoch 682/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1189 - val_accuracy: 0.9710\n",
            "Epoch 683/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0044 - accuracy: 0.9996 - val_loss: 0.1174 - val_accuracy: 0.9726\n",
            "Epoch 684/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 0.1169 - val_accuracy: 0.9695\n",
            "Epoch 685/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0041 - accuracy: 0.9996 - val_loss: 0.1176 - val_accuracy: 0.9710\n",
            "Epoch 686/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0057 - accuracy: 0.9992 - val_loss: 0.1162 - val_accuracy: 0.9741\n",
            "Epoch 687/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1178 - val_accuracy: 0.9726\n",
            "Epoch 688/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0043 - accuracy: 0.9996 - val_loss: 0.1180 - val_accuracy: 0.9710\n",
            "Epoch 689/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0046 - accuracy: 0.9996 - val_loss: 0.1173 - val_accuracy: 0.9726\n",
            "Epoch 690/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.1175 - val_accuracy: 0.9710\n",
            "Epoch 691/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 0.1139 - val_accuracy: 0.9756\n",
            "Epoch 692/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.1180 - val_accuracy: 0.9710\n",
            "Epoch 693/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0052 - accuracy: 0.9992 - val_loss: 0.1155 - val_accuracy: 0.9741\n",
            "Epoch 694/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0037 - accuracy: 0.9996 - val_loss: 0.1186 - val_accuracy: 0.9710\n",
            "Epoch 695/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1169 - val_accuracy: 0.9726\n",
            "Epoch 696/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0054 - accuracy: 0.9996 - val_loss: 0.1213 - val_accuracy: 0.9710\n",
            "Epoch 697/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1182 - val_accuracy: 0.9710\n",
            "Epoch 698/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0045 - accuracy: 0.9996 - val_loss: 0.1230 - val_accuracy: 0.9695\n",
            "Epoch 699/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0042 - accuracy: 0.9996 - val_loss: 0.1138 - val_accuracy: 0.9741\n",
            "Epoch 700/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0051 - accuracy: 0.9992 - val_loss: 0.1172 - val_accuracy: 0.9695\n",
            "Epoch 701/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0060 - accuracy: 0.9992 - val_loss: 0.1169 - val_accuracy: 0.9726\n",
            "Epoch 702/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.1168 - val_accuracy: 0.9710\n",
            "Epoch 703/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0043 - accuracy: 0.9996 - val_loss: 0.1199 - val_accuracy: 0.9710\n",
            "Epoch 704/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1207 - val_accuracy: 0.9695\n",
            "Epoch 705/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 0.1162 - val_accuracy: 0.9726\n",
            "Epoch 706/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1175 - val_accuracy: 0.9710\n",
            "Epoch 707/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.1183 - val_accuracy: 0.9710\n",
            "Epoch 708/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.1194 - val_accuracy: 0.9695\n",
            "Epoch 709/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1182 - val_accuracy: 0.9710\n",
            "Epoch 710/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0038 - accuracy: 0.9996 - val_loss: 0.1173 - val_accuracy: 0.9710\n",
            "Epoch 711/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0036 - accuracy: 0.9996 - val_loss: 0.1190 - val_accuracy: 0.9726\n",
            "Epoch 712/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0049 - accuracy: 0.9996 - val_loss: 0.1181 - val_accuracy: 0.9710\n",
            "Epoch 713/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1207 - val_accuracy: 0.9726\n",
            "Epoch 714/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.1179 - val_accuracy: 0.9726\n",
            "Epoch 715/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0050 - accuracy: 0.9996 - val_loss: 0.1158 - val_accuracy: 0.9726\n",
            "Epoch 716/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0045 - accuracy: 0.9996 - val_loss: 0.1178 - val_accuracy: 0.9710\n",
            "Epoch 717/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.1177 - val_accuracy: 0.9741\n",
            "Epoch 718/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0045 - accuracy: 0.9996 - val_loss: 0.1181 - val_accuracy: 0.9726\n",
            "Epoch 719/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.1181 - val_accuracy: 0.9710\n",
            "Epoch 720/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.1172 - val_accuracy: 0.9710\n",
            "Epoch 721/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0050 - accuracy: 0.9992 - val_loss: 0.1177 - val_accuracy: 0.9741\n",
            "Epoch 722/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0040 - accuracy: 0.9996 - val_loss: 0.1163 - val_accuracy: 0.9756\n",
            "Epoch 723/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0046 - accuracy: 0.9996 - val_loss: 0.1167 - val_accuracy: 0.9756\n",
            "Epoch 724/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.1189 - val_accuracy: 0.9726\n",
            "Epoch 725/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0037 - accuracy: 0.9996 - val_loss: 0.1180 - val_accuracy: 0.9741\n",
            "Epoch 726/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.1226 - val_accuracy: 0.9695\n",
            "Epoch 727/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1218 - val_accuracy: 0.9710\n",
            "Epoch 728/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.1180 - val_accuracy: 0.9710\n",
            "Epoch 729/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0046 - accuracy: 0.9996 - val_loss: 0.1198 - val_accuracy: 0.9680\n",
            "Epoch 730/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1181 - val_accuracy: 0.9741\n",
            "Epoch 731/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 0.1163 - val_accuracy: 0.9741\n",
            "Epoch 732/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0041 - accuracy: 0.9996 - val_loss: 0.1205 - val_accuracy: 0.9710\n",
            "Epoch 733/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0045 - accuracy: 0.9996 - val_loss: 0.1185 - val_accuracy: 0.9726\n",
            "Epoch 734/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0038 - accuracy: 0.9996 - val_loss: 0.1181 - val_accuracy: 0.9710\n",
            "Epoch 735/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1166 - val_accuracy: 0.9741\n",
            "Epoch 736/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1128 - val_accuracy: 0.9771\n",
            "Epoch 737/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0051 - accuracy: 0.9996 - val_loss: 0.1130 - val_accuracy: 0.9756\n",
            "Epoch 738/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0052 - accuracy: 0.9996 - val_loss: 0.1159 - val_accuracy: 0.9726\n",
            "Epoch 739/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1194 - val_accuracy: 0.9710\n",
            "Epoch 740/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0045 - accuracy: 0.9996 - val_loss: 0.1182 - val_accuracy: 0.9695\n",
            "Epoch 741/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1169 - val_accuracy: 0.9726\n",
            "Epoch 742/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.1172 - val_accuracy: 0.9695\n",
            "Epoch 743/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1223 - val_accuracy: 0.9710\n",
            "Epoch 744/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0040 - accuracy: 0.9996 - val_loss: 0.1174 - val_accuracy: 0.9710\n",
            "Epoch 745/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1175 - val_accuracy: 0.9710\n",
            "Epoch 746/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0036 - accuracy: 0.9996 - val_loss: 0.1208 - val_accuracy: 0.9710\n",
            "Epoch 747/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0044 - accuracy: 0.9996 - val_loss: 0.1172 - val_accuracy: 0.9710\n",
            "Epoch 748/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0045 - accuracy: 0.9996 - val_loss: 0.1171 - val_accuracy: 0.9726\n",
            "Epoch 749/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.1171 - val_accuracy: 0.9726\n",
            "Epoch 750/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1174 - val_accuracy: 0.9741\n",
            "Epoch 751/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1173 - val_accuracy: 0.9756\n",
            "Epoch 752/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1193 - val_accuracy: 0.9710\n",
            "Epoch 753/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0058 - accuracy: 0.9992 - val_loss: 0.1195 - val_accuracy: 0.9710\n",
            "Epoch 754/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0050 - accuracy: 0.9992 - val_loss: 0.1163 - val_accuracy: 0.9726\n",
            "Epoch 755/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1171 - val_accuracy: 0.9710\n",
            "Epoch 756/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.1169 - val_accuracy: 0.9710\n",
            "Epoch 757/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1164 - val_accuracy: 0.9741\n",
            "Epoch 758/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0033 - accuracy: 0.9996 - val_loss: 0.1209 - val_accuracy: 0.9710\n",
            "Epoch 759/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0043 - accuracy: 0.9996 - val_loss: 0.1185 - val_accuracy: 0.9710\n",
            "Epoch 760/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1204 - val_accuracy: 0.9710\n",
            "Epoch 761/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0042 - accuracy: 0.9996 - val_loss: 0.1187 - val_accuracy: 0.9741\n",
            "Epoch 762/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1210 - val_accuracy: 0.9710\n",
            "Epoch 763/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0040 - accuracy: 0.9996 - val_loss: 0.1185 - val_accuracy: 0.9726\n",
            "Epoch 764/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1197 - val_accuracy: 0.9726\n",
            "Epoch 765/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.1190 - val_accuracy: 0.9726\n",
            "Epoch 766/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.1181 - val_accuracy: 0.9741\n",
            "Epoch 767/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0044 - accuracy: 0.9996 - val_loss: 0.1190 - val_accuracy: 0.9726\n",
            "Epoch 768/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1213 - val_accuracy: 0.9680\n",
            "Epoch 769/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.1190 - val_accuracy: 0.9710\n",
            "Epoch 770/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1207 - val_accuracy: 0.9726\n",
            "Epoch 771/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1185 - val_accuracy: 0.9771\n",
            "Epoch 772/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 0.1206 - val_accuracy: 0.9695\n",
            "Epoch 773/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1213 - val_accuracy: 0.9695\n",
            "Epoch 774/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0030 - accuracy: 0.9996 - val_loss: 0.1214 - val_accuracy: 0.9695\n",
            "Epoch 775/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0053 - accuracy: 0.9992 - val_loss: 0.1161 - val_accuracy: 0.9695\n",
            "Epoch 776/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0046 - accuracy: 0.9996 - val_loss: 0.1177 - val_accuracy: 0.9726\n",
            "Epoch 777/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1188 - val_accuracy: 0.9741\n",
            "Epoch 778/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1202 - val_accuracy: 0.9726\n",
            "Epoch 779/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1177 - val_accuracy: 0.9726\n",
            "Epoch 780/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.1165 - val_accuracy: 0.9741\n",
            "Epoch 781/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0040 - accuracy: 0.9996 - val_loss: 0.1157 - val_accuracy: 0.9741\n",
            "Epoch 782/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0044 - accuracy: 0.9996 - val_loss: 0.1161 - val_accuracy: 0.9741\n",
            "Epoch 783/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0036 - accuracy: 0.9996 - val_loss: 0.1174 - val_accuracy: 0.9726\n",
            "Epoch 784/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1199 - val_accuracy: 0.9726\n",
            "Epoch 785/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0033 - accuracy: 0.9996 - val_loss: 0.1197 - val_accuracy: 0.9726\n",
            "Epoch 786/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0040 - accuracy: 0.9996 - val_loss: 0.1239 - val_accuracy: 0.9710\n",
            "Epoch 787/1000\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0038 - accuracy: 0.9996 - val_loss: 0.1192 - val_accuracy: 0.9741\n",
            "Epoch 788/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0038 - accuracy: 0.9996 - val_loss: 0.1184 - val_accuracy: 0.9726\n",
            "Epoch 789/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.1208 - val_accuracy: 0.9710\n",
            "Epoch 790/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1194 - val_accuracy: 0.9726\n",
            "Epoch 791/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.1208 - val_accuracy: 0.9710\n",
            "Epoch 792/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1194 - val_accuracy: 0.9726\n",
            "Epoch 793/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1207 - val_accuracy: 0.9726\n",
            "Epoch 794/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0039 - accuracy: 0.9996 - val_loss: 0.1203 - val_accuracy: 0.9741\n",
            "Epoch 795/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1203 - val_accuracy: 0.9726\n",
            "Epoch 796/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0036 - accuracy: 0.9996 - val_loss: 0.1205 - val_accuracy: 0.9710\n",
            "Epoch 797/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.1196 - val_accuracy: 0.9741\n",
            "Epoch 798/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0037 - accuracy: 0.9996 - val_loss: 0.1239 - val_accuracy: 0.9710\n",
            "Epoch 799/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0037 - accuracy: 0.9996 - val_loss: 0.1231 - val_accuracy: 0.9710\n",
            "Epoch 800/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.1206 - val_accuracy: 0.9726\n",
            "Epoch 801/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 0.1183 - val_accuracy: 0.9741\n",
            "Epoch 802/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.1172 - val_accuracy: 0.9741\n",
            "Epoch 803/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1208 - val_accuracy: 0.9726\n",
            "Epoch 804/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1213 - val_accuracy: 0.9726\n",
            "Epoch 805/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0031 - accuracy: 0.9996 - val_loss: 0.1212 - val_accuracy: 0.9726\n",
            "Epoch 806/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1203 - val_accuracy: 0.9741\n",
            "Epoch 807/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0040 - accuracy: 0.9996 - val_loss: 0.1241 - val_accuracy: 0.9695\n",
            "Epoch 808/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0041 - accuracy: 0.9996 - val_loss: 0.1172 - val_accuracy: 0.9741\n",
            "Epoch 809/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1199 - val_accuracy: 0.9726\n",
            "Epoch 810/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.1194 - val_accuracy: 0.9726\n",
            "Epoch 811/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0045 - accuracy: 0.9996 - val_loss: 0.1184 - val_accuracy: 0.9741\n",
            "Epoch 812/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1179 - val_accuracy: 0.9726\n",
            "Epoch 813/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.1191 - val_accuracy: 0.9741\n",
            "Epoch 814/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1203 - val_accuracy: 0.9741\n",
            "Epoch 815/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.1217 - val_accuracy: 0.9726\n",
            "Epoch 816/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0039 - accuracy: 0.9996 - val_loss: 0.1218 - val_accuracy: 0.9710\n",
            "Epoch 817/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.1181 - val_accuracy: 0.9756\n",
            "Epoch 818/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0036 - accuracy: 0.9996 - val_loss: 0.1241 - val_accuracy: 0.9710\n",
            "Epoch 819/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1197 - val_accuracy: 0.9726\n",
            "Epoch 820/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1204 - val_accuracy: 0.9741\n",
            "Epoch 821/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.1278 - val_accuracy: 0.9710\n",
            "Epoch 822/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1222 - val_accuracy: 0.9726\n",
            "Epoch 823/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.1193 - val_accuracy: 0.9741\n",
            "Epoch 824/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.1197 - val_accuracy: 0.9726\n",
            "Epoch 825/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.1207 - val_accuracy: 0.9710\n",
            "Epoch 826/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0038 - accuracy: 0.9996 - val_loss: 0.1227 - val_accuracy: 0.9695\n",
            "Epoch 827/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0036 - accuracy: 0.9996 - val_loss: 0.1191 - val_accuracy: 0.9726\n",
            "Epoch 828/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1206 - val_accuracy: 0.9741\n",
            "Epoch 829/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.1209 - val_accuracy: 0.9726\n",
            "Epoch 830/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0037 - accuracy: 0.9996 - val_loss: 0.1224 - val_accuracy: 0.9710\n",
            "Epoch 831/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1192 - val_accuracy: 0.9726\n",
            "Epoch 832/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.1217 - val_accuracy: 0.9695\n",
            "Epoch 833/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1229 - val_accuracy: 0.9726\n",
            "Epoch 834/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.1218 - val_accuracy: 0.9726\n",
            "Epoch 835/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0044 - accuracy: 0.9996 - val_loss: 0.1215 - val_accuracy: 0.9726\n",
            "Epoch 836/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0040 - accuracy: 0.9996 - val_loss: 0.1230 - val_accuracy: 0.9710\n",
            "Epoch 837/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1216 - val_accuracy: 0.9710\n",
            "Epoch 838/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0034 - accuracy: 0.9996 - val_loss: 0.1225 - val_accuracy: 0.9710\n",
            "Epoch 839/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0033 - accuracy: 0.9996 - val_loss: 0.1231 - val_accuracy: 0.9710\n",
            "Epoch 840/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.1221 - val_accuracy: 0.9726\n",
            "Epoch 841/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.1197 - val_accuracy: 0.9710\n",
            "Epoch 842/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0037 - accuracy: 0.9996 - val_loss: 0.1192 - val_accuracy: 0.9741\n",
            "Epoch 843/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0036 - accuracy: 0.9996 - val_loss: 0.1192 - val_accuracy: 0.9726\n",
            "Epoch 844/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0049 - accuracy: 0.9992 - val_loss: 0.1202 - val_accuracy: 0.9726\n",
            "Epoch 845/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.1217 - val_accuracy: 0.9741\n",
            "Epoch 846/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0043 - accuracy: 0.9996 - val_loss: 0.1211 - val_accuracy: 0.9741\n",
            "Epoch 847/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.1209 - val_accuracy: 0.9741\n",
            "Epoch 848/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.1200 - val_accuracy: 0.9741\n",
            "Epoch 849/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0032 - accuracy: 0.9996 - val_loss: 0.1220 - val_accuracy: 0.9710\n",
            "Epoch 850/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1224 - val_accuracy: 0.9710\n",
            "Epoch 851/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.1208 - val_accuracy: 0.9741\n",
            "Epoch 852/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.1221 - val_accuracy: 0.9710\n",
            "Epoch 853/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.1208 - val_accuracy: 0.9695\n",
            "Epoch 854/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0037 - accuracy: 0.9996 - val_loss: 0.1218 - val_accuracy: 0.9741\n",
            "Epoch 855/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0040 - accuracy: 0.9996 - val_loss: 0.1198 - val_accuracy: 0.9726\n",
            "Epoch 856/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0036 - accuracy: 0.9996 - val_loss: 0.1211 - val_accuracy: 0.9695\n",
            "Epoch 857/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.1188 - val_accuracy: 0.9726\n",
            "Epoch 858/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1205 - val_accuracy: 0.9726\n",
            "Epoch 859/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1196 - val_accuracy: 0.9726\n",
            "Epoch 860/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1229 - val_accuracy: 0.9710\n",
            "Epoch 861/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1219 - val_accuracy: 0.9726\n",
            "Epoch 862/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1216 - val_accuracy: 0.9726\n",
            "Epoch 863/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1203 - val_accuracy: 0.9726\n",
            "Epoch 864/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.1201 - val_accuracy: 0.9726\n",
            "Epoch 865/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0035 - accuracy: 0.9996 - val_loss: 0.1199 - val_accuracy: 0.9726\n",
            "Epoch 866/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0033 - accuracy: 0.9996 - val_loss: 0.1218 - val_accuracy: 0.9726\n",
            "Epoch 867/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1212 - val_accuracy: 0.9741\n",
            "Epoch 868/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0035 - accuracy: 0.9996 - val_loss: 0.1239 - val_accuracy: 0.9710\n",
            "Epoch 869/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0044 - accuracy: 0.9996 - val_loss: 0.1217 - val_accuracy: 0.9710\n",
            "Epoch 870/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1206 - val_accuracy: 0.9726\n",
            "Epoch 871/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0036 - accuracy: 0.9996 - val_loss: 0.1211 - val_accuracy: 0.9726\n",
            "Epoch 872/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.1235 - val_accuracy: 0.9695\n",
            "Epoch 873/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1218 - val_accuracy: 0.9726\n",
            "Epoch 874/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1235 - val_accuracy: 0.9695\n",
            "Epoch 875/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0038 - accuracy: 0.9996 - val_loss: 0.1222 - val_accuracy: 0.9741\n",
            "Epoch 876/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.1199 - val_accuracy: 0.9726\n",
            "Epoch 877/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.1219 - val_accuracy: 0.9710\n",
            "Epoch 878/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1215 - val_accuracy: 0.9726\n",
            "Epoch 879/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.1220 - val_accuracy: 0.9710\n",
            "Epoch 880/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.1219 - val_accuracy: 0.9726\n",
            "Epoch 881/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0038 - accuracy: 0.9996 - val_loss: 0.1183 - val_accuracy: 0.9741\n",
            "Epoch 882/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0032 - accuracy: 0.9996 - val_loss: 0.1202 - val_accuracy: 0.9726\n",
            "Epoch 883/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.1206 - val_accuracy: 0.9726\n",
            "Epoch 884/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1206 - val_accuracy: 0.9741\n",
            "Epoch 885/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.1211 - val_accuracy: 0.9710\n",
            "Epoch 886/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.1207 - val_accuracy: 0.9710\n",
            "Epoch 887/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1230 - val_accuracy: 0.9695\n",
            "Epoch 888/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0035 - accuracy: 0.9996 - val_loss: 0.1231 - val_accuracy: 0.9695\n",
            "Epoch 889/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1224 - val_accuracy: 0.9710\n",
            "Epoch 890/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.1222 - val_accuracy: 0.9710\n",
            "Epoch 891/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1196 - val_accuracy: 0.9756\n",
            "Epoch 892/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0050 - accuracy: 0.9992 - val_loss: 0.1184 - val_accuracy: 0.9726\n",
            "Epoch 893/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.1181 - val_accuracy: 0.9756\n",
            "Epoch 894/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1199 - val_accuracy: 0.9741\n",
            "Epoch 895/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.1209 - val_accuracy: 0.9710\n",
            "Epoch 896/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1217 - val_accuracy: 0.9726\n",
            "Epoch 897/1000\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.1224 - val_accuracy: 0.9710\n",
            "Epoch 898/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.1209 - val_accuracy: 0.9741\n",
            "Epoch 899/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0033 - accuracy: 0.9996 - val_loss: 0.1245 - val_accuracy: 0.9695\n",
            "Epoch 900/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.1234 - val_accuracy: 0.9710\n",
            "Epoch 901/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1225 - val_accuracy: 0.9726\n",
            "Epoch 902/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.1223 - val_accuracy: 0.9710\n",
            "Epoch 903/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1217 - val_accuracy: 0.9741\n",
            "Epoch 904/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.1234 - val_accuracy: 0.9710\n",
            "Epoch 905/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.1220 - val_accuracy: 0.9726\n",
            "Epoch 906/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.1239 - val_accuracy: 0.9726\n",
            "Epoch 907/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1239 - val_accuracy: 0.9741\n",
            "Epoch 908/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0032 - accuracy: 0.9996 - val_loss: 0.1245 - val_accuracy: 0.9726\n",
            "Epoch 909/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0031 - accuracy: 0.9996 - val_loss: 0.1248 - val_accuracy: 0.9695\n",
            "Epoch 910/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0034 - accuracy: 0.9996 - val_loss: 0.1229 - val_accuracy: 0.9741\n",
            "Epoch 911/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1223 - val_accuracy: 0.9741\n",
            "Epoch 912/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0030 - accuracy: 0.9996 - val_loss: 0.1265 - val_accuracy: 0.9726\n",
            "Epoch 913/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.1221 - val_accuracy: 0.9726\n",
            "Epoch 914/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1246 - val_accuracy: 0.9726\n",
            "Epoch 915/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.1268 - val_accuracy: 0.9710\n",
            "Epoch 916/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1231 - val_accuracy: 0.9726\n",
            "Epoch 917/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0035 - accuracy: 0.9996 - val_loss: 0.1226 - val_accuracy: 0.9741\n",
            "Epoch 918/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.1252 - val_accuracy: 0.9710\n",
            "Epoch 919/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.1236 - val_accuracy: 0.9741\n",
            "Epoch 920/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.1261 - val_accuracy: 0.9726\n",
            "Epoch 921/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0036 - accuracy: 0.9996 - val_loss: 0.1246 - val_accuracy: 0.9726\n",
            "Epoch 922/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1248 - val_accuracy: 0.9741\n",
            "Epoch 923/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1255 - val_accuracy: 0.9710\n",
            "Epoch 924/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.1239 - val_accuracy: 0.9726\n",
            "Epoch 925/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1233 - val_accuracy: 0.9726\n",
            "Epoch 926/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.1224 - val_accuracy: 0.9726\n",
            "Epoch 927/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0038 - accuracy: 0.9996 - val_loss: 0.1222 - val_accuracy: 0.9726\n",
            "Epoch 928/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0034 - accuracy: 0.9996 - val_loss: 0.1231 - val_accuracy: 0.9741\n",
            "Epoch 929/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1264 - val_accuracy: 0.9726\n",
            "Epoch 930/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0039 - accuracy: 0.9996 - val_loss: 0.1232 - val_accuracy: 0.9756\n",
            "Epoch 931/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0038 - accuracy: 0.9996 - val_loss: 0.1223 - val_accuracy: 0.9741\n",
            "Epoch 932/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0029 - accuracy: 0.9996 - val_loss: 0.1259 - val_accuracy: 0.9726\n",
            "Epoch 933/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0031 - accuracy: 0.9996 - val_loss: 0.1243 - val_accuracy: 0.9726\n",
            "Epoch 934/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0034 - accuracy: 0.9996 - val_loss: 0.1216 - val_accuracy: 0.9726\n",
            "Epoch 935/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1233 - val_accuracy: 0.9726\n",
            "Epoch 936/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0029 - accuracy: 0.9996 - val_loss: 0.1253 - val_accuracy: 0.9726\n",
            "Epoch 937/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1268 - val_accuracy: 0.9726\n",
            "Epoch 938/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1258 - val_accuracy: 0.9726\n",
            "Epoch 939/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0029 - accuracy: 0.9996 - val_loss: 0.1267 - val_accuracy: 0.9741\n",
            "Epoch 940/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.1254 - val_accuracy: 0.9726\n",
            "Epoch 941/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1222 - val_accuracy: 0.9726\n",
            "Epoch 942/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0036 - accuracy: 0.9996 - val_loss: 0.1268 - val_accuracy: 0.9680\n",
            "Epoch 943/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1258 - val_accuracy: 0.9726\n",
            "Epoch 944/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1247 - val_accuracy: 0.9726\n",
            "Epoch 945/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.1249 - val_accuracy: 0.9726\n",
            "Epoch 946/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.1249 - val_accuracy: 0.9726\n",
            "Epoch 947/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0029 - accuracy: 0.9996 - val_loss: 0.1265 - val_accuracy: 0.9726\n",
            "Epoch 948/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1269 - val_accuracy: 0.9726\n",
            "Epoch 949/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.1234 - val_accuracy: 0.9710\n",
            "Epoch 950/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.1249 - val_accuracy: 0.9741\n",
            "Epoch 951/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0038 - accuracy: 0.9996 - val_loss: 0.1253 - val_accuracy: 0.9726\n",
            "Epoch 952/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1248 - val_accuracy: 0.9726\n",
            "Epoch 953/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1235 - val_accuracy: 0.9726\n",
            "Epoch 954/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0034 - accuracy: 0.9996 - val_loss: 0.1234 - val_accuracy: 0.9726\n",
            "Epoch 955/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0032 - accuracy: 0.9996 - val_loss: 0.1234 - val_accuracy: 0.9741\n",
            "Epoch 956/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1233 - val_accuracy: 0.9741\n",
            "Epoch 957/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0042 - accuracy: 0.9996 - val_loss: 0.1261 - val_accuracy: 0.9710\n",
            "Epoch 958/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0032 - accuracy: 0.9996 - val_loss: 0.1260 - val_accuracy: 0.9710\n",
            "Epoch 959/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.1261 - val_accuracy: 0.9710\n",
            "Epoch 960/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0038 - accuracy: 0.9996 - val_loss: 0.1246 - val_accuracy: 0.9710\n",
            "Epoch 961/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1250 - val_accuracy: 0.9741\n",
            "Epoch 962/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.1220 - val_accuracy: 0.9741\n",
            "Epoch 963/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1227 - val_accuracy: 0.9756\n",
            "Epoch 964/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1265 - val_accuracy: 0.9741\n",
            "Epoch 965/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.1255 - val_accuracy: 0.9741\n",
            "Epoch 966/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1260 - val_accuracy: 0.9710\n",
            "Epoch 967/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.1243 - val_accuracy: 0.9741\n",
            "Epoch 968/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.1245 - val_accuracy: 0.9741\n",
            "Epoch 969/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1258 - val_accuracy: 0.9710\n",
            "Epoch 970/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1252 - val_accuracy: 0.9741\n",
            "Epoch 971/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0032 - accuracy: 0.9996 - val_loss: 0.1269 - val_accuracy: 0.9695\n",
            "Epoch 972/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0031 - accuracy: 0.9996 - val_loss: 0.1274 - val_accuracy: 0.9710\n",
            "Epoch 973/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0037 - accuracy: 0.9996 - val_loss: 0.1251 - val_accuracy: 0.9710\n",
            "Epoch 974/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.1240 - val_accuracy: 0.9726\n",
            "Epoch 975/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1243 - val_accuracy: 0.9741\n",
            "Epoch 976/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.1256 - val_accuracy: 0.9726\n",
            "Epoch 977/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1281 - val_accuracy: 0.9680\n",
            "Epoch 978/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0031 - accuracy: 0.9996 - val_loss: 0.1275 - val_accuracy: 0.9710\n",
            "Epoch 979/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1268 - val_accuracy: 0.9726\n",
            "Epoch 980/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0031 - accuracy: 0.9996 - val_loss: 0.1274 - val_accuracy: 0.9741\n",
            "Epoch 981/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0028 - accuracy: 0.9996 - val_loss: 0.1280 - val_accuracy: 0.9741\n",
            "Epoch 982/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0029 - accuracy: 0.9996 - val_loss: 0.1279 - val_accuracy: 0.9695\n",
            "Epoch 983/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1275 - val_accuracy: 0.9710\n",
            "Epoch 984/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1285 - val_accuracy: 0.9726\n",
            "Epoch 985/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.1306 - val_accuracy: 0.9710\n",
            "Epoch 986/1000\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.1255 - val_accuracy: 0.9726\n",
            "Epoch 987/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1268 - val_accuracy: 0.9710\n",
            "Epoch 988/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.1251 - val_accuracy: 0.9710\n",
            "Epoch 989/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1261 - val_accuracy: 0.9726\n",
            "Epoch 990/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1278 - val_accuracy: 0.9710\n",
            "Epoch 991/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.1274 - val_accuracy: 0.9726\n",
            "Epoch 992/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0032 - accuracy: 0.9996 - val_loss: 0.1253 - val_accuracy: 0.9741\n",
            "Epoch 993/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.1280 - val_accuracy: 0.9710\n",
            "Epoch 994/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0028 - accuracy: 0.9996 - val_loss: 0.1267 - val_accuracy: 0.9710\n",
            "Epoch 995/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0032 - accuracy: 0.9996 - val_loss: 0.1249 - val_accuracy: 0.9756\n",
            "Epoch 996/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0039 - accuracy: 0.9996 - val_loss: 0.1259 - val_accuracy: 0.9710\n",
            "Epoch 997/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0032 - accuracy: 0.9996 - val_loss: 0.1252 - val_accuracy: 0.9710\n",
            "Epoch 998/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.1256 - val_accuracy: 0.9741\n",
            "Epoch 999/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0032 - accuracy: 0.9996 - val_loss: 0.1254 - val_accuracy: 0.9726\n",
            "Epoch 1000/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0035 - accuracy: 0.9996 - val_loss: 0.1275 - val_accuracy: 0.9710\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.predict(validation_data)\n",
        "predictions = [i.argmax() for i in preds]\n",
        "y_true = [i.argmax() for i in validation_labels]\n",
        "print('Accuracy {}'.format(accuracy_score(y_true=y_true, y_pred=predictions)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckJ0J6veTiG9",
        "outputId": "5e2c638f-a51e-4a5c-aa10-8630fecc73be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.9710365853658537\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.predict(test_data)\n",
        "\n",
        "predictions = [i.argmax() for i in preds]\n",
        "y_true = [i.argmax() for i in test_labels]\n",
        "#cm = confusion_matrix(y_pred=predictions, y_true=y_true)\n",
        "\n",
        "print('Accuracy {}'.format(accuracy_score(y_true=y_true, y_pred=predictions)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sg9ETz8ETjgl",
        "outputId": "fd59ebaa-5ef0-4cfc-f7e1-489a0ca40f4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.9735449735449735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/My_projects _and _datasets/IDRID_detection/DenseNet121_upto15frozen.h5')\n",
        "model.save_weights('/content/drive/MyDrive/My_projects _and _datasets/IDRID_detection/DenseNet121_upto15frozen_weights.h5')"
      ],
      "metadata": {
        "id": "_ZB16Xa3Ve1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model=load_model('/content/drive/MyDrive/My_projects _and _datasets/IDRID_detection/DenseNet121_upto15frozen.h5',compile=False)\n",
        "loaded_model.load_weights('/content/drive/MyDrive/My_projects _and _datasets/IDRID_detection/DenseNet121_upto15frozen_weights.h5')"
      ],
      "metadata": {
        "id": "0wZjYWO_VshY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train','Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "HgtG9cMrV3Ai",
        "outputId": "8ca01234-6bce-4081-dbba-af3ff751fe24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train','Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "uOkERAykV9XJ",
        "outputId": "2bc368c3-ad5a-443b-bac8-f9fad9b1c199"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report \n",
        "import seaborn as sns\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "0miOKhEgWDH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = loaded_model.predict(test_data)\n",
        "\n",
        "y_pred = [i.argmax() for i in preds]\n",
        "y_true = [i.argmax() for i in test_labels]\n",
        "cm = confusion_matrix(y_pred=y_pred, y_true=y_true)\n",
        "\n",
        "print('Test Accuracy={}'.format(accuracy_score(y_true=y_true, y_pred=y_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbn9Vk0gWPTJ",
        "outputId": "44256461-4d55-4b37-ec7a-f4db806454bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy=0.9735449735449735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('CONFUSION MATRIX')\n",
        "conf_matrix = pd.DataFrame(data = cm,  \n",
        "                           columns = ['with_DR','without_DR'],  \n",
        "                           index =['with_DR','without_DR']) \n",
        "\n",
        "accuracy = np.trace(cm) / float(np.sum(cm))\n",
        "misclass = 1 - accuracy\n",
        "plt.figure(figsize = (10,8)) \n",
        "sns.heatmap(conf_matrix, annot = True, fmt = 'd', cmap = \"Blues\") \n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
        "plt.show() \n",
        "\n",
        "target_names=['with_DR','without_DR']\n",
        "print('The details for confusion matrix is =') \n",
        "print (classification_report(y_true, y_pred,target_names=target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "id": "BZfe3Z-zWYHI",
        "outputId": "b80cf741-fd9b-4da7-c0c5-d84c52bea7f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFUSION MATRIX\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The details for confusion matrix is =\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     with_DR       0.97      0.97      0.97       181\n",
            "  without_DR       0.97      0.97      0.97       197\n",
            "\n",
            "    accuracy                           0.97       378\n",
            "   macro avg       0.97      0.97      0.97       378\n",
            "weighted avg       0.97      0.97      0.97       378\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sensitivity = cm[0,0]/(cm[0,0]+cm[1,0])\n",
        "print('Sensitivity : ', sensitivity*100 )\n",
        "\n",
        "Specificity = cm[1,1]/(cm[1,1]+cm[0,1])\n",
        "print('Specificity : ', Specificity*100 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6GI5lq-We9L",
        "outputId": "1592bc4c-2ddb-465f-8938-8e5c46050711"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sensitivity :  97.23756906077348\n",
            "Specificity :  97.46192893401016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "cFJ3mgQwWlW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = loaded_model.predict(validation_data)\n",
        "predictions = [i.argmax() for i in preds]\n",
        "y_true = [i.argmax() for i in validation_labels]\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkxIPmSiWy0R",
        "outputId": "21b9368d-a066-42ff-a91b-ee88aa1e30a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_df=pd.read_csv('/content/drive/MyDrive/My_projects _and _datasets/Final_work/Binary_prediction - Sheet1.csv')\n",
        "val_df['DenseNet121']=predictions\n",
        "val_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "vROu1aVzW15D",
        "outputId": "a20db90d-a42a-4b0d-85ba-6d9a64ef5b34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0  Unnamed: 0.1  True Label  vgg16  xception  DenseNet121\n",
              "0             0             0           0      0         0            0\n",
              "1             1             1           0      0         0            0\n",
              "2             2             2           0      0         0            0\n",
              "3             3             3           0      0         0            1\n",
              "4             4             4           0      0         0            0\n",
              "..          ...           ...         ...    ...       ...          ...\n",
              "651         651           651           1      1         1            1\n",
              "652         652           652           1      1         1            1\n",
              "653         653           653           1      1         1            1\n",
              "654         654           654           1      1         1            1\n",
              "655         655           655           1      1         1            1\n",
              "\n",
              "[656 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eb4998bd-086a-4150-ade8-a307b46ed5b8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>True Label</th>\n",
              "      <th>vgg16</th>\n",
              "      <th>xception</th>\n",
              "      <th>DenseNet121</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>651</th>\n",
              "      <td>651</td>\n",
              "      <td>651</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>652</th>\n",
              "      <td>652</td>\n",
              "      <td>652</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>653</th>\n",
              "      <td>653</td>\n",
              "      <td>653</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>654</th>\n",
              "      <td>654</td>\n",
              "      <td>654</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>655</th>\n",
              "      <td>655</td>\n",
              "      <td>655</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>656 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb4998bd-086a-4150-ade8-a307b46ed5b8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eb4998bd-086a-4150-ade8-a307b46ed5b8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eb4998bd-086a-4150-ade8-a307b46ed5b8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_df.to_csv('/content/drive/MyDrive/My_projects _and _datasets/Final_work/Binary_prediction - Sheet1.csv')"
      ],
      "metadata": {
        "id": "biRTAdPFW93C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df=pd.read_csv('/content/drive/MyDrive/My_projects _and _datasets/Final_work/Binary_confidence_matrix - Sheet1.csv')\n",
        "preds = loaded_model.predict(test_data)\n",
        "for i in range(0,2):\n",
        "  test_df['DenseNet121_class'+str(i)]=preds[:,i]"
      ],
      "metadata": {
        "id": "gdIcIDc_XNp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "paKyKC2VXPzP",
        "outputId": "2d861d59-51ee-45ab-f7ad-de7d0f9c75f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0  Unnamed: 0.1  True Label  vgg16_class0  vgg16_class1  \\\n",
              "0             0             0           0      1.000000  3.271071e-08   \n",
              "1             1             1           0      0.650171  3.464978e-01   \n",
              "2             2             2           0      0.999786  1.910670e-04   \n",
              "3             3             3           0      0.999226  7.497075e-04   \n",
              "4             4             4           0      1.000000  9.023950e-08   \n",
              "..          ...           ...         ...           ...           ...   \n",
              "373         373           373           1      0.000005  9.999956e-01   \n",
              "374         374           374           1      0.000115  9.999150e-01   \n",
              "375         375           375           1      0.000070  9.999461e-01   \n",
              "376         376           376           1      0.000016  9.999875e-01   \n",
              "377         377           377           1      0.000024  9.999841e-01   \n",
              "\n",
              "     xception_class0  xception_class1  DenseNet121_class0  DenseNet121_class1  \n",
              "0       9.999988e-01     1.115273e-06        9.820170e-01        1.637366e-02  \n",
              "1       9.999999e-01     2.007653e-07        9.999959e-01        3.717736e-06  \n",
              "2       1.000000e+00     7.120615e-14        1.000000e+00        4.247402e-09  \n",
              "3       9.805162e-01     1.904154e-02        9.609939e-01        4.056131e-02  \n",
              "4       1.000000e+00     8.365292e-09        1.000000e+00        4.018924e-11  \n",
              "..               ...              ...                 ...                 ...  \n",
              "373     8.094603e-12     1.000000e+00        3.967403e-07        9.999998e-01  \n",
              "374     4.629031e-05     9.999508e-01        1.524401e-05        9.999863e-01  \n",
              "375     6.023692e-06     9.999930e-01        2.297094e-04        9.998475e-01  \n",
              "376     7.922729e-09     1.000000e+00        4.790058e-06        9.999969e-01  \n",
              "377     2.996096e-05     9.999675e-01        7.265744e-06        9.999924e-01  \n",
              "\n",
              "[378 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5456a55d-dd68-44c9-ae09-842895a6782b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>True Label</th>\n",
              "      <th>vgg16_class0</th>\n",
              "      <th>vgg16_class1</th>\n",
              "      <th>xception_class0</th>\n",
              "      <th>xception_class1</th>\n",
              "      <th>DenseNet121_class0</th>\n",
              "      <th>DenseNet121_class1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.271071e-08</td>\n",
              "      <td>9.999988e-01</td>\n",
              "      <td>1.115273e-06</td>\n",
              "      <td>9.820170e-01</td>\n",
              "      <td>1.637366e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.650171</td>\n",
              "      <td>3.464978e-01</td>\n",
              "      <td>9.999999e-01</td>\n",
              "      <td>2.007653e-07</td>\n",
              "      <td>9.999959e-01</td>\n",
              "      <td>3.717736e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.999786</td>\n",
              "      <td>1.910670e-04</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>7.120615e-14</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>4.247402e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.999226</td>\n",
              "      <td>7.497075e-04</td>\n",
              "      <td>9.805162e-01</td>\n",
              "      <td>1.904154e-02</td>\n",
              "      <td>9.609939e-01</td>\n",
              "      <td>4.056131e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>9.023950e-08</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>8.365292e-09</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>4.018924e-11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>373</th>\n",
              "      <td>373</td>\n",
              "      <td>373</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>9.999956e-01</td>\n",
              "      <td>8.094603e-12</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>3.967403e-07</td>\n",
              "      <td>9.999998e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>374</th>\n",
              "      <td>374</td>\n",
              "      <td>374</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000115</td>\n",
              "      <td>9.999150e-01</td>\n",
              "      <td>4.629031e-05</td>\n",
              "      <td>9.999508e-01</td>\n",
              "      <td>1.524401e-05</td>\n",
              "      <td>9.999863e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375</th>\n",
              "      <td>375</td>\n",
              "      <td>375</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000070</td>\n",
              "      <td>9.999461e-01</td>\n",
              "      <td>6.023692e-06</td>\n",
              "      <td>9.999930e-01</td>\n",
              "      <td>2.297094e-04</td>\n",
              "      <td>9.998475e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>376</th>\n",
              "      <td>376</td>\n",
              "      <td>376</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>9.999875e-01</td>\n",
              "      <td>7.922729e-09</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>4.790058e-06</td>\n",
              "      <td>9.999969e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>377</th>\n",
              "      <td>377</td>\n",
              "      <td>377</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>9.999841e-01</td>\n",
              "      <td>2.996096e-05</td>\n",
              "      <td>9.999675e-01</td>\n",
              "      <td>7.265744e-06</td>\n",
              "      <td>9.999924e-01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>378 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5456a55d-dd68-44c9-ae09-842895a6782b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5456a55d-dd68-44c9-ae09-842895a6782b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5456a55d-dd68-44c9-ae09-842895a6782b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.to_csv('/content/drive/MyDrive/My_projects _and _datasets/Final_work/Binary_confidence_matrix - Sheet1.csv')"
      ],
      "metadata": {
        "id": "_IHgZi5GXeIu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}