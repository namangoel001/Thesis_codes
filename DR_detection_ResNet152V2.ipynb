{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DR_detection_ResNet152V2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYPHztwnrUMX",
        "outputId": "558cafbf-8fed-4a4a-fc90-af630c4c2bdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from os.path import basename, join, exists"
      ],
      "metadata": {
        "id": "mBqFvfVwrd2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder=r\"/content/drive/MyDrive/My_projects _and _datasets/Final_work/APTOS/Train/\"\n",
        "total=0\n",
        "print('---Training set details----')\n",
        "for sub_folder in os.listdir(folder):\n",
        "  no_of_images=len(os.listdir(folder + sub_folder))\n",
        "  total+=no_of_images\n",
        "  print(str(no_of_images) + \" \" + sub_folder + \" images\")\n",
        "\n",
        "print(\"Total no. of images \",total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I92Fi-fTriDp",
        "outputId": "8867f6e0-9444-4a18-cf1d-d4f8708ee404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---Training set details----\n",
            "1676 with_DR images\n",
            "1608 without_DR images\n",
            "Total no. of images  3284\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folder=r\"/content/drive/MyDrive/My_projects _and _datasets/Final_work/APTOS/Test/\"\n",
        "total=0\n",
        "print('---Test set details----')\n",
        "for sub_folder in os.listdir(folder):\n",
        "  no_of_images=len(os.listdir(folder + sub_folder))\n",
        "  total+=no_of_images\n",
        "  print(str(no_of_images) + \" \" + sub_folder + \" images\")\n",
        "\n",
        "print(\"Total no. of images\",total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FP2EGdssr7hY",
        "outputId": "16bc2ce8-7286-48e5-cb79-50f858016b46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---Test set details----\n",
            "181 with_DR images\n",
            "197 without_DR images\n",
            "Total no. of images 378\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.random.seed(777)\n",
        "import time\n",
        "import keras as keras\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.vgg16 import decode_predictions\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Activation,Flatten\n",
        "from keras.layers import merge,Input\n",
        "from keras.models import Model\n",
        "from keras.utils import np_utils\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.applications.resnet_v2 import ResNet152V2\n",
        "from keras.applications.xception import Xception\n",
        "from keras.applications.vgg16 import preprocess_input as pi_vgg16\n",
        "from keras.applications.inception_v3 import preprocess_input as pi_incep\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input as pi_resnet\n",
        "from keras.applications.vgg19 import preprocess_input as pi_vgg19\n",
        "from keras.applications.xception import preprocess_input as pi_xcep \n",
        "from keras.models import load_model\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from sklearn.metrics import accuracy_score\n",
        "from  numpy import mean \n",
        "from numpy import std\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.optimizers import Adam,SGD\n",
        "from keras.callbacks import ReduceLROnPlateau,EarlyStopping,ModelCheckpoint\n",
        "from keras.layers import GlobalAveragePooling2D, Concatenate\n",
        "from keras.layers import BatchNormalization,Dropout\n",
        "from keras.layers import Lambda\n",
        "from keras.regularizers import l2\n",
        "import math\n",
        "from keras import backend as K\n",
        "from keras.metrics import categorical_accuracy\n",
        "import warnings\n",
        "warnings.filterwarnings('always')\n",
        "warnings.filterwarnings('ignore')\n",
        "from keras.models import load_model\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "qJyQy_Amr-bW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_height =224\n",
        "img_width = 224\n",
        "batch_size =32\n",
        "input_shape = (img_width, img_height, 3)"
      ],
      "metadata": {
        "id": "-kySi1fxsDWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_seed = np.random.seed(1142)\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    featurewise_center=True,\n",
        "    featurewise_std_normalization=True,\n",
        "    validation_split= 0.2,\n",
        "    zoom_range=0.2)\n",
        "    #shear_range=0.2)\n",
        "\n",
        "train_generator_Excep = train_datagen.flow_from_directory(\n",
        "    \"/content/drive/MyDrive/My_projects _and _datasets/Final_work/APTOS/Train/\",\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    seed = random_seed,\n",
        "    shuffle=False,\n",
        "    subset = 'training',\n",
        "    class_mode='binary')\n",
        "\n",
        "val_generator_Excep = train_datagen.flow_from_directory(\n",
        "    \"/content/drive/MyDrive/My_projects _and _datasets/Final_work/APTOS/Train/\",\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    seed = random_seed,\n",
        "    shuffle=False,\n",
        "    subset = 'validation',\n",
        "    class_mode='binary')\n",
        "test_datagen=ImageDataGenerator(rescale=1./255)\n",
        "test_generator_Excep=test_datagen.flow_from_directory(\"/content/drive/MyDrive/My_projects _and _datasets/Final_work/APTOS/Test/\",\n",
        "                                                      target_size=(img_height, img_width),\n",
        "                                                          batch_size=batch_size, \n",
        "                                                          seed=random_seed,\n",
        "                                                          shuffle=False,\n",
        "                                                          class_mode='binary') # set as training data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqoYrawzsLkW",
        "outputId": "2096d9dd-5bcc-47ea-c30f-be67b7889ec7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2628 images belonging to 2 classes.\n",
            "Found 656 images belonging to 2 classes.\n",
            "Found 378 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nb_train_samples = len(train_generator_Excep.filenames)\n",
        "nb_validation_samples = len(val_generator_Excep.filenames)\n",
        "predict_size_train = int(math.ceil(nb_train_samples / batch_size))\n",
        "predict_size_validation = int(math.ceil(nb_validation_samples / batch_size))\n",
        "\n",
        "nb_test_samples = len(test_generator_Excep.filenames)\n",
        "predict_size_test = int(math.ceil(nb_test_samples / batch_size))\n",
        "print(nb_train_samples)\n",
        "print(nb_validation_samples)\n",
        "print(nb_test_samples)\n",
        "print(predict_size_train)\n",
        "print(predict_size_validation)\n",
        "print(predict_size_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Py1NEuNMsQyR",
        "outputId": "ad656a58-08ff-403a-8473-87b3e188103b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2628\n",
            "656\n",
            "378\n",
            "83\n",
            "21\n",
            "12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name=\"ResNet152V2\"\n",
        "model = ResNet152V2(include_top=False, weights=\"imagenet\",pooling='avg',input_tensor=Input(shape=input_shape))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ep1CR0SfsUGu",
        "outputId": "cb5b12de-4efa-40d7-ad46-8bf282016902"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "234553344/234545216 [==============================] - 10s 0us/step\n",
            "234561536/234545216 [==============================] - 10s 0us/step\n",
            "Model: \"resnet152v2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_conv[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv2_block1_preact_bn (BatchN  (None, 56, 56, 64)  256         ['pool1_pool[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2_block1_preact_relu (Acti  (None, 56, 56, 64)  0           ['conv2_block1_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4096        ['conv2_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block1_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36864       ['conv2_block1_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_out (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_conv[0][0]',    \n",
            "                                                                  'conv2_block1_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_preact_bn (BatchN  (None, 56, 56, 256)  1024       ['conv2_block1_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2_block2_preact_relu (Acti  (None, 56, 56, 256)  0          ['conv2_block2_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16384       ['conv2_block2_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block2_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36864       ['conv2_block2_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_out (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
            "                                                                  'conv2_block2_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_preact_bn (BatchN  (None, 56, 56, 256)  1024       ['conv2_block2_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2_block3_preact_relu (Acti  (None, 56, 56, 256)  0          ['conv2_block3_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16384       ['conv2_block3_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block3_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 28, 28, 64)   36864       ['conv2_block3_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, 28, 28, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, 28, 28, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 28, 28, 256)  0           ['conv2_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, 28, 28, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_out (Add)         (None, 28, 28, 256)  0           ['max_pooling2d[0][0]',          \n",
            "                                                                  'conv2_block3_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_preact_bn (BatchN  (None, 28, 28, 256)  1024       ['conv2_block3_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block1_preact_relu (Acti  (None, 28, 28, 256)  0          ['conv3_block1_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32768       ['conv3_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block1_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block1_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv3_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_out (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_conv[0][0]',    \n",
            "                                                                  'conv3_block1_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block1_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block2_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block2_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block2_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block2_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block2_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_out (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
            "                                                                  'conv3_block2_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block2_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block3_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block3_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block3_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block3_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block3_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_out (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
            "                                                                  'conv3_block3_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block3_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block4_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block4_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block4_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block4_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block4_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_out (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',       \n",
            "                                                                  'conv3_block4_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block5_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block4_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block5_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block5_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block5_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block5_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block5_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block5_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block5_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block5_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block5_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block5_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block5_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block5_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block5_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block5_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block5_out (Add)         (None, 28, 28, 512)  0           ['conv3_block4_out[0][0]',       \n",
            "                                                                  'conv3_block5_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block6_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block5_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block6_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block6_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block6_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block6_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block6_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block6_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block6_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block6_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block6_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block6_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block6_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block6_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block6_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block6_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block6_out (Add)         (None, 28, 28, 512)  0           ['conv3_block5_out[0][0]',       \n",
            "                                                                  'conv3_block6_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block7_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block6_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block7_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block7_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block7_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block7_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block7_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block7_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block7_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block7_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block7_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block7_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block7_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block7_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block7_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block7_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block7_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block7_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block7_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block7_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block7_out (Add)         (None, 28, 28, 512)  0           ['conv3_block6_out[0][0]',       \n",
            "                                                                  'conv3_block7_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block8_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block7_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block8_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block8_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block8_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block8_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block8_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block8_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block8_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block8_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block8_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block8_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block8_2_conv (Conv2D)   (None, 14, 14, 128)  147456      ['conv3_block8_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block8_2_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv3_block8_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block8_2_relu (Activatio  (None, 14, 14, 128)  0          ['conv3_block8_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 14, 14, 512)  0          ['conv3_block7_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block8_3_conv (Conv2D)   (None, 14, 14, 512)  66048       ['conv3_block8_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block8_out (Add)         (None, 14, 14, 512)  0           ['max_pooling2d_1[0][0]',        \n",
            "                                                                  'conv3_block8_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_preact_bn (BatchN  (None, 14, 14, 512)  2048       ['conv3_block8_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block1_preact_relu (Acti  (None, 14, 14, 512)  0          ['conv4_block1_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131072      ['conv4_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block1_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block1_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv4_block1_preact_relu[0][0]'\n",
            "                                )                                ]                                \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_out (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_conv[0][0]',    \n",
            "                                )                                 'conv4_block1_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block1_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block2_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block2_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block2_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block2_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_out (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
            "                                )                                 'conv4_block2_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block2_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block3_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block3_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block3_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block3_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_out (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
            "                                )                                 'conv4_block3_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block3_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block4_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block4_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block4_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block4_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_out (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
            "                                )                                 'conv4_block4_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block4_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block5_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block5_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block5_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block5_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_out (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
            "                                )                                 'conv4_block5_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block5_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block6_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block6_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block6_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block6_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_out (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
            "                                )                                 'conv4_block6_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block7_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block6_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block7_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block7_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block7_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block7_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block7_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block7_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block7_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block7_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block7_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block7_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block7_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block7_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block7_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block7_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block7_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block7_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block7_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block7_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block7_out (Add)         (None, 14, 14, 1024  0           ['conv4_block6_out[0][0]',       \n",
            "                                )                                 'conv4_block7_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block8_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block7_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block8_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block8_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block8_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block8_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block8_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block8_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block8_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block8_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block8_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block8_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block8_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block8_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block8_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block8_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block8_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block8_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block8_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block8_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block8_out (Add)         (None, 14, 14, 1024  0           ['conv4_block7_out[0][0]',       \n",
            "                                )                                 'conv4_block8_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block9_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block8_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block9_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block9_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block9_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block9_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block9_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block9_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block9_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block9_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block9_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block9_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block9_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block9_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block9_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block9_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block9_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block9_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block9_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block9_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block9_out (Add)         (None, 14, 14, 1024  0           ['conv4_block8_out[0][0]',       \n",
            "                                )                                 'conv4_block9_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block10_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block9_out[0][0]']       \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block10_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block10_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block10_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block10_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block10_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block10_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block10_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block10_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block10_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block10_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block10_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block10_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block10_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block10_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block10_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block10_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block10_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block10_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block10_out (Add)        (None, 14, 14, 1024  0           ['conv4_block9_out[0][0]',       \n",
            "                                )                                 'conv4_block10_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block11_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block10_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block11_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block11_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block11_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block11_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block11_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block11_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block11_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block11_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block11_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block11_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block11_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block11_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block11_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block11_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block11_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block11_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block11_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block11_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block11_out (Add)        (None, 14, 14, 1024  0           ['conv4_block10_out[0][0]',      \n",
            "                                )                                 'conv4_block11_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block12_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block11_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block12_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block12_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block12_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block12_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block12_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block12_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block12_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block12_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block12_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block12_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block12_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block12_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block12_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block12_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block12_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block12_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block12_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block12_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block12_out (Add)        (None, 14, 14, 1024  0           ['conv4_block11_out[0][0]',      \n",
            "                                )                                 'conv4_block12_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block13_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block12_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block13_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block13_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block13_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block13_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block13_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block13_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block13_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block13_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block13_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block13_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block13_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block13_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block13_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block13_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block13_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block13_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block13_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block13_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block13_out (Add)        (None, 14, 14, 1024  0           ['conv4_block12_out[0][0]',      \n",
            "                                )                                 'conv4_block13_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block14_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block13_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block14_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block14_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block14_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block14_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block14_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block14_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block14_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block14_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block14_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block14_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block14_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block14_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block14_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block14_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block14_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block14_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block14_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block14_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block14_out (Add)        (None, 14, 14, 1024  0           ['conv4_block13_out[0][0]',      \n",
            "                                )                                 'conv4_block14_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block15_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block14_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block15_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block15_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block15_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block15_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block15_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block15_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block15_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block15_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block15_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block15_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block15_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block15_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block15_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block15_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block15_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block15_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block15_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block15_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block15_out (Add)        (None, 14, 14, 1024  0           ['conv4_block14_out[0][0]',      \n",
            "                                )                                 'conv4_block15_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block16_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block15_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block16_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block16_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block16_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block16_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block16_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block16_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block16_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block16_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block16_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block16_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block16_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block16_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block16_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block16_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block16_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block16_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block16_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block16_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block16_out (Add)        (None, 14, 14, 1024  0           ['conv4_block15_out[0][0]',      \n",
            "                                )                                 'conv4_block16_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block17_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block16_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block17_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block17_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block17_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block17_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block17_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block17_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block17_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block17_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block17_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block17_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block17_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block17_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block17_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block17_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block17_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block17_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block17_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block17_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block17_out (Add)        (None, 14, 14, 1024  0           ['conv4_block16_out[0][0]',      \n",
            "                                )                                 'conv4_block17_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block18_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block17_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block18_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block18_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block18_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block18_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block18_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block18_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block18_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block18_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block18_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block18_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block18_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block18_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block18_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block18_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block18_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block18_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block18_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block18_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block18_out (Add)        (None, 14, 14, 1024  0           ['conv4_block17_out[0][0]',      \n",
            "                                )                                 'conv4_block18_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block19_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block18_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block19_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block19_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block19_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block19_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block19_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block19_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block19_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block19_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block19_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block19_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block19_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block19_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block19_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block19_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block19_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block19_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block19_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block19_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block19_out (Add)        (None, 14, 14, 1024  0           ['conv4_block18_out[0][0]',      \n",
            "                                )                                 'conv4_block19_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block20_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block19_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block20_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block20_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block20_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block20_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block20_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block20_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block20_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block20_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block20_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block20_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block20_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block20_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block20_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block20_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block20_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block20_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block20_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block20_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block20_out (Add)        (None, 14, 14, 1024  0           ['conv4_block19_out[0][0]',      \n",
            "                                )                                 'conv4_block20_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block21_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block20_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block21_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block21_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block21_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block21_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block21_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block21_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block21_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block21_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block21_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block21_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block21_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block21_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block21_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block21_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block21_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block21_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block21_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block21_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block21_out (Add)        (None, 14, 14, 1024  0           ['conv4_block20_out[0][0]',      \n",
            "                                )                                 'conv4_block21_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block22_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block21_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block22_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block22_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block22_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block22_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block22_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block22_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block22_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block22_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block22_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block22_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block22_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block22_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block22_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block22_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block22_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block22_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block22_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block22_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block22_out (Add)        (None, 14, 14, 1024  0           ['conv4_block21_out[0][0]',      \n",
            "                                )                                 'conv4_block22_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block23_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block22_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block23_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block23_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block23_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block23_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block23_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block23_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block23_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block23_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block23_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block23_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block23_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block23_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block23_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block23_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block23_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block23_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block23_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block23_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block23_out (Add)        (None, 14, 14, 1024  0           ['conv4_block22_out[0][0]',      \n",
            "                                )                                 'conv4_block23_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block24_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block23_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block24_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block24_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block24_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block24_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block24_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block24_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block24_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block24_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block24_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block24_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block24_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block24_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block24_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block24_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block24_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block24_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block24_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block24_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block24_out (Add)        (None, 14, 14, 1024  0           ['conv4_block23_out[0][0]',      \n",
            "                                )                                 'conv4_block24_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block25_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block24_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block25_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block25_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block25_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block25_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block25_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block25_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block25_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block25_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block25_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block25_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block25_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block25_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block25_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block25_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block25_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block25_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block25_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block25_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block25_out (Add)        (None, 14, 14, 1024  0           ['conv4_block24_out[0][0]',      \n",
            "                                )                                 'conv4_block25_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block26_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block25_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block26_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block26_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block26_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block26_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block26_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block26_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block26_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block26_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block26_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block26_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block26_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block26_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block26_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block26_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block26_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block26_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block26_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block26_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block26_out (Add)        (None, 14, 14, 1024  0           ['conv4_block25_out[0][0]',      \n",
            "                                )                                 'conv4_block26_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block27_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block26_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block27_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block27_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block27_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block27_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block27_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block27_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block27_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block27_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block27_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block27_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block27_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block27_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block27_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block27_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block27_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block27_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block27_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block27_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block27_out (Add)        (None, 14, 14, 1024  0           ['conv4_block26_out[0][0]',      \n",
            "                                )                                 'conv4_block27_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block28_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block27_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block28_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block28_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block28_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block28_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block28_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block28_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block28_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block28_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block28_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block28_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block28_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block28_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block28_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block28_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block28_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block28_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block28_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block28_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block28_out (Add)        (None, 14, 14, 1024  0           ['conv4_block27_out[0][0]',      \n",
            "                                )                                 'conv4_block28_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block29_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block28_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block29_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block29_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block29_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block29_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block29_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block29_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block29_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block29_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block29_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block29_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block29_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block29_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block29_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block29_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block29_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block29_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block29_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block29_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block29_out (Add)        (None, 14, 14, 1024  0           ['conv4_block28_out[0][0]',      \n",
            "                                )                                 'conv4_block29_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block30_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block29_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block30_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block30_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block30_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block30_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block30_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block30_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block30_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block30_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block30_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block30_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block30_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block30_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block30_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block30_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block30_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block30_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block30_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block30_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block30_out (Add)        (None, 14, 14, 1024  0           ['conv4_block29_out[0][0]',      \n",
            "                                )                                 'conv4_block30_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block31_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block30_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block31_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block31_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block31_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block31_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block31_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block31_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block31_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block31_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block31_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block31_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block31_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block31_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block31_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block31_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block31_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block31_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block31_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block31_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block31_out (Add)        (None, 14, 14, 1024  0           ['conv4_block30_out[0][0]',      \n",
            "                                )                                 'conv4_block31_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block32_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block31_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block32_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block32_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block32_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block32_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block32_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block32_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block32_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block32_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block32_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block32_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block32_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block32_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block32_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block32_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block32_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block32_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block32_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block32_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block32_out (Add)        (None, 14, 14, 1024  0           ['conv4_block31_out[0][0]',      \n",
            "                                )                                 'conv4_block32_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block33_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block32_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block33_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block33_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block33_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block33_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block33_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block33_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block33_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block33_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block33_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block33_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block33_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block33_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block33_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block33_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block33_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block33_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block33_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block33_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block33_out (Add)        (None, 14, 14, 1024  0           ['conv4_block32_out[0][0]',      \n",
            "                                )                                 'conv4_block33_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block34_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block33_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block34_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block34_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block34_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block34_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block34_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block34_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block34_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block34_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block34_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block34_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block34_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block34_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block34_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block34_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block34_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block34_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block34_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block34_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block34_out (Add)        (None, 14, 14, 1024  0           ['conv4_block33_out[0][0]',      \n",
            "                                )                                 'conv4_block34_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block35_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block34_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block35_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block35_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block35_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block35_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block35_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block35_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block35_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block35_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block35_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block35_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block35_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block35_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block35_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block35_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block35_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block35_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block35_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block35_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block35_out (Add)        (None, 14, 14, 1024  0           ['conv4_block34_out[0][0]',      \n",
            "                                )                                 'conv4_block35_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block36_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block35_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block36_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block36_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block36_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block36_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block36_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block36_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block36_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block36_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block36_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block36_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block36_2_conv (Conv2D)  (None, 7, 7, 256)    589824      ['conv4_block36_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block36_2_bn (BatchNorma  (None, 7, 7, 256)   1024        ['conv4_block36_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block36_2_relu (Activati  (None, 7, 7, 256)   0           ['conv4_block36_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 1024)  0           ['conv4_block35_out[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block36_3_conv (Conv2D)  (None, 7, 7, 1024)   263168      ['conv4_block36_2_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block36_out (Add)        (None, 7, 7, 1024)   0           ['max_pooling2d_2[0][0]',        \n",
            "                                                                  'conv4_block36_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block1_preact_bn (BatchN  (None, 7, 7, 1024)  4096        ['conv4_block36_out[0][0]']      \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block1_preact_relu (Acti  (None, 7, 7, 1024)  0           ['conv5_block1_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524288      ['conv5_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block1_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block1_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv5_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_conv[0][0]',    \n",
            "                                                                  'conv5_block1_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_preact_bn (BatchN  (None, 7, 7, 2048)  8192        ['conv5_block1_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block2_preact_relu (Acti  (None, 7, 7, 2048)  0           ['conv5_block2_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1048576     ['conv5_block2_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block2_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block2_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
            "                                                                  'conv5_block2_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_preact_bn (BatchN  (None, 7, 7, 2048)  8192        ['conv5_block2_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block3_preact_relu (Acti  (None, 7, 7, 2048)  0           ['conv5_block3_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1048576     ['conv5_block3_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block3_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block3_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
            "                                                                  'conv5_block3_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " post_bn (BatchNormalization)   (None, 7, 7, 2048)   8192        ['conv5_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " post_relu (Activation)         (None, 7, 7, 2048)   0           ['post_bn[0][0]']                \n",
            "                                                                                                  \n",
            " avg_pool (GlobalAveragePooling  (None, 2048)        0           ['post_relu[0][0]']              \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 58,331,648\n",
            "Trainable params: 58,187,904\n",
            "Non-trainable params: 143,744\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efptKuKSspQw",
        "outputId": "feba4075-e8c0-4dd9-e49c-eb3da1d8d9fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"resnet152v2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_conv[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv2_block1_preact_bn (BatchN  (None, 56, 56, 64)  256         ['pool1_pool[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2_block1_preact_relu (Acti  (None, 56, 56, 64)  0           ['conv2_block1_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4096        ['conv2_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block1_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36864       ['conv2_block1_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_out (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_conv[0][0]',    \n",
            "                                                                  'conv2_block1_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_preact_bn (BatchN  (None, 56, 56, 256)  1024       ['conv2_block1_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2_block2_preact_relu (Acti  (None, 56, 56, 256)  0          ['conv2_block2_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16384       ['conv2_block2_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block2_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36864       ['conv2_block2_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_out (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
            "                                                                  'conv2_block2_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_preact_bn (BatchN  (None, 56, 56, 256)  1024       ['conv2_block2_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2_block3_preact_relu (Acti  (None, 56, 56, 256)  0          ['conv2_block3_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16384       ['conv2_block3_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block3_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 28, 28, 64)   36864       ['conv2_block3_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, 28, 28, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, 28, 28, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 28, 28, 256)  0           ['conv2_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, 28, 28, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_out (Add)         (None, 28, 28, 256)  0           ['max_pooling2d[0][0]',          \n",
            "                                                                  'conv2_block3_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_preact_bn (BatchN  (None, 28, 28, 256)  1024       ['conv2_block3_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block1_preact_relu (Acti  (None, 28, 28, 256)  0          ['conv3_block1_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32768       ['conv3_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block1_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block1_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv3_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_out (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_conv[0][0]',    \n",
            "                                                                  'conv3_block1_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block1_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block2_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block2_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block2_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block2_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block2_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_out (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
            "                                                                  'conv3_block2_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block2_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block3_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block3_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block3_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block3_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block3_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_out (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
            "                                                                  'conv3_block3_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block3_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block4_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block4_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block4_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block4_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block4_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_out (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',       \n",
            "                                                                  'conv3_block4_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block5_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block4_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block5_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block5_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block5_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block5_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block5_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block5_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block5_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block5_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block5_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block5_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block5_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block5_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block5_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block5_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block5_out (Add)         (None, 28, 28, 512)  0           ['conv3_block4_out[0][0]',       \n",
            "                                                                  'conv3_block5_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block6_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block5_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block6_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block6_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block6_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block6_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block6_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block6_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block6_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block6_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block6_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block6_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block6_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block6_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block6_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block6_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block6_out (Add)         (None, 28, 28, 512)  0           ['conv3_block5_out[0][0]',       \n",
            "                                                                  'conv3_block6_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block7_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block6_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block7_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block7_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block7_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block7_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block7_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block7_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block7_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block7_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block7_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block7_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block7_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block7_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block7_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block7_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block7_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block7_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block7_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block7_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block7_out (Add)         (None, 28, 28, 512)  0           ['conv3_block6_out[0][0]',       \n",
            "                                                                  'conv3_block7_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block8_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block7_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block8_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block8_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block8_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block8_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block8_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block8_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block8_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block8_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block8_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block8_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block8_2_conv (Conv2D)   (None, 14, 14, 128)  147456      ['conv3_block8_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block8_2_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv3_block8_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block8_2_relu (Activatio  (None, 14, 14, 128)  0          ['conv3_block8_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 14, 14, 512)  0          ['conv3_block7_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block8_3_conv (Conv2D)   (None, 14, 14, 512)  66048       ['conv3_block8_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block8_out (Add)         (None, 14, 14, 512)  0           ['max_pooling2d_1[0][0]',        \n",
            "                                                                  'conv3_block8_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_preact_bn (BatchN  (None, 14, 14, 512)  2048       ['conv3_block8_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block1_preact_relu (Acti  (None, 14, 14, 512)  0          ['conv4_block1_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131072      ['conv4_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block1_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block1_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv4_block1_preact_relu[0][0]'\n",
            "                                )                                ]                                \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_out (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_conv[0][0]',    \n",
            "                                )                                 'conv4_block1_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block1_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block2_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block2_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block2_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block2_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_out (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
            "                                )                                 'conv4_block2_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block2_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block3_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block3_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block3_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block3_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_out (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
            "                                )                                 'conv4_block3_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block3_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block4_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block4_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block4_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block4_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_out (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
            "                                )                                 'conv4_block4_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block4_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block5_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block5_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block5_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block5_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_out (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
            "                                )                                 'conv4_block5_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block5_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block6_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block6_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block6_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block6_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_out (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
            "                                )                                 'conv4_block6_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block7_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block6_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block7_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block7_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block7_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block7_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block7_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block7_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block7_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block7_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block7_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block7_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block7_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block7_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block7_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block7_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block7_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block7_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block7_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block7_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block7_out (Add)         (None, 14, 14, 1024  0           ['conv4_block6_out[0][0]',       \n",
            "                                )                                 'conv4_block7_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block8_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block7_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block8_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block8_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block8_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block8_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block8_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block8_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block8_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block8_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block8_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block8_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block8_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block8_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block8_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block8_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block8_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block8_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block8_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block8_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block8_out (Add)         (None, 14, 14, 1024  0           ['conv4_block7_out[0][0]',       \n",
            "                                )                                 'conv4_block8_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block9_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block8_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block9_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block9_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block9_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block9_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block9_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block9_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block9_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block9_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block9_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block9_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block9_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block9_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block9_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block9_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block9_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block9_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block9_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block9_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block9_out (Add)         (None, 14, 14, 1024  0           ['conv4_block8_out[0][0]',       \n",
            "                                )                                 'conv4_block9_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block10_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block9_out[0][0]']       \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block10_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block10_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block10_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block10_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block10_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block10_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block10_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block10_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block10_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block10_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block10_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block10_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block10_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block10_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block10_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block10_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block10_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block10_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block10_out (Add)        (None, 14, 14, 1024  0           ['conv4_block9_out[0][0]',       \n",
            "                                )                                 'conv4_block10_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block11_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block10_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block11_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block11_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block11_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block11_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block11_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block11_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block11_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block11_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block11_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block11_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block11_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block11_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block11_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block11_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block11_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block11_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block11_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block11_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block11_out (Add)        (None, 14, 14, 1024  0           ['conv4_block10_out[0][0]',      \n",
            "                                )                                 'conv4_block11_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block12_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block11_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block12_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block12_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block12_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block12_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block12_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block12_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block12_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block12_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block12_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block12_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block12_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block12_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block12_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block12_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block12_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block12_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block12_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block12_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block12_out (Add)        (None, 14, 14, 1024  0           ['conv4_block11_out[0][0]',      \n",
            "                                )                                 'conv4_block12_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block13_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block12_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block13_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block13_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block13_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block13_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block13_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block13_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block13_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block13_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block13_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block13_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block13_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block13_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block13_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block13_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block13_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block13_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block13_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block13_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block13_out (Add)        (None, 14, 14, 1024  0           ['conv4_block12_out[0][0]',      \n",
            "                                )                                 'conv4_block13_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block14_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block13_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block14_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block14_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block14_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block14_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block14_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block14_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block14_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block14_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block14_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block14_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block14_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block14_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block14_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block14_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block14_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block14_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block14_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block14_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block14_out (Add)        (None, 14, 14, 1024  0           ['conv4_block13_out[0][0]',      \n",
            "                                )                                 'conv4_block14_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block15_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block14_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block15_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block15_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block15_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block15_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block15_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block15_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block15_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block15_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block15_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block15_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block15_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block15_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block15_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block15_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block15_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block15_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block15_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block15_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block15_out (Add)        (None, 14, 14, 1024  0           ['conv4_block14_out[0][0]',      \n",
            "                                )                                 'conv4_block15_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block16_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block15_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block16_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block16_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block16_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block16_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block16_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block16_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block16_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block16_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block16_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block16_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block16_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block16_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block16_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block16_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block16_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block16_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block16_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block16_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block16_out (Add)        (None, 14, 14, 1024  0           ['conv4_block15_out[0][0]',      \n",
            "                                )                                 'conv4_block16_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block17_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block16_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block17_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block17_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block17_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block17_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block17_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block17_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block17_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block17_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block17_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block17_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block17_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block17_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block17_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block17_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block17_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block17_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block17_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block17_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block17_out (Add)        (None, 14, 14, 1024  0           ['conv4_block16_out[0][0]',      \n",
            "                                )                                 'conv4_block17_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block18_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block17_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block18_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block18_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block18_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block18_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block18_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block18_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block18_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block18_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block18_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block18_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block18_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block18_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block18_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block18_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block18_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block18_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block18_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block18_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block18_out (Add)        (None, 14, 14, 1024  0           ['conv4_block17_out[0][0]',      \n",
            "                                )                                 'conv4_block18_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block19_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block18_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block19_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block19_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block19_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block19_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block19_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block19_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block19_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block19_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block19_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block19_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block19_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block19_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block19_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block19_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block19_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block19_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block19_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block19_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block19_out (Add)        (None, 14, 14, 1024  0           ['conv4_block18_out[0][0]',      \n",
            "                                )                                 'conv4_block19_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block20_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block19_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block20_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block20_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block20_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block20_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block20_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block20_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block20_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block20_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block20_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block20_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block20_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block20_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block20_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block20_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block20_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block20_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block20_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block20_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block20_out (Add)        (None, 14, 14, 1024  0           ['conv4_block19_out[0][0]',      \n",
            "                                )                                 'conv4_block20_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block21_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block20_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block21_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block21_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block21_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block21_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block21_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block21_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block21_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block21_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block21_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block21_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block21_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block21_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block21_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block21_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block21_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block21_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block21_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block21_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block21_out (Add)        (None, 14, 14, 1024  0           ['conv4_block20_out[0][0]',      \n",
            "                                )                                 'conv4_block21_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block22_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block21_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block22_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block22_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block22_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block22_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block22_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block22_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block22_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block22_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block22_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block22_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block22_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block22_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block22_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block22_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block22_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block22_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block22_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block22_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block22_out (Add)        (None, 14, 14, 1024  0           ['conv4_block21_out[0][0]',      \n",
            "                                )                                 'conv4_block22_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block23_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block22_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block23_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block23_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block23_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block23_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block23_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block23_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block23_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block23_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block23_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block23_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block23_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block23_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block23_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block23_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block23_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block23_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block23_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block23_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block23_out (Add)        (None, 14, 14, 1024  0           ['conv4_block22_out[0][0]',      \n",
            "                                )                                 'conv4_block23_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block24_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block23_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block24_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block24_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block24_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block24_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block24_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block24_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block24_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block24_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block24_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block24_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block24_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block24_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block24_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block24_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block24_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block24_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block24_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block24_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block24_out (Add)        (None, 14, 14, 1024  0           ['conv4_block23_out[0][0]',      \n",
            "                                )                                 'conv4_block24_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block25_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block24_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block25_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block25_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block25_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block25_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block25_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block25_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block25_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block25_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block25_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block25_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block25_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block25_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block25_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block25_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block25_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block25_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block25_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block25_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block25_out (Add)        (None, 14, 14, 1024  0           ['conv4_block24_out[0][0]',      \n",
            "                                )                                 'conv4_block25_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block26_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block25_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block26_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block26_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block26_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block26_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block26_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block26_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block26_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block26_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block26_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block26_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block26_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block26_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block26_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block26_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block26_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block26_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block26_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block26_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block26_out (Add)        (None, 14, 14, 1024  0           ['conv4_block25_out[0][0]',      \n",
            "                                )                                 'conv4_block26_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block27_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block26_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block27_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block27_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block27_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block27_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block27_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block27_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block27_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block27_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block27_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block27_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block27_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block27_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block27_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block27_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block27_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block27_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block27_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block27_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block27_out (Add)        (None, 14, 14, 1024  0           ['conv4_block26_out[0][0]',      \n",
            "                                )                                 'conv4_block27_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block28_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block27_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block28_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block28_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block28_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block28_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block28_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block28_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block28_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block28_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block28_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block28_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block28_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block28_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block28_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block28_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block28_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block28_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block28_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block28_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block28_out (Add)        (None, 14, 14, 1024  0           ['conv4_block27_out[0][0]',      \n",
            "                                )                                 'conv4_block28_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block29_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block28_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block29_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block29_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block29_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block29_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block29_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block29_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block29_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block29_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block29_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block29_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block29_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block29_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block29_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block29_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block29_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block29_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block29_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block29_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block29_out (Add)        (None, 14, 14, 1024  0           ['conv4_block28_out[0][0]',      \n",
            "                                )                                 'conv4_block29_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block30_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block29_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block30_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block30_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block30_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block30_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block30_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block30_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block30_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block30_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block30_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block30_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block30_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block30_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block30_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block30_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block30_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block30_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block30_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block30_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block30_out (Add)        (None, 14, 14, 1024  0           ['conv4_block29_out[0][0]',      \n",
            "                                )                                 'conv4_block30_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block31_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block30_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block31_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block31_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block31_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block31_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block31_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block31_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block31_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block31_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block31_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block31_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block31_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block31_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block31_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block31_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block31_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block31_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block31_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block31_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block31_out (Add)        (None, 14, 14, 1024  0           ['conv4_block30_out[0][0]',      \n",
            "                                )                                 'conv4_block31_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block32_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block31_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block32_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block32_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block32_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block32_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block32_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block32_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block32_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block32_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block32_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block32_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block32_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block32_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block32_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block32_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block32_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block32_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block32_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block32_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block32_out (Add)        (None, 14, 14, 1024  0           ['conv4_block31_out[0][0]',      \n",
            "                                )                                 'conv4_block32_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block33_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block32_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block33_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block33_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block33_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block33_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block33_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block33_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block33_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block33_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block33_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block33_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block33_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block33_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block33_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block33_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block33_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block33_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block33_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block33_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block33_out (Add)        (None, 14, 14, 1024  0           ['conv4_block32_out[0][0]',      \n",
            "                                )                                 'conv4_block33_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block34_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block33_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block34_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block34_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block34_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block34_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block34_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block34_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block34_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block34_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block34_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block34_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block34_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block34_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block34_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block34_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block34_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block34_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block34_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block34_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block34_out (Add)        (None, 14, 14, 1024  0           ['conv4_block33_out[0][0]',      \n",
            "                                )                                 'conv4_block34_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block35_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block34_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block35_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block35_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block35_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block35_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block35_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block35_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block35_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block35_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block35_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block35_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block35_2_conv (Conv2D)  (None, 14, 14, 256)  589824      ['conv4_block35_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block35_2_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block35_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block35_2_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block35_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block35_3_conv (Conv2D)  (None, 14, 14, 1024  263168      ['conv4_block35_2_relu[0][0]']   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block35_out (Add)        (None, 14, 14, 1024  0           ['conv4_block34_out[0][0]',      \n",
            "                                )                                 'conv4_block35_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block36_preact_bn (Batch  (None, 14, 14, 1024  4096       ['conv4_block35_out[0][0]']      \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block36_preact_relu (Act  (None, 14, 14, 1024  0          ['conv4_block36_preact_bn[0][0]']\n",
            " ivation)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block36_1_conv (Conv2D)  (None, 14, 14, 256)  262144      ['conv4_block36_preact_relu[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv4_block36_1_bn (BatchNorma  (None, 14, 14, 256)  1024       ['conv4_block36_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block36_1_relu (Activati  (None, 14, 14, 256)  0          ['conv4_block36_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block36_2_pad (ZeroPaddi  (None, 16, 16, 256)  0          ['conv4_block36_1_relu[0][0]']   \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv4_block36_2_conv (Conv2D)  (None, 7, 7, 256)    589824      ['conv4_block36_2_pad[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block36_2_bn (BatchNorma  (None, 7, 7, 256)   1024        ['conv4_block36_2_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block36_2_relu (Activati  (None, 7, 7, 256)   0           ['conv4_block36_2_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 1024)  0           ['conv4_block35_out[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block36_3_conv (Conv2D)  (None, 7, 7, 1024)   263168      ['conv4_block36_2_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block36_out (Add)        (None, 7, 7, 1024)   0           ['max_pooling2d_2[0][0]',        \n",
            "                                                                  'conv4_block36_3_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block1_preact_bn (BatchN  (None, 7, 7, 1024)  4096        ['conv4_block36_out[0][0]']      \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block1_preact_relu (Acti  (None, 7, 7, 1024)  0           ['conv5_block1_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524288      ['conv5_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block1_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block1_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv5_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_conv[0][0]',    \n",
            "                                                                  'conv5_block1_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_preact_bn (BatchN  (None, 7, 7, 2048)  8192        ['conv5_block1_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block2_preact_relu (Acti  (None, 7, 7, 2048)  0           ['conv5_block2_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1048576     ['conv5_block2_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block2_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block2_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
            "                                                                  'conv5_block2_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_preact_bn (BatchN  (None, 7, 7, 2048)  8192        ['conv5_block2_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block3_preact_relu (Acti  (None, 7, 7, 2048)  0           ['conv5_block3_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1048576     ['conv5_block3_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block3_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block3_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
            "                                                                  'conv5_block3_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " post_bn (BatchNormalization)   (None, 7, 7, 2048)   8192        ['conv5_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " post_relu (Activation)         (None, 7, 7, 2048)   0           ['post_bn[0][0]']                \n",
            "                                                                                                  \n",
            " avg_pool (GlobalAveragePooling  (None, 2048)        0           ['post_relu[0][0]']              \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 58,331,648\n",
            "Trainable params: 0\n",
            "Non-trainable params: 58,331,648\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bottleneck_features_train = model.predict_generator(train_generator_Excep, predict_size_train)\n",
        "np.save('/content/drive/MyDrive/My_projects _and _datasets/IDRID_detection/'+'bottleneck_features_train_'+model_name+'.npy', bottleneck_features_train)"
      ],
      "metadata": {
        "id": "gF3ic3nAs3bX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bottleneck_features_validation = model.predict_generator(val_generator_Excep, predict_size_validation)\n",
        "np.save('/content/drive/MyDrive/My_projects _and _datasets/IDRID_detection/'+'bottleneck_features_validation_'+model_name+'.npy', bottleneck_features_validation)"
      ],
      "metadata": {
        "id": "SWWtyB0ItDtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bottleneck_features_test = model.predict_generator(test_generator_Excep, predict_size_test)\n",
        "np.save(\"/content/drive/MyDrive/My_projects _and _datasets/IDRID_detection/\"+'bottleneck_features_test_'+model_name+'.npy', bottleneck_features_test)"
      ],
      "metadata": {
        "id": "xYbZYlmVuYWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=np.load('/content/drive/MyDrive/My_projects _and _datasets/IDRID_detection/bottleneck_features_train_ResNet152V2.npy')\n",
        "validation_data=np.load('/content/drive/MyDrive/My_projects _and _datasets/IDRID_detection/bottleneck_features_validation_ResNet152V2.npy')\n",
        "test_data = np.load('/content/drive/MyDrive/My_projects _and _datasets/IDRID_detection/bottleneck_features_test_ResNet152V2.npy')"
      ],
      "metadata": {
        "id": "mM_s35aGue9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.shape)\n",
        "print(validation_data.shape)\n",
        "print(test_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7MMhiXEyqTU",
        "outputId": "9322edbe-1040-4d87-947f-6735d3677f34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2628, 2048)\n",
            "(656, 2048)\n",
            "(378, 2048)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels=train_generator_Excep.classes\n",
        "train_labels=train_labels = to_categorical(train_labels, num_classes=2)\n",
        "validation_labels=val_generator_Excep.classes\n",
        "validation_labels = to_categorical(validation_labels, num_classes=2)\n",
        "test_labels=test_generator_Excep.classes\n",
        "test_labels=to_categorical(test_labels,num_classes=2)"
      ],
      "metadata": {
        "id": "6O1c8AXsyyJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_labels.shape)\n",
        "print(validation_labels.shape)\n",
        "print(test_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JM40atwzy8V4",
        "outputId": "5df9313c-7201-47c0-967e-6e1ca16a6588"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2628, 2)\n",
            "(656, 2)\n",
            "(378, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(112,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2,activation='sigmoid'))\n",
        "adam_opt2=Adam(lr = 0.001, beta_1=0.6, beta_2=0.8, amsgrad=True)\n",
        "\n",
        "model.compile(optimizer=adam_opt2, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_data, train_labels,\n",
        "                    epochs=1000,\n",
        "                    batch_size=batch_size,\n",
        "                    validation_data=(validation_data, validation_labels),\n",
        "                    verbose= 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0MhQFSBzAHP",
        "outputId": "f9103e84-fae6-4479-c568-a59254141413"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.2993 - accuracy: 0.8855 - val_loss: 0.1583 - val_accuracy: 0.9512\n",
            "Epoch 2/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.2087 - accuracy: 0.9258 - val_loss: 0.1339 - val_accuracy: 0.9634\n",
            "Epoch 3/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.1798 - accuracy: 0.9403 - val_loss: 0.1259 - val_accuracy: 0.9680\n",
            "Epoch 4/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.1645 - accuracy: 0.9452 - val_loss: 0.1218 - val_accuracy: 0.9726\n",
            "Epoch 5/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.1500 - accuracy: 0.9505 - val_loss: 0.1179 - val_accuracy: 0.9695\n",
            "Epoch 6/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.1408 - accuracy: 0.9521 - val_loss: 0.1089 - val_accuracy: 0.9680\n",
            "Epoch 7/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.1363 - accuracy: 0.9581 - val_loss: 0.1284 - val_accuracy: 0.9634\n",
            "Epoch 8/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.1289 - accuracy: 0.9578 - val_loss: 0.1132 - val_accuracy: 0.9604\n",
            "Epoch 9/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.1178 - accuracy: 0.9604 - val_loss: 0.1340 - val_accuracy: 0.9649\n",
            "Epoch 10/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.1206 - accuracy: 0.9639 - val_loss: 0.1006 - val_accuracy: 0.9726\n",
            "Epoch 11/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.1091 - accuracy: 0.9658 - val_loss: 0.1072 - val_accuracy: 0.9710\n",
            "Epoch 12/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.1034 - accuracy: 0.9650 - val_loss: 0.1011 - val_accuracy: 0.9695\n",
            "Epoch 13/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.1030 - accuracy: 0.9654 - val_loss: 0.1296 - val_accuracy: 0.9695\n",
            "Epoch 14/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.1028 - accuracy: 0.9635 - val_loss: 0.1022 - val_accuracy: 0.9726\n",
            "Epoch 15/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0902 - accuracy: 0.9692 - val_loss: 0.1012 - val_accuracy: 0.9726\n",
            "Epoch 16/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0884 - accuracy: 0.9730 - val_loss: 0.0977 - val_accuracy: 0.9695\n",
            "Epoch 17/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0823 - accuracy: 0.9741 - val_loss: 0.0979 - val_accuracy: 0.9741\n",
            "Epoch 18/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0778 - accuracy: 0.9756 - val_loss: 0.0975 - val_accuracy: 0.9756\n",
            "Epoch 19/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0750 - accuracy: 0.9764 - val_loss: 0.0987 - val_accuracy: 0.9726\n",
            "Epoch 20/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0757 - accuracy: 0.9775 - val_loss: 0.1031 - val_accuracy: 0.9726\n",
            "Epoch 21/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0673 - accuracy: 0.9798 - val_loss: 0.0986 - val_accuracy: 0.9726\n",
            "Epoch 22/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9802 - val_loss: 0.0960 - val_accuracy: 0.9726\n",
            "Epoch 23/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0663 - accuracy: 0.9821 - val_loss: 0.1041 - val_accuracy: 0.9695\n",
            "Epoch 24/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0684 - accuracy: 0.9791 - val_loss: 0.1026 - val_accuracy: 0.9741\n",
            "Epoch 25/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0610 - accuracy: 0.9825 - val_loss: 0.1001 - val_accuracy: 0.9726\n",
            "Epoch 26/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0603 - accuracy: 0.9821 - val_loss: 0.1099 - val_accuracy: 0.9726\n",
            "Epoch 27/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0605 - accuracy: 0.9836 - val_loss: 0.1040 - val_accuracy: 0.9726\n",
            "Epoch 28/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0549 - accuracy: 0.9833 - val_loss: 0.1057 - val_accuracy: 0.9726\n",
            "Epoch 29/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0562 - accuracy: 0.9795 - val_loss: 0.1014 - val_accuracy: 0.9695\n",
            "Epoch 30/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0509 - accuracy: 0.9863 - val_loss: 0.0985 - val_accuracy: 0.9741\n",
            "Epoch 31/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0466 - accuracy: 0.9874 - val_loss: 0.1094 - val_accuracy: 0.9710\n",
            "Epoch 32/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0494 - accuracy: 0.9852 - val_loss: 0.0971 - val_accuracy: 0.9710\n",
            "Epoch 33/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0503 - accuracy: 0.9844 - val_loss: 0.0957 - val_accuracy: 0.9726\n",
            "Epoch 34/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0458 - accuracy: 0.9867 - val_loss: 0.1007 - val_accuracy: 0.9710\n",
            "Epoch 35/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0435 - accuracy: 0.9871 - val_loss: 0.0946 - val_accuracy: 0.9726\n",
            "Epoch 36/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0406 - accuracy: 0.9901 - val_loss: 0.0986 - val_accuracy: 0.9726\n",
            "Epoch 37/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0395 - accuracy: 0.9886 - val_loss: 0.1077 - val_accuracy: 0.9726\n",
            "Epoch 38/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0434 - accuracy: 0.9871 - val_loss: 0.0992 - val_accuracy: 0.9710\n",
            "Epoch 39/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0371 - accuracy: 0.9909 - val_loss: 0.1045 - val_accuracy: 0.9726\n",
            "Epoch 40/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0413 - accuracy: 0.9905 - val_loss: 0.0987 - val_accuracy: 0.9741\n",
            "Epoch 41/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0334 - accuracy: 0.9924 - val_loss: 0.0989 - val_accuracy: 0.9710\n",
            "Epoch 42/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0367 - accuracy: 0.9897 - val_loss: 0.0994 - val_accuracy: 0.9710\n",
            "Epoch 43/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0333 - accuracy: 0.9901 - val_loss: 0.1046 - val_accuracy: 0.9726\n",
            "Epoch 44/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0318 - accuracy: 0.9909 - val_loss: 0.1046 - val_accuracy: 0.9726\n",
            "Epoch 45/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0320 - accuracy: 0.9916 - val_loss: 0.0956 - val_accuracy: 0.9741\n",
            "Epoch 46/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0320 - accuracy: 0.9935 - val_loss: 0.1013 - val_accuracy: 0.9756\n",
            "Epoch 47/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0279 - accuracy: 0.9924 - val_loss: 0.1035 - val_accuracy: 0.9710\n",
            "Epoch 48/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0291 - accuracy: 0.9932 - val_loss: 0.1004 - val_accuracy: 0.9741\n",
            "Epoch 49/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0295 - accuracy: 0.9912 - val_loss: 0.1005 - val_accuracy: 0.9726\n",
            "Epoch 50/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0276 - accuracy: 0.9924 - val_loss: 0.0989 - val_accuracy: 0.9710\n",
            "Epoch 51/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0252 - accuracy: 0.9958 - val_loss: 0.1058 - val_accuracy: 0.9710\n",
            "Epoch 52/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0272 - accuracy: 0.9935 - val_loss: 0.1056 - val_accuracy: 0.9741\n",
            "Epoch 53/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0256 - accuracy: 0.9928 - val_loss: 0.1046 - val_accuracy: 0.9726\n",
            "Epoch 54/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0233 - accuracy: 0.9939 - val_loss: 0.1052 - val_accuracy: 0.9726\n",
            "Epoch 55/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0261 - accuracy: 0.9935 - val_loss: 0.1086 - val_accuracy: 0.9741\n",
            "Epoch 56/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0260 - accuracy: 0.9916 - val_loss: 0.1044 - val_accuracy: 0.9756\n",
            "Epoch 57/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0238 - accuracy: 0.9951 - val_loss: 0.1069 - val_accuracy: 0.9695\n",
            "Epoch 58/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0219 - accuracy: 0.9958 - val_loss: 0.0995 - val_accuracy: 0.9726\n",
            "Epoch 59/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0276 - accuracy: 0.9935 - val_loss: 0.1034 - val_accuracy: 0.9741\n",
            "Epoch 60/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0220 - accuracy: 0.9954 - val_loss: 0.1096 - val_accuracy: 0.9710\n",
            "Epoch 61/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0205 - accuracy: 0.9970 - val_loss: 0.1102 - val_accuracy: 0.9726\n",
            "Epoch 62/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0203 - accuracy: 0.9962 - val_loss: 0.1065 - val_accuracy: 0.9710\n",
            "Epoch 63/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0212 - accuracy: 0.9962 - val_loss: 0.1014 - val_accuracy: 0.9726\n",
            "Epoch 64/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0188 - accuracy: 0.9966 - val_loss: 0.1076 - val_accuracy: 0.9741\n",
            "Epoch 65/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0182 - accuracy: 0.9958 - val_loss: 0.1130 - val_accuracy: 0.9710\n",
            "Epoch 66/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0172 - accuracy: 0.9973 - val_loss: 0.1142 - val_accuracy: 0.9695\n",
            "Epoch 67/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0182 - accuracy: 0.9973 - val_loss: 0.1120 - val_accuracy: 0.9695\n",
            "Epoch 68/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0183 - accuracy: 0.9966 - val_loss: 0.1117 - val_accuracy: 0.9695\n",
            "Epoch 69/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0169 - accuracy: 0.9970 - val_loss: 0.1077 - val_accuracy: 0.9741\n",
            "Epoch 70/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0170 - accuracy: 0.9973 - val_loss: 0.1076 - val_accuracy: 0.9726\n",
            "Epoch 71/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0162 - accuracy: 0.9973 - val_loss: 0.1075 - val_accuracy: 0.9726\n",
            "Epoch 72/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0169 - accuracy: 0.9977 - val_loss: 0.1051 - val_accuracy: 0.9741\n",
            "Epoch 73/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0154 - accuracy: 0.9966 - val_loss: 0.1099 - val_accuracy: 0.9710\n",
            "Epoch 74/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0167 - accuracy: 0.9973 - val_loss: 0.1073 - val_accuracy: 0.9756\n",
            "Epoch 75/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0143 - accuracy: 0.9973 - val_loss: 0.1047 - val_accuracy: 0.9756\n",
            "Epoch 76/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0155 - accuracy: 0.9977 - val_loss: 0.1096 - val_accuracy: 0.9710\n",
            "Epoch 77/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0148 - accuracy: 0.9981 - val_loss: 0.1094 - val_accuracy: 0.9726\n",
            "Epoch 78/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0140 - accuracy: 0.9985 - val_loss: 0.1092 - val_accuracy: 0.9710\n",
            "Epoch 79/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0135 - accuracy: 0.9989 - val_loss: 0.1065 - val_accuracy: 0.9726\n",
            "Epoch 80/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0132 - accuracy: 0.9981 - val_loss: 0.1088 - val_accuracy: 0.9726\n",
            "Epoch 81/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0120 - accuracy: 0.9977 - val_loss: 0.1090 - val_accuracy: 0.9741\n",
            "Epoch 82/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0143 - accuracy: 0.9973 - val_loss: 0.1085 - val_accuracy: 0.9741\n",
            "Epoch 83/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0127 - accuracy: 0.9985 - val_loss: 0.1142 - val_accuracy: 0.9695\n",
            "Epoch 84/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0117 - accuracy: 0.9989 - val_loss: 0.1136 - val_accuracy: 0.9741\n",
            "Epoch 85/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0142 - accuracy: 0.9977 - val_loss: 0.1154 - val_accuracy: 0.9710\n",
            "Epoch 86/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0115 - accuracy: 0.9989 - val_loss: 0.1188 - val_accuracy: 0.9680\n",
            "Epoch 87/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0112 - accuracy: 0.9981 - val_loss: 0.1134 - val_accuracy: 0.9710\n",
            "Epoch 88/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 0.9989 - val_loss: 0.1120 - val_accuracy: 0.9741\n",
            "Epoch 89/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0115 - accuracy: 0.9973 - val_loss: 0.1143 - val_accuracy: 0.9726\n",
            "Epoch 90/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9985 - val_loss: 0.1124 - val_accuracy: 0.9710\n",
            "Epoch 91/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0115 - accuracy: 0.9985 - val_loss: 0.1125 - val_accuracy: 0.9710\n",
            "Epoch 92/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0115 - accuracy: 0.9989 - val_loss: 0.1135 - val_accuracy: 0.9726\n",
            "Epoch 93/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0112 - accuracy: 0.9996 - val_loss: 0.1180 - val_accuracy: 0.9710\n",
            "Epoch 94/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9992 - val_loss: 0.1155 - val_accuracy: 0.9726\n",
            "Epoch 95/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.9996 - val_loss: 0.1172 - val_accuracy: 0.9726\n",
            "Epoch 96/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.9992 - val_loss: 0.1128 - val_accuracy: 0.9710\n",
            "Epoch 97/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0101 - accuracy: 0.9981 - val_loss: 0.1111 - val_accuracy: 0.9710\n",
            "Epoch 98/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0095 - accuracy: 0.9992 - val_loss: 0.1180 - val_accuracy: 0.9710\n",
            "Epoch 99/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9970 - val_loss: 0.1145 - val_accuracy: 0.9710\n",
            "Epoch 100/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9996 - val_loss: 0.1183 - val_accuracy: 0.9710\n",
            "Epoch 101/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.1177 - val_accuracy: 0.9726\n",
            "Epoch 102/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0095 - accuracy: 0.9985 - val_loss: 0.1168 - val_accuracy: 0.9726\n",
            "Epoch 103/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0098 - accuracy: 0.9992 - val_loss: 0.1203 - val_accuracy: 0.9710\n",
            "Epoch 104/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9992 - val_loss: 0.1182 - val_accuracy: 0.9726\n",
            "Epoch 105/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 0.9989 - val_loss: 0.1141 - val_accuracy: 0.9710\n",
            "Epoch 106/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9992 - val_loss: 0.1192 - val_accuracy: 0.9726\n",
            "Epoch 107/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0097 - accuracy: 0.9989 - val_loss: 0.1157 - val_accuracy: 0.9726\n",
            "Epoch 108/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0100 - accuracy: 0.9989 - val_loss: 0.1189 - val_accuracy: 0.9710\n",
            "Epoch 109/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.1183 - val_accuracy: 0.9726\n",
            "Epoch 110/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 0.9989 - val_loss: 0.1185 - val_accuracy: 0.9710\n",
            "Epoch 111/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 0.9989 - val_loss: 0.1233 - val_accuracy: 0.9710\n",
            "Epoch 112/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0089 - accuracy: 0.9992 - val_loss: 0.1211 - val_accuracy: 0.9710\n",
            "Epoch 113/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.1190 - val_accuracy: 0.9710\n",
            "Epoch 114/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0098 - accuracy: 0.9985 - val_loss: 0.1187 - val_accuracy: 0.9710\n",
            "Epoch 115/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0070 - accuracy: 0.9996 - val_loss: 0.1214 - val_accuracy: 0.9726\n",
            "Epoch 116/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 0.9992 - val_loss: 0.1203 - val_accuracy: 0.9695\n",
            "Epoch 117/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0084 - accuracy: 0.9989 - val_loss: 0.1190 - val_accuracy: 0.9710\n",
            "Epoch 118/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0072 - accuracy: 0.9996 - val_loss: 0.1184 - val_accuracy: 0.9726\n",
            "Epoch 119/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0067 - accuracy: 0.9996 - val_loss: 0.1197 - val_accuracy: 0.9710\n",
            "Epoch 120/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0075 - accuracy: 0.9992 - val_loss: 0.1202 - val_accuracy: 0.9710\n",
            "Epoch 121/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0063 - accuracy: 0.9996 - val_loss: 0.1219 - val_accuracy: 0.9726\n",
            "Epoch 122/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.1252 - val_accuracy: 0.9695\n",
            "Epoch 123/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0074 - accuracy: 0.9996 - val_loss: 0.1194 - val_accuracy: 0.9710\n",
            "Epoch 124/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0076 - accuracy: 0.9996 - val_loss: 0.1209 - val_accuracy: 0.9710\n",
            "Epoch 125/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0078 - accuracy: 0.9996 - val_loss: 0.1271 - val_accuracy: 0.9710\n",
            "Epoch 126/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0068 - accuracy: 0.9992 - val_loss: 0.1256 - val_accuracy: 0.9710\n",
            "Epoch 127/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0075 - accuracy: 0.9989 - val_loss: 0.1260 - val_accuracy: 0.9710\n",
            "Epoch 128/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.1227 - val_accuracy: 0.9726\n",
            "Epoch 129/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.1292 - val_accuracy: 0.9710\n",
            "Epoch 130/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0056 - accuracy: 0.9996 - val_loss: 0.1321 - val_accuracy: 0.9695\n",
            "Epoch 131/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.1258 - val_accuracy: 0.9710\n",
            "Epoch 132/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.1244 - val_accuracy: 0.9710\n",
            "Epoch 133/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.1280 - val_accuracy: 0.9695\n",
            "Epoch 134/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0059 - accuracy: 0.9996 - val_loss: 0.1256 - val_accuracy: 0.9695\n",
            "Epoch 135/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0068 - accuracy: 0.9992 - val_loss: 0.1275 - val_accuracy: 0.9710\n",
            "Epoch 136/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.1284 - val_accuracy: 0.9710\n",
            "Epoch 137/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0066 - accuracy: 0.9992 - val_loss: 0.1261 - val_accuracy: 0.9726\n",
            "Epoch 138/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0059 - accuracy: 0.9992 - val_loss: 0.1246 - val_accuracy: 0.9710\n",
            "Epoch 139/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 0.9996 - val_loss: 0.1249 - val_accuracy: 0.9695\n",
            "Epoch 140/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.1241 - val_accuracy: 0.9726\n",
            "Epoch 141/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1293 - val_accuracy: 0.9695\n",
            "Epoch 142/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9996 - val_loss: 0.1262 - val_accuracy: 0.9710\n",
            "Epoch 143/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0055 - accuracy: 0.9996 - val_loss: 0.1247 - val_accuracy: 0.9726\n",
            "Epoch 144/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.9996 - val_loss: 0.1233 - val_accuracy: 0.9741\n",
            "Epoch 145/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1268 - val_accuracy: 0.9710\n",
            "Epoch 146/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.1267 - val_accuracy: 0.9695\n",
            "Epoch 147/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0061 - accuracy: 0.9996 - val_loss: 0.1298 - val_accuracy: 0.9680\n",
            "Epoch 148/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1277 - val_accuracy: 0.9695\n",
            "Epoch 149/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0050 - accuracy: 0.9996 - val_loss: 0.1282 - val_accuracy: 0.9695\n",
            "Epoch 150/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0054 - accuracy: 0.9996 - val_loss: 0.1291 - val_accuracy: 0.9710\n",
            "Epoch 151/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0059 - accuracy: 0.9996 - val_loss: 0.1309 - val_accuracy: 0.9710\n",
            "Epoch 152/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 0.9996 - val_loss: 0.1331 - val_accuracy: 0.9710\n",
            "Epoch 153/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 0.1305 - val_accuracy: 0.9695\n",
            "Epoch 154/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1322 - val_accuracy: 0.9710\n",
            "Epoch 155/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0053 - accuracy: 0.9996 - val_loss: 0.1334 - val_accuracy: 0.9695\n",
            "Epoch 156/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1331 - val_accuracy: 0.9680\n",
            "Epoch 157/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0049 - accuracy: 0.9996 - val_loss: 0.1351 - val_accuracy: 0.9695\n",
            "Epoch 158/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.9996 - val_loss: 0.1345 - val_accuracy: 0.9695\n",
            "Epoch 159/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0048 - accuracy: 0.9996 - val_loss: 0.1316 - val_accuracy: 0.9695\n",
            "Epoch 160/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1353 - val_accuracy: 0.9695\n",
            "Epoch 161/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 0.9996 - val_loss: 0.1314 - val_accuracy: 0.9695\n",
            "Epoch 162/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.9996 - val_loss: 0.1296 - val_accuracy: 0.9695\n",
            "Epoch 163/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1344 - val_accuracy: 0.9695\n",
            "Epoch 164/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0046 - accuracy: 0.9996 - val_loss: 0.1294 - val_accuracy: 0.9710\n",
            "Epoch 165/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0046 - accuracy: 0.9996 - val_loss: 0.1323 - val_accuracy: 0.9695\n",
            "Epoch 166/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1333 - val_accuracy: 0.9710\n",
            "Epoch 167/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1361 - val_accuracy: 0.9695\n",
            "Epoch 168/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0047 - accuracy: 0.9996 - val_loss: 0.1323 - val_accuracy: 0.9710\n",
            "Epoch 169/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.1351 - val_accuracy: 0.9695\n",
            "Epoch 170/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.9996 - val_loss: 0.1322 - val_accuracy: 0.9695\n",
            "Epoch 171/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 0.1306 - val_accuracy: 0.9726\n",
            "Epoch 172/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 0.9996 - val_loss: 0.1347 - val_accuracy: 0.9695\n",
            "Epoch 173/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1354 - val_accuracy: 0.9695\n",
            "Epoch 174/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0046 - accuracy: 0.9996 - val_loss: 0.1326 - val_accuracy: 0.9680\n",
            "Epoch 175/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1285 - val_accuracy: 0.9726\n",
            "Epoch 176/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.9996 - val_loss: 0.1323 - val_accuracy: 0.9695\n",
            "Epoch 177/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1338 - val_accuracy: 0.9695\n",
            "Epoch 178/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1352 - val_accuracy: 0.9695\n",
            "Epoch 179/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1367 - val_accuracy: 0.9695\n",
            "Epoch 180/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1355 - val_accuracy: 0.9695\n",
            "Epoch 181/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1321 - val_accuracy: 0.9710\n",
            "Epoch 182/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1359 - val_accuracy: 0.9695\n",
            "Epoch 183/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1322 - val_accuracy: 0.9726\n",
            "Epoch 184/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1338 - val_accuracy: 0.9680\n",
            "Epoch 185/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1377 - val_accuracy: 0.9695\n",
            "Epoch 186/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1373 - val_accuracy: 0.9695\n",
            "Epoch 187/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 0.9996 - val_loss: 0.1351 - val_accuracy: 0.9680\n",
            "Epoch 188/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.1287 - val_accuracy: 0.9695\n",
            "Epoch 189/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1350 - val_accuracy: 0.9695\n",
            "Epoch 190/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1337 - val_accuracy: 0.9726\n",
            "Epoch 191/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0045 - accuracy: 0.9996 - val_loss: 0.1403 - val_accuracy: 0.9680\n",
            "Epoch 192/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 0.9996 - val_loss: 0.1336 - val_accuracy: 0.9710\n",
            "Epoch 193/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 0.9996 - val_loss: 0.1320 - val_accuracy: 0.9680\n",
            "Epoch 194/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1366 - val_accuracy: 0.9695\n",
            "Epoch 195/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1384 - val_accuracy: 0.9695\n",
            "Epoch 196/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1342 - val_accuracy: 0.9695\n",
            "Epoch 197/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0037 - accuracy: 0.9996 - val_loss: 0.1392 - val_accuracy: 0.9680\n",
            "Epoch 198/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1379 - val_accuracy: 0.9665\n",
            "Epoch 199/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.1394 - val_accuracy: 0.9665\n",
            "Epoch 200/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1360 - val_accuracy: 0.9695\n",
            "Epoch 201/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1394 - val_accuracy: 0.9680\n",
            "Epoch 202/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1407 - val_accuracy: 0.9680\n",
            "Epoch 203/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0032 - accuracy: 0.9996 - val_loss: 0.1364 - val_accuracy: 0.9695\n",
            "Epoch 204/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1356 - val_accuracy: 0.9726\n",
            "Epoch 205/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0031 - accuracy: 0.9996 - val_loss: 0.1349 - val_accuracy: 0.9695\n",
            "Epoch 206/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1355 - val_accuracy: 0.9726\n",
            "Epoch 207/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 0.9996 - val_loss: 0.1402 - val_accuracy: 0.9680\n",
            "Epoch 208/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 0.9996 - val_loss: 0.1416 - val_accuracy: 0.9680\n",
            "Epoch 209/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1399 - val_accuracy: 0.9680\n",
            "Epoch 210/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1379 - val_accuracy: 0.9695\n",
            "Epoch 211/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1351 - val_accuracy: 0.9726\n",
            "Epoch 212/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1352 - val_accuracy: 0.9680\n",
            "Epoch 213/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1410 - val_accuracy: 0.9695\n",
            "Epoch 214/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1410 - val_accuracy: 0.9680\n",
            "Epoch 215/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1401 - val_accuracy: 0.9695\n",
            "Epoch 216/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1391 - val_accuracy: 0.9680\n",
            "Epoch 217/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1394 - val_accuracy: 0.9680\n",
            "Epoch 218/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1420 - val_accuracy: 0.9680\n",
            "Epoch 219/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1385 - val_accuracy: 0.9680\n",
            "Epoch 220/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1408 - val_accuracy: 0.9695\n",
            "Epoch 221/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.9680\n",
            "Epoch 222/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1394 - val_accuracy: 0.9695\n",
            "Epoch 223/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1393 - val_accuracy: 0.9695\n",
            "Epoch 224/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1378 - val_accuracy: 0.9695\n",
            "Epoch 225/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 0.9996 - val_loss: 0.1425 - val_accuracy: 0.9695\n",
            "Epoch 226/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1410 - val_accuracy: 0.9680\n",
            "Epoch 227/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1393 - val_accuracy: 0.9680\n",
            "Epoch 228/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1400 - val_accuracy: 0.9680\n",
            "Epoch 229/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1408 - val_accuracy: 0.9695\n",
            "Epoch 230/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 0.9996 - val_loss: 0.1386 - val_accuracy: 0.9680\n",
            "Epoch 231/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1404 - val_accuracy: 0.9680\n",
            "Epoch 232/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1422 - val_accuracy: 0.9680\n",
            "Epoch 233/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.1401 - val_accuracy: 0.9680\n",
            "Epoch 234/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1435 - val_accuracy: 0.9695\n",
            "Epoch 235/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1359 - val_accuracy: 0.9695\n",
            "Epoch 236/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1405 - val_accuracy: 0.9695\n",
            "Epoch 237/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.1426 - val_accuracy: 0.9680\n",
            "Epoch 238/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1452 - val_accuracy: 0.9680\n",
            "Epoch 239/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1404 - val_accuracy: 0.9680\n",
            "Epoch 240/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1477 - val_accuracy: 0.9710\n",
            "Epoch 241/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 0.9996 - val_loss: 0.1436 - val_accuracy: 0.9695\n",
            "Epoch 242/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1468 - val_accuracy: 0.9695\n",
            "Epoch 243/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0028 - accuracy: 0.9996 - val_loss: 0.1434 - val_accuracy: 0.9680\n",
            "Epoch 244/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1467 - val_accuracy: 0.9680\n",
            "Epoch 245/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1450 - val_accuracy: 0.9695\n",
            "Epoch 246/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1439 - val_accuracy: 0.9680\n",
            "Epoch 247/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1473 - val_accuracy: 0.9695\n",
            "Epoch 248/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1439 - val_accuracy: 0.9695\n",
            "Epoch 249/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.1448 - val_accuracy: 0.9680\n",
            "Epoch 250/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1453 - val_accuracy: 0.9695\n",
            "Epoch 251/1000\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1485 - val_accuracy: 0.9680\n",
            "Epoch 252/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1450 - val_accuracy: 0.9680\n",
            "Epoch 253/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0030 - accuracy: 0.9996 - val_loss: 0.1431 - val_accuracy: 0.9680\n",
            "Epoch 254/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 0.9996 - val_loss: 0.1453 - val_accuracy: 0.9680\n",
            "Epoch 255/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1424 - val_accuracy: 0.9680\n",
            "Epoch 256/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 0.9996 - val_loss: 0.1441 - val_accuracy: 0.9680\n",
            "Epoch 257/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1478 - val_accuracy: 0.9680\n",
            "Epoch 258/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1475 - val_accuracy: 0.9695\n",
            "Epoch 259/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1456 - val_accuracy: 0.9680\n",
            "Epoch 260/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1482 - val_accuracy: 0.9680\n",
            "Epoch 261/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1491 - val_accuracy: 0.9680\n",
            "Epoch 262/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1475 - val_accuracy: 0.9680\n",
            "Epoch 263/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.1522 - val_accuracy: 0.9665\n",
            "Epoch 264/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1460 - val_accuracy: 0.9695\n",
            "Epoch 265/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1482 - val_accuracy: 0.9680\n",
            "Epoch 266/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1492 - val_accuracy: 0.9680\n",
            "Epoch 267/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1517 - val_accuracy: 0.9680\n",
            "Epoch 268/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 0.9996 - val_loss: 0.1482 - val_accuracy: 0.9680\n",
            "Epoch 269/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1505 - val_accuracy: 0.9680\n",
            "Epoch 270/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1514 - val_accuracy: 0.9680\n",
            "Epoch 271/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1513 - val_accuracy: 0.9680\n",
            "Epoch 272/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1490 - val_accuracy: 0.9680\n",
            "Epoch 273/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1468 - val_accuracy: 0.9710\n",
            "Epoch 274/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1488 - val_accuracy: 0.9680\n",
            "Epoch 275/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 0.9996 - val_loss: 0.1471 - val_accuracy: 0.9680\n",
            "Epoch 276/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1498 - val_accuracy: 0.9695\n",
            "Epoch 277/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1484 - val_accuracy: 0.9680\n",
            "Epoch 278/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.1518 - val_accuracy: 0.9665\n",
            "Epoch 279/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1490 - val_accuracy: 0.9680\n",
            "Epoch 280/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.1506 - val_accuracy: 0.9680\n",
            "Epoch 281/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1475 - val_accuracy: 0.9710\n",
            "Epoch 282/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1488 - val_accuracy: 0.9710\n",
            "Epoch 283/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1489 - val_accuracy: 0.9680\n",
            "Epoch 284/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9710\n",
            "Epoch 285/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1496 - val_accuracy: 0.9680\n",
            "Epoch 286/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1482 - val_accuracy: 0.9710\n",
            "Epoch 287/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1500 - val_accuracy: 0.9695\n",
            "Epoch 288/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1508 - val_accuracy: 0.9680\n",
            "Epoch 289/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1508 - val_accuracy: 0.9680\n",
            "Epoch 290/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1508 - val_accuracy: 0.9710\n",
            "Epoch 291/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9710\n",
            "Epoch 292/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1473 - val_accuracy: 0.9710\n",
            "Epoch 293/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1496 - val_accuracy: 0.9710\n",
            "Epoch 294/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1541 - val_accuracy: 0.9665\n",
            "Epoch 295/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1520 - val_accuracy: 0.9710\n",
            "Epoch 296/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9665\n",
            "Epoch 297/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.1469 - val_accuracy: 0.9710\n",
            "Epoch 298/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1512 - val_accuracy: 0.9680\n",
            "Epoch 299/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1506 - val_accuracy: 0.9710\n",
            "Epoch 300/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1506 - val_accuracy: 0.9695\n",
            "Epoch 301/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1512 - val_accuracy: 0.9710\n",
            "Epoch 302/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1524 - val_accuracy: 0.9710\n",
            "Epoch 303/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1553 - val_accuracy: 0.9665\n",
            "Epoch 304/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1511 - val_accuracy: 0.9695\n",
            "Epoch 305/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.1481 - val_accuracy: 0.9710\n",
            "Epoch 306/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.1507 - val_accuracy: 0.9695\n",
            "Epoch 307/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.1541 - val_accuracy: 0.9695\n",
            "Epoch 308/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1497 - val_accuracy: 0.9680\n",
            "Epoch 309/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.1513 - val_accuracy: 0.9695\n",
            "Epoch 310/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1515 - val_accuracy: 0.9710\n",
            "Epoch 311/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1536 - val_accuracy: 0.9695\n",
            "Epoch 312/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1555 - val_accuracy: 0.9665\n",
            "Epoch 313/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1536 - val_accuracy: 0.9710\n",
            "Epoch 314/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.1501 - val_accuracy: 0.9680\n",
            "Epoch 315/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1520 - val_accuracy: 0.9680\n",
            "Epoch 316/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1558 - val_accuracy: 0.9665\n",
            "Epoch 317/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1537 - val_accuracy: 0.9680\n",
            "Epoch 318/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1511 - val_accuracy: 0.9710\n",
            "Epoch 319/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1551 - val_accuracy: 0.9695\n",
            "Epoch 320/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.1546 - val_accuracy: 0.9680\n",
            "Epoch 321/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1551 - val_accuracy: 0.9680\n",
            "Epoch 322/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1551 - val_accuracy: 0.9680\n",
            "Epoch 323/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1506 - val_accuracy: 0.9680\n",
            "Epoch 324/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.1501 - val_accuracy: 0.9680\n",
            "Epoch 325/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1534 - val_accuracy: 0.9680\n",
            "Epoch 326/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.1505 - val_accuracy: 0.9710\n",
            "Epoch 327/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1531 - val_accuracy: 0.9680\n",
            "Epoch 328/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1532 - val_accuracy: 0.9680\n",
            "Epoch 329/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1511 - val_accuracy: 0.9680\n",
            "Epoch 330/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1528 - val_accuracy: 0.9680\n",
            "Epoch 331/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.1530 - val_accuracy: 0.9680\n",
            "Epoch 332/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1521 - val_accuracy: 0.9680\n",
            "Epoch 333/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1531 - val_accuracy: 0.9695\n",
            "Epoch 334/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1492 - val_accuracy: 0.9710\n",
            "Epoch 335/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1566 - val_accuracy: 0.9680\n",
            "Epoch 336/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.1548 - val_accuracy: 0.9680\n",
            "Epoch 337/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.1532 - val_accuracy: 0.9680\n",
            "Epoch 338/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1556 - val_accuracy: 0.9695\n",
            "Epoch 339/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1531 - val_accuracy: 0.9710\n",
            "Epoch 340/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1551 - val_accuracy: 0.9710\n",
            "Epoch 341/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1579 - val_accuracy: 0.9680\n",
            "Epoch 342/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1570 - val_accuracy: 0.9680\n",
            "Epoch 343/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1538 - val_accuracy: 0.9695\n",
            "Epoch 344/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1554 - val_accuracy: 0.9680\n",
            "Epoch 345/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1576 - val_accuracy: 0.9680\n",
            "Epoch 346/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1584 - val_accuracy: 0.9680\n",
            "Epoch 347/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1596 - val_accuracy: 0.9680\n",
            "Epoch 348/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.1514 - val_accuracy: 0.9710\n",
            "Epoch 349/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1601 - val_accuracy: 0.9695\n",
            "Epoch 350/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1557 - val_accuracy: 0.9710\n",
            "Epoch 351/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1546 - val_accuracy: 0.9710\n",
            "Epoch 352/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.1568 - val_accuracy: 0.9680\n",
            "Epoch 353/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1568 - val_accuracy: 0.9680\n",
            "Epoch 354/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1572 - val_accuracy: 0.9710\n",
            "Epoch 355/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1573 - val_accuracy: 0.9695\n",
            "Epoch 356/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1591 - val_accuracy: 0.9695\n",
            "Epoch 357/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1574 - val_accuracy: 0.9680\n",
            "Epoch 358/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1595 - val_accuracy: 0.9680\n",
            "Epoch 359/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1578 - val_accuracy: 0.9710\n",
            "Epoch 360/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1562 - val_accuracy: 0.9710\n",
            "Epoch 361/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1599 - val_accuracy: 0.9695\n",
            "Epoch 362/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1554 - val_accuracy: 0.9695\n",
            "Epoch 363/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1587 - val_accuracy: 0.9695\n",
            "Epoch 364/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1593 - val_accuracy: 0.9695\n",
            "Epoch 365/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1542 - val_accuracy: 0.9710\n",
            "Epoch 366/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1578 - val_accuracy: 0.9695\n",
            "Epoch 367/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1583 - val_accuracy: 0.9695\n",
            "Epoch 368/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1609 - val_accuracy: 0.9695\n",
            "Epoch 369/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1571 - val_accuracy: 0.9710\n",
            "Epoch 370/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 9.9724e-04 - accuracy: 1.0000 - val_loss: 0.1628 - val_accuracy: 0.9695\n",
            "Epoch 371/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1572 - val_accuracy: 0.9695\n",
            "Epoch 372/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1567 - val_accuracy: 0.9710\n",
            "Epoch 373/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1576 - val_accuracy: 0.9665\n",
            "Epoch 374/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1555 - val_accuracy: 0.9695\n",
            "Epoch 375/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1592 - val_accuracy: 0.9680\n",
            "Epoch 376/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.1567 - val_accuracy: 0.9695\n",
            "Epoch 377/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1591 - val_accuracy: 0.9695\n",
            "Epoch 378/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1601 - val_accuracy: 0.9665\n",
            "Epoch 379/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1585 - val_accuracy: 0.9710\n",
            "Epoch 380/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1609 - val_accuracy: 0.9680\n",
            "Epoch 381/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1592 - val_accuracy: 0.9695\n",
            "Epoch 382/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1603 - val_accuracy: 0.9695\n",
            "Epoch 383/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1592 - val_accuracy: 0.9695\n",
            "Epoch 384/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.1573 - val_accuracy: 0.9695\n",
            "Epoch 385/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.1560 - val_accuracy: 0.9695\n",
            "Epoch 386/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1599 - val_accuracy: 0.9680\n",
            "Epoch 387/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1591 - val_accuracy: 0.9695\n",
            "Epoch 388/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1552 - val_accuracy: 0.9695\n",
            "Epoch 389/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1566 - val_accuracy: 0.9695\n",
            "Epoch 390/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1609 - val_accuracy: 0.9695\n",
            "Epoch 391/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.9992 - val_loss: 0.1606 - val_accuracy: 0.9680\n",
            "Epoch 392/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1568 - val_accuracy: 0.9695\n",
            "Epoch 393/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1568 - val_accuracy: 0.9710\n",
            "Epoch 394/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1638 - val_accuracy: 0.9680\n",
            "Epoch 395/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1604 - val_accuracy: 0.9695\n",
            "Epoch 396/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1580 - val_accuracy: 0.9695\n",
            "Epoch 397/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1595 - val_accuracy: 0.9680\n",
            "Epoch 398/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1590 - val_accuracy: 0.9695\n",
            "Epoch 399/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1617 - val_accuracy: 0.9680\n",
            "Epoch 400/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1624 - val_accuracy: 0.9680\n",
            "Epoch 401/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.1559 - val_accuracy: 0.9710\n",
            "Epoch 402/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1570 - val_accuracy: 0.9695\n",
            "Epoch 403/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1614 - val_accuracy: 0.9680\n",
            "Epoch 404/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1590 - val_accuracy: 0.9695\n",
            "Epoch 405/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.1597 - val_accuracy: 0.9695\n",
            "Epoch 406/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1593 - val_accuracy: 0.9695\n",
            "Epoch 407/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1618 - val_accuracy: 0.9665\n",
            "Epoch 408/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.1534 - val_accuracy: 0.9695\n",
            "Epoch 409/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1590 - val_accuracy: 0.9695\n",
            "Epoch 410/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1599 - val_accuracy: 0.9695\n",
            "Epoch 411/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.9992 - val_loss: 0.1583 - val_accuracy: 0.9695\n",
            "Epoch 412/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1588 - val_accuracy: 0.9695\n",
            "Epoch 413/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1598 - val_accuracy: 0.9695\n",
            "Epoch 414/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1613 - val_accuracy: 0.9695\n",
            "Epoch 415/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1619 - val_accuracy: 0.9695\n",
            "Epoch 416/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.1631 - val_accuracy: 0.9695\n",
            "Epoch 417/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1627 - val_accuracy: 0.9695\n",
            "Epoch 418/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1580 - val_accuracy: 0.9710\n",
            "Epoch 419/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1616 - val_accuracy: 0.9695\n",
            "Epoch 420/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1609 - val_accuracy: 0.9695\n",
            "Epoch 421/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.1598 - val_accuracy: 0.9695\n",
            "Epoch 422/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.1590 - val_accuracy: 0.9695\n",
            "Epoch 423/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.1585 - val_accuracy: 0.9695\n",
            "Epoch 424/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 9.8485e-04 - accuracy: 1.0000 - val_loss: 0.1600 - val_accuracy: 0.9695\n",
            "Epoch 425/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1602 - val_accuracy: 0.9695\n",
            "Epoch 426/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1593 - val_accuracy: 0.9695\n",
            "Epoch 427/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1581 - val_accuracy: 0.9710\n",
            "Epoch 428/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1612 - val_accuracy: 0.9710\n",
            "Epoch 429/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1614 - val_accuracy: 0.9726\n",
            "Epoch 430/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1630 - val_accuracy: 0.9680\n",
            "Epoch 431/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1640 - val_accuracy: 0.9680\n",
            "Epoch 432/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1603 - val_accuracy: 0.9680\n",
            "Epoch 433/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1612 - val_accuracy: 0.9726\n",
            "Epoch 434/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.1597 - val_accuracy: 0.9695\n",
            "Epoch 435/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1673 - val_accuracy: 0.9695\n",
            "Epoch 436/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1622 - val_accuracy: 0.9695\n",
            "Epoch 437/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1652 - val_accuracy: 0.9695\n",
            "Epoch 438/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.1536 - val_accuracy: 0.9741\n",
            "Epoch 439/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1618 - val_accuracy: 0.9710\n",
            "Epoch 440/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1625 - val_accuracy: 0.9710\n",
            "Epoch 441/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1648 - val_accuracy: 0.9710\n",
            "Epoch 442/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1629 - val_accuracy: 0.9710\n",
            "Epoch 443/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.1554 - val_accuracy: 0.9695\n",
            "Epoch 444/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1595 - val_accuracy: 0.9695\n",
            "Epoch 445/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1617 - val_accuracy: 0.9695\n",
            "Epoch 446/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 9.4021e-04 - accuracy: 1.0000 - val_loss: 0.1644 - val_accuracy: 0.9710\n",
            "Epoch 447/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1621 - val_accuracy: 0.9710\n",
            "Epoch 448/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1642 - val_accuracy: 0.9680\n",
            "Epoch 449/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1635 - val_accuracy: 0.9680\n",
            "Epoch 450/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 8.4297e-04 - accuracy: 1.0000 - val_loss: 0.1631 - val_accuracy: 0.9680\n",
            "Epoch 451/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1632 - val_accuracy: 0.9680\n",
            "Epoch 452/1000\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1645 - val_accuracy: 0.9695\n",
            "Epoch 453/1000\n",
            "83/83 [==============================] - 2s 23ms/step - loss: 9.4689e-04 - accuracy: 1.0000 - val_loss: 0.1644 - val_accuracy: 0.9680\n",
            "Epoch 454/1000\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 9.6694e-04 - accuracy: 1.0000 - val_loss: 0.1656 - val_accuracy: 0.9680\n",
            "Epoch 455/1000\n",
            "83/83 [==============================] - 1s 9ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1699 - val_accuracy: 0.9710\n",
            "Epoch 456/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.1585 - val_accuracy: 0.9710\n",
            "Epoch 457/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1628 - val_accuracy: 0.9680\n",
            "Epoch 458/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1619 - val_accuracy: 0.9726\n",
            "Epoch 459/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1634 - val_accuracy: 0.9680\n",
            "Epoch 460/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.1634 - val_accuracy: 0.9680\n",
            "Epoch 461/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1630 - val_accuracy: 0.9680\n",
            "Epoch 462/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1628 - val_accuracy: 0.9680\n",
            "Epoch 463/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1621 - val_accuracy: 0.9680\n",
            "Epoch 464/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1639 - val_accuracy: 0.9680\n",
            "Epoch 465/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1648 - val_accuracy: 0.9680\n",
            "Epoch 466/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 9.6166e-04 - accuracy: 1.0000 - val_loss: 0.1630 - val_accuracy: 0.9695\n",
            "Epoch 467/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1638 - val_accuracy: 0.9680\n",
            "Epoch 468/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1674 - val_accuracy: 0.9680\n",
            "Epoch 469/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.1661 - val_accuracy: 0.9680\n",
            "Epoch 470/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1637 - val_accuracy: 0.9710\n",
            "Epoch 471/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1661 - val_accuracy: 0.9680\n",
            "Epoch 472/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 9.8653e-04 - accuracy: 1.0000 - val_loss: 0.1693 - val_accuracy: 0.9695\n",
            "Epoch 473/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1645 - val_accuracy: 0.9680\n",
            "Epoch 474/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 0.9992 - val_loss: 0.1644 - val_accuracy: 0.9680\n",
            "Epoch 475/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 9.1350e-04 - accuracy: 1.0000 - val_loss: 0.1663 - val_accuracy: 0.9680\n",
            "Epoch 476/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 9.2413e-04 - accuracy: 1.0000 - val_loss: 0.1657 - val_accuracy: 0.9680\n",
            "Epoch 477/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1641 - val_accuracy: 0.9695\n",
            "Epoch 478/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1651 - val_accuracy: 0.9680\n",
            "Epoch 479/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1705 - val_accuracy: 0.9695\n",
            "Epoch 480/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1633 - val_accuracy: 0.9695\n",
            "Epoch 481/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1631 - val_accuracy: 0.9695\n",
            "Epoch 482/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1647 - val_accuracy: 0.9680\n",
            "Epoch 483/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.1657 - val_accuracy: 0.9695\n",
            "Epoch 484/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 9.7589e-04 - accuracy: 1.0000 - val_loss: 0.1633 - val_accuracy: 0.9726\n",
            "Epoch 485/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1658 - val_accuracy: 0.9680\n",
            "Epoch 486/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 8.4813e-04 - accuracy: 1.0000 - val_loss: 0.1664 - val_accuracy: 0.9680\n",
            "Epoch 487/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1656 - val_accuracy: 0.9680\n",
            "Epoch 488/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 7.7642e-04 - accuracy: 1.0000 - val_loss: 0.1654 - val_accuracy: 0.9710\n",
            "Epoch 489/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.1669 - val_accuracy: 0.9695\n",
            "Epoch 490/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1670 - val_accuracy: 0.9695\n",
            "Epoch 491/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1660 - val_accuracy: 0.9680\n",
            "Epoch 492/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9695\n",
            "Epoch 493/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1663 - val_accuracy: 0.9680\n",
            "Epoch 494/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.1668 - val_accuracy: 0.9680\n",
            "Epoch 495/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1673 - val_accuracy: 0.9695\n",
            "Epoch 496/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1679 - val_accuracy: 0.9695\n",
            "Epoch 497/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1651 - val_accuracy: 0.9695\n",
            "Epoch 498/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 9.6157e-04 - accuracy: 1.0000 - val_loss: 0.1669 - val_accuracy: 0.9695\n",
            "Epoch 499/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1647 - val_accuracy: 0.9695\n",
            "Epoch 500/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 0.9992 - val_loss: 0.1667 - val_accuracy: 0.9680\n",
            "Epoch 501/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1676 - val_accuracy: 0.9665\n",
            "Epoch 502/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1668 - val_accuracy: 0.9665\n",
            "Epoch 503/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 8.6233e-04 - accuracy: 1.0000 - val_loss: 0.1686 - val_accuracy: 0.9665\n",
            "Epoch 504/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1665 - val_accuracy: 0.9680\n",
            "Epoch 505/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9680\n",
            "Epoch 506/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1663 - val_accuracy: 0.9680\n",
            "Epoch 507/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1664 - val_accuracy: 0.9695\n",
            "Epoch 508/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 8.9036e-04 - accuracy: 1.0000 - val_loss: 0.1678 - val_accuracy: 0.9680\n",
            "Epoch 509/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1610 - val_accuracy: 0.9710\n",
            "Epoch 510/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1633 - val_accuracy: 0.9695\n",
            "Epoch 511/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 9.5412e-04 - accuracy: 1.0000 - val_loss: 0.1646 - val_accuracy: 0.9695\n",
            "Epoch 512/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 7.6399e-04 - accuracy: 1.0000 - val_loss: 0.1662 - val_accuracy: 0.9695\n",
            "Epoch 513/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 9.4938e-04 - accuracy: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9680\n",
            "Epoch 514/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 8.6426e-04 - accuracy: 1.0000 - val_loss: 0.1675 - val_accuracy: 0.9680\n",
            "Epoch 515/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 7.4785e-04 - accuracy: 1.0000 - val_loss: 0.1697 - val_accuracy: 0.9680\n",
            "Epoch 516/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 9.1932e-04 - accuracy: 1.0000 - val_loss: 0.1689 - val_accuracy: 0.9695\n",
            "Epoch 517/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1651 - val_accuracy: 0.9695\n",
            "Epoch 518/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1654 - val_accuracy: 0.9710\n",
            "Epoch 519/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 7.9657e-04 - accuracy: 1.0000 - val_loss: 0.1686 - val_accuracy: 0.9680\n",
            "Epoch 520/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 9.9756e-04 - accuracy: 1.0000 - val_loss: 0.1672 - val_accuracy: 0.9680\n",
            "Epoch 521/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1599 - val_accuracy: 0.9710\n",
            "Epoch 522/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1558 - val_accuracy: 0.9710\n",
            "Epoch 523/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1614 - val_accuracy: 0.9695\n",
            "Epoch 524/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1617 - val_accuracy: 0.9710\n",
            "Epoch 525/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 8.5791e-04 - accuracy: 1.0000 - val_loss: 0.1635 - val_accuracy: 0.9710\n",
            "Epoch 526/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.1640 - val_accuracy: 0.9680\n",
            "Epoch 527/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 9.9312e-04 - accuracy: 1.0000 - val_loss: 0.1599 - val_accuracy: 0.9726\n",
            "Epoch 528/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1623 - val_accuracy: 0.9695\n",
            "Epoch 529/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 9.1655e-04 - accuracy: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9695\n",
            "Epoch 530/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 9.1961e-04 - accuracy: 1.0000 - val_loss: 0.1670 - val_accuracy: 0.9695\n",
            "Epoch 531/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1638 - val_accuracy: 0.9726\n",
            "Epoch 532/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 9.6319e-04 - accuracy: 1.0000 - val_loss: 0.1669 - val_accuracy: 0.9680\n",
            "Epoch 533/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 8.6530e-04 - accuracy: 1.0000 - val_loss: 0.1660 - val_accuracy: 0.9695\n",
            "Epoch 534/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 9.9874e-04 - accuracy: 1.0000 - val_loss: 0.1674 - val_accuracy: 0.9680\n",
            "Epoch 535/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1639 - val_accuracy: 0.9695\n",
            "Epoch 536/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1610 - val_accuracy: 0.9710\n",
            "Epoch 537/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1643 - val_accuracy: 0.9695\n",
            "Epoch 538/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9695\n",
            "Epoch 539/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 9.1015e-04 - accuracy: 1.0000 - val_loss: 0.1700 - val_accuracy: 0.9695\n",
            "Epoch 540/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 9.7575e-04 - accuracy: 1.0000 - val_loss: 0.1677 - val_accuracy: 0.9695\n",
            "Epoch 541/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 9.5961e-04 - accuracy: 1.0000 - val_loss: 0.1665 - val_accuracy: 0.9695\n",
            "Epoch 542/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1672 - val_accuracy: 0.9680\n",
            "Epoch 543/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 9.1705e-04 - accuracy: 1.0000 - val_loss: 0.1668 - val_accuracy: 0.9710\n",
            "Epoch 544/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 8.4967e-04 - accuracy: 1.0000 - val_loss: 0.1666 - val_accuracy: 0.9695\n",
            "Epoch 545/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 8.6567e-04 - accuracy: 1.0000 - val_loss: 0.1673 - val_accuracy: 0.9680\n",
            "Epoch 546/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.1664 - val_accuracy: 0.9680\n",
            "Epoch 547/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 9.1654e-04 - accuracy: 1.0000 - val_loss: 0.1686 - val_accuracy: 0.9680\n",
            "Epoch 548/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.1676 - val_accuracy: 0.9695\n",
            "Epoch 549/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1679 - val_accuracy: 0.9695\n",
            "Epoch 550/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1661 - val_accuracy: 0.9710\n",
            "Epoch 551/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 7.0168e-04 - accuracy: 1.0000 - val_loss: 0.1683 - val_accuracy: 0.9710\n",
            "Epoch 552/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1687 - val_accuracy: 0.9695\n",
            "Epoch 553/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1685 - val_accuracy: 0.9695\n",
            "Epoch 554/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1694 - val_accuracy: 0.9695\n",
            "Epoch 555/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 9.1089e-04 - accuracy: 1.0000 - val_loss: 0.1693 - val_accuracy: 0.9695\n",
            "Epoch 556/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1702 - val_accuracy: 0.9695\n",
            "Epoch 557/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.1718 - val_accuracy: 0.9680\n",
            "Epoch 558/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 9.5863e-04 - accuracy: 1.0000 - val_loss: 0.1706 - val_accuracy: 0.9680\n",
            "Epoch 559/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 9.4761e-04 - accuracy: 1.0000 - val_loss: 0.1697 - val_accuracy: 0.9695\n",
            "Epoch 560/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.1662 - val_accuracy: 0.9695\n",
            "Epoch 561/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 7.7526e-04 - accuracy: 1.0000 - val_loss: 0.1680 - val_accuracy: 0.9695\n",
            "Epoch 562/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 8.3955e-04 - accuracy: 1.0000 - val_loss: 0.1697 - val_accuracy: 0.9680\n",
            "Epoch 563/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 8.8145e-04 - accuracy: 1.0000 - val_loss: 0.1705 - val_accuracy: 0.9695\n",
            "Epoch 564/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.1694 - val_accuracy: 0.9680\n",
            "Epoch 565/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 7.2320e-04 - accuracy: 1.0000 - val_loss: 0.1717 - val_accuracy: 0.9695\n",
            "Epoch 566/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1730 - val_accuracy: 0.9695\n",
            "Epoch 567/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1707 - val_accuracy: 0.9680\n",
            "Epoch 568/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 7.4440e-04 - accuracy: 1.0000 - val_loss: 0.1701 - val_accuracy: 0.9695\n",
            "Epoch 569/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.1683 - val_accuracy: 0.9680\n",
            "Epoch 570/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 9.5172e-04 - accuracy: 0.9996 - val_loss: 0.1697 - val_accuracy: 0.9680\n",
            "Epoch 571/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 8.9666e-04 - accuracy: 1.0000 - val_loss: 0.1699 - val_accuracy: 0.9680\n",
            "Epoch 572/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 8.9189e-04 - accuracy: 1.0000 - val_loss: 0.1685 - val_accuracy: 0.9680\n",
            "Epoch 573/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 7.4140e-04 - accuracy: 1.0000 - val_loss: 0.1715 - val_accuracy: 0.9680\n",
            "Epoch 574/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 8.3160e-04 - accuracy: 1.0000 - val_loss: 0.1703 - val_accuracy: 0.9695\n",
            "Epoch 575/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 8.8756e-04 - accuracy: 1.0000 - val_loss: 0.1710 - val_accuracy: 0.9680\n",
            "Epoch 576/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.1729 - val_accuracy: 0.9695\n",
            "Epoch 577/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 9.4561e-04 - accuracy: 1.0000 - val_loss: 0.1695 - val_accuracy: 0.9695\n",
            "Epoch 578/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 7.2818e-04 - accuracy: 1.0000 - val_loss: 0.1734 - val_accuracy: 0.9695\n",
            "Epoch 579/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 6.3934e-04 - accuracy: 1.0000 - val_loss: 0.1736 - val_accuracy: 0.9695\n",
            "Epoch 580/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 8.6523e-04 - accuracy: 1.0000 - val_loss: 0.1700 - val_accuracy: 0.9680\n",
            "Epoch 581/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 8.6940e-04 - accuracy: 1.0000 - val_loss: 0.1706 - val_accuracy: 0.9680\n",
            "Epoch 582/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 6.2013e-04 - accuracy: 1.0000 - val_loss: 0.1711 - val_accuracy: 0.9695\n",
            "Epoch 583/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 8.8251e-04 - accuracy: 1.0000 - val_loss: 0.1746 - val_accuracy: 0.9695\n",
            "Epoch 584/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1704 - val_accuracy: 0.9710\n",
            "Epoch 585/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1694 - val_accuracy: 0.9695\n",
            "Epoch 586/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1724 - val_accuracy: 0.9695\n",
            "Epoch 587/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.1721 - val_accuracy: 0.9695\n",
            "Epoch 588/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 8.0681e-04 - accuracy: 1.0000 - val_loss: 0.1715 - val_accuracy: 0.9680\n",
            "Epoch 589/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1748 - val_accuracy: 0.9695\n",
            "Epoch 590/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 8.5291e-04 - accuracy: 1.0000 - val_loss: 0.1710 - val_accuracy: 0.9695\n",
            "Epoch 591/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 7.4989e-04 - accuracy: 1.0000 - val_loss: 0.1737 - val_accuracy: 0.9695\n",
            "Epoch 592/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 8.9284e-04 - accuracy: 1.0000 - val_loss: 0.1723 - val_accuracy: 0.9695\n",
            "Epoch 593/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 7.2825e-04 - accuracy: 1.0000 - val_loss: 0.1729 - val_accuracy: 0.9680\n",
            "Epoch 594/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 8.8225e-04 - accuracy: 1.0000 - val_loss: 0.1738 - val_accuracy: 0.9695\n",
            "Epoch 595/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 8.6203e-04 - accuracy: 1.0000 - val_loss: 0.1739 - val_accuracy: 0.9680\n",
            "Epoch 596/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 8.0624e-04 - accuracy: 1.0000 - val_loss: 0.1702 - val_accuracy: 0.9680\n",
            "Epoch 597/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 7.1550e-04 - accuracy: 1.0000 - val_loss: 0.1711 - val_accuracy: 0.9695\n",
            "Epoch 598/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.1728 - val_accuracy: 0.9695\n",
            "Epoch 599/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 8.7914e-04 - accuracy: 1.0000 - val_loss: 0.1705 - val_accuracy: 0.9710\n",
            "Epoch 600/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 7.7800e-04 - accuracy: 1.0000 - val_loss: 0.1712 - val_accuracy: 0.9695\n",
            "Epoch 601/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 6.7971e-04 - accuracy: 1.0000 - val_loss: 0.1710 - val_accuracy: 0.9726\n",
            "Epoch 602/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 7.6778e-04 - accuracy: 1.0000 - val_loss: 0.1748 - val_accuracy: 0.9680\n",
            "Epoch 603/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 8.1053e-04 - accuracy: 1.0000 - val_loss: 0.1741 - val_accuracy: 0.9680\n",
            "Epoch 604/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 6.9608e-04 - accuracy: 1.0000 - val_loss: 0.1688 - val_accuracy: 0.9726\n",
            "Epoch 605/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 8.2213e-04 - accuracy: 1.0000 - val_loss: 0.1739 - val_accuracy: 0.9665\n",
            "Epoch 606/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.1718 - val_accuracy: 0.9695\n",
            "Epoch 607/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 8.9550e-04 - accuracy: 1.0000 - val_loss: 0.1727 - val_accuracy: 0.9680\n",
            "Epoch 608/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 8.5924e-04 - accuracy: 1.0000 - val_loss: 0.1752 - val_accuracy: 0.9680\n",
            "Epoch 609/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 6.9796e-04 - accuracy: 1.0000 - val_loss: 0.1729 - val_accuracy: 0.9710\n",
            "Epoch 610/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1732 - val_accuracy: 0.9680\n",
            "Epoch 611/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 6.1541e-04 - accuracy: 1.0000 - val_loss: 0.1744 - val_accuracy: 0.9680\n",
            "Epoch 612/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 9.5251e-04 - accuracy: 1.0000 - val_loss: 0.1739 - val_accuracy: 0.9680\n",
            "Epoch 613/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 7.0589e-04 - accuracy: 1.0000 - val_loss: 0.1756 - val_accuracy: 0.9695\n",
            "Epoch 614/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 8.5533e-04 - accuracy: 1.0000 - val_loss: 0.1744 - val_accuracy: 0.9680\n",
            "Epoch 615/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 6.0340e-04 - accuracy: 1.0000 - val_loss: 0.1763 - val_accuracy: 0.9680\n",
            "Epoch 616/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.1723 - val_accuracy: 0.9680\n",
            "Epoch 617/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 7.8034e-04 - accuracy: 1.0000 - val_loss: 0.1714 - val_accuracy: 0.9680\n",
            "Epoch 618/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 9.6124e-04 - accuracy: 1.0000 - val_loss: 0.1713 - val_accuracy: 0.9695\n",
            "Epoch 619/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 7.0550e-04 - accuracy: 1.0000 - val_loss: 0.1740 - val_accuracy: 0.9695\n",
            "Epoch 620/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 5.9671e-04 - accuracy: 1.0000 - val_loss: 0.1742 - val_accuracy: 0.9680\n",
            "Epoch 621/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 8.6128e-04 - accuracy: 1.0000 - val_loss: 0.1716 - val_accuracy: 0.9726\n",
            "Epoch 622/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1730 - val_accuracy: 0.9680\n",
            "Epoch 623/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 9.1076e-04 - accuracy: 1.0000 - val_loss: 0.1727 - val_accuracy: 0.9680\n",
            "Epoch 624/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 9.5114e-04 - accuracy: 1.0000 - val_loss: 0.1712 - val_accuracy: 0.9665\n",
            "Epoch 625/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 6.5209e-04 - accuracy: 1.0000 - val_loss: 0.1705 - val_accuracy: 0.9710\n",
            "Epoch 626/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 9.3537e-04 - accuracy: 1.0000 - val_loss: 0.1708 - val_accuracy: 0.9710\n",
            "Epoch 627/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 7.1715e-04 - accuracy: 1.0000 - val_loss: 0.1729 - val_accuracy: 0.9695\n",
            "Epoch 628/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1731 - val_accuracy: 0.9680\n",
            "Epoch 629/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 7.7410e-04 - accuracy: 1.0000 - val_loss: 0.1738 - val_accuracy: 0.9680\n",
            "Epoch 630/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.1723 - val_accuracy: 0.9695\n",
            "Epoch 631/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 8.5405e-04 - accuracy: 1.0000 - val_loss: 0.1720 - val_accuracy: 0.9710\n",
            "Epoch 632/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 5.7530e-04 - accuracy: 1.0000 - val_loss: 0.1732 - val_accuracy: 0.9710\n",
            "Epoch 633/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 7.3051e-04 - accuracy: 1.0000 - val_loss: 0.1765 - val_accuracy: 0.9680\n",
            "Epoch 634/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 8.3637e-04 - accuracy: 1.0000 - val_loss: 0.1757 - val_accuracy: 0.9680\n",
            "Epoch 635/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 9.4122e-04 - accuracy: 1.0000 - val_loss: 0.1737 - val_accuracy: 0.9695\n",
            "Epoch 636/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 0.9992 - val_loss: 0.1712 - val_accuracy: 0.9695\n",
            "Epoch 637/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 8.8927e-04 - accuracy: 1.0000 - val_loss: 0.1753 - val_accuracy: 0.9695\n",
            "Epoch 638/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1739 - val_accuracy: 0.9695\n",
            "Epoch 639/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1738 - val_accuracy: 0.9695\n",
            "Epoch 640/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 7.9036e-04 - accuracy: 1.0000 - val_loss: 0.1722 - val_accuracy: 0.9695\n",
            "Epoch 641/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 7.2164e-04 - accuracy: 1.0000 - val_loss: 0.1760 - val_accuracy: 0.9680\n",
            "Epoch 642/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 9.5624e-04 - accuracy: 1.0000 - val_loss: 0.1747 - val_accuracy: 0.9695\n",
            "Epoch 643/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 8.7275e-04 - accuracy: 1.0000 - val_loss: 0.1813 - val_accuracy: 0.9695\n",
            "Epoch 644/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 7.4581e-04 - accuracy: 1.0000 - val_loss: 0.1774 - val_accuracy: 0.9695\n",
            "Epoch 645/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 7.2504e-04 - accuracy: 1.0000 - val_loss: 0.1765 - val_accuracy: 0.9680\n",
            "Epoch 646/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 6.2341e-04 - accuracy: 1.0000 - val_loss: 0.1766 - val_accuracy: 0.9680\n",
            "Epoch 647/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 8.9717e-04 - accuracy: 1.0000 - val_loss: 0.1755 - val_accuracy: 0.9665\n",
            "Epoch 648/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 6.8959e-04 - accuracy: 1.0000 - val_loss: 0.1750 - val_accuracy: 0.9680\n",
            "Epoch 649/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 9.3273e-04 - accuracy: 1.0000 - val_loss: 0.1763 - val_accuracy: 0.9695\n",
            "Epoch 650/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 9.3346e-04 - accuracy: 1.0000 - val_loss: 0.1744 - val_accuracy: 0.9695\n",
            "Epoch 651/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.1797 - val_accuracy: 0.9695\n",
            "Epoch 652/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 8.6334e-04 - accuracy: 1.0000 - val_loss: 0.1760 - val_accuracy: 0.9680\n",
            "Epoch 653/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 7.8561e-04 - accuracy: 1.0000 - val_loss: 0.1754 - val_accuracy: 0.9680\n",
            "Epoch 654/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 6.6116e-04 - accuracy: 1.0000 - val_loss: 0.1778 - val_accuracy: 0.9680\n",
            "Epoch 655/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 6.0998e-04 - accuracy: 1.0000 - val_loss: 0.1767 - val_accuracy: 0.9710\n",
            "Epoch 656/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 8.9783e-04 - accuracy: 0.9996 - val_loss: 0.1757 - val_accuracy: 0.9680\n",
            "Epoch 657/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 8.3687e-04 - accuracy: 1.0000 - val_loss: 0.1757 - val_accuracy: 0.9680\n",
            "Epoch 658/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 8.9413e-04 - accuracy: 1.0000 - val_loss: 0.1742 - val_accuracy: 0.9695\n",
            "Epoch 659/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 4.8706e-04 - accuracy: 1.0000 - val_loss: 0.1760 - val_accuracy: 0.9680\n",
            "Epoch 660/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 5.3880e-04 - accuracy: 1.0000 - val_loss: 0.1771 - val_accuracy: 0.9695\n",
            "Epoch 661/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 7.5567e-04 - accuracy: 1.0000 - val_loss: 0.1800 - val_accuracy: 0.9695\n",
            "Epoch 662/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 9.0964e-04 - accuracy: 1.0000 - val_loss: 0.1742 - val_accuracy: 0.9695\n",
            "Epoch 663/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 5.9187e-04 - accuracy: 1.0000 - val_loss: 0.1741 - val_accuracy: 0.9695\n",
            "Epoch 664/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 6.9085e-04 - accuracy: 1.0000 - val_loss: 0.1752 - val_accuracy: 0.9695\n",
            "Epoch 665/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1730 - val_accuracy: 0.9695\n",
            "Epoch 666/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 6.0558e-04 - accuracy: 1.0000 - val_loss: 0.1754 - val_accuracy: 0.9695\n",
            "Epoch 667/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 7.5254e-04 - accuracy: 1.0000 - val_loss: 0.1770 - val_accuracy: 0.9680\n",
            "Epoch 668/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 6.5347e-04 - accuracy: 1.0000 - val_loss: 0.1774 - val_accuracy: 0.9680\n",
            "Epoch 669/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 6.8735e-04 - accuracy: 1.0000 - val_loss: 0.1781 - val_accuracy: 0.9680\n",
            "Epoch 670/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 9.6184e-04 - accuracy: 1.0000 - val_loss: 0.1796 - val_accuracy: 0.9680\n",
            "Epoch 671/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 8.6993e-04 - accuracy: 1.0000 - val_loss: 0.1761 - val_accuracy: 0.9710\n",
            "Epoch 672/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 7.4097e-04 - accuracy: 1.0000 - val_loss: 0.1780 - val_accuracy: 0.9695\n",
            "Epoch 673/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.1752 - val_accuracy: 0.9680\n",
            "Epoch 674/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 5.3971e-04 - accuracy: 1.0000 - val_loss: 0.1768 - val_accuracy: 0.9680\n",
            "Epoch 675/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 9.4414e-04 - accuracy: 1.0000 - val_loss: 0.1830 - val_accuracy: 0.9695\n",
            "Epoch 676/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 8.6438e-04 - accuracy: 1.0000 - val_loss: 0.1767 - val_accuracy: 0.9695\n",
            "Epoch 677/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 8.0832e-04 - accuracy: 1.0000 - val_loss: 0.1765 - val_accuracy: 0.9695\n",
            "Epoch 678/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 9.7273e-04 - accuracy: 1.0000 - val_loss: 0.1776 - val_accuracy: 0.9680\n",
            "Epoch 679/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 7.0714e-04 - accuracy: 1.0000 - val_loss: 0.1760 - val_accuracy: 0.9710\n",
            "Epoch 680/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.1734 - val_accuracy: 0.9726\n",
            "Epoch 681/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1746 - val_accuracy: 0.9695\n",
            "Epoch 682/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 7.4051e-04 - accuracy: 1.0000 - val_loss: 0.1756 - val_accuracy: 0.9695\n",
            "Epoch 683/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 9.4654e-04 - accuracy: 1.0000 - val_loss: 0.1763 - val_accuracy: 0.9695\n",
            "Epoch 684/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 7.3941e-04 - accuracy: 1.0000 - val_loss: 0.1762 - val_accuracy: 0.9695\n",
            "Epoch 685/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 6.4808e-04 - accuracy: 1.0000 - val_loss: 0.1769 - val_accuracy: 0.9695\n",
            "Epoch 686/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 8.7803e-04 - accuracy: 1.0000 - val_loss: 0.1783 - val_accuracy: 0.9680\n",
            "Epoch 687/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 6.8371e-04 - accuracy: 1.0000 - val_loss: 0.1783 - val_accuracy: 0.9695\n",
            "Epoch 688/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 7.7146e-04 - accuracy: 1.0000 - val_loss: 0.1763 - val_accuracy: 0.9680\n",
            "Epoch 689/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 6.7494e-04 - accuracy: 1.0000 - val_loss: 0.1780 - val_accuracy: 0.9695\n",
            "Epoch 690/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 7.2929e-04 - accuracy: 1.0000 - val_loss: 0.1776 - val_accuracy: 0.9680\n",
            "Epoch 691/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 9.1576e-04 - accuracy: 0.9996 - val_loss: 0.1802 - val_accuracy: 0.9695\n",
            "Epoch 692/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 6.2153e-04 - accuracy: 1.0000 - val_loss: 0.1798 - val_accuracy: 0.9695\n",
            "Epoch 693/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 4.9683e-04 - accuracy: 1.0000 - val_loss: 0.1800 - val_accuracy: 0.9695\n",
            "Epoch 694/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 7.4225e-04 - accuracy: 1.0000 - val_loss: 0.1790 - val_accuracy: 0.9695\n",
            "Epoch 695/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 9.9114e-04 - accuracy: 1.0000 - val_loss: 0.1759 - val_accuracy: 0.9710\n",
            "Epoch 696/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 7.5280e-04 - accuracy: 1.0000 - val_loss: 0.1749 - val_accuracy: 0.9695\n",
            "Epoch 697/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 5.7062e-04 - accuracy: 1.0000 - val_loss: 0.1762 - val_accuracy: 0.9695\n",
            "Epoch 698/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 5.1815e-04 - accuracy: 1.0000 - val_loss: 0.1766 - val_accuracy: 0.9695\n",
            "Epoch 699/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 6.6150e-04 - accuracy: 1.0000 - val_loss: 0.1798 - val_accuracy: 0.9710\n",
            "Epoch 700/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 6.5058e-04 - accuracy: 1.0000 - val_loss: 0.1812 - val_accuracy: 0.9695\n",
            "Epoch 701/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 7.1032e-04 - accuracy: 1.0000 - val_loss: 0.1790 - val_accuracy: 0.9710\n",
            "Epoch 702/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 4.1452e-04 - accuracy: 1.0000 - val_loss: 0.1794 - val_accuracy: 0.9710\n",
            "Epoch 703/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 8.7586e-04 - accuracy: 1.0000 - val_loss: 0.1818 - val_accuracy: 0.9695\n",
            "Epoch 704/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 6.9742e-04 - accuracy: 1.0000 - val_loss: 0.1816 - val_accuracy: 0.9695\n",
            "Epoch 705/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 7.2344e-04 - accuracy: 1.0000 - val_loss: 0.1829 - val_accuracy: 0.9695\n",
            "Epoch 706/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 7.3205e-04 - accuracy: 1.0000 - val_loss: 0.1810 - val_accuracy: 0.9695\n",
            "Epoch 707/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 6.4397e-04 - accuracy: 1.0000 - val_loss: 0.1802 - val_accuracy: 0.9695\n",
            "Epoch 708/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 7.4341e-04 - accuracy: 1.0000 - val_loss: 0.1755 - val_accuracy: 0.9695\n",
            "Epoch 709/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 7.5072e-04 - accuracy: 1.0000 - val_loss: 0.1764 - val_accuracy: 0.9695\n",
            "Epoch 710/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.1781 - val_accuracy: 0.9695\n",
            "Epoch 711/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 7.2538e-04 - accuracy: 1.0000 - val_loss: 0.1786 - val_accuracy: 0.9710\n",
            "Epoch 712/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 7.6930e-04 - accuracy: 1.0000 - val_loss: 0.1816 - val_accuracy: 0.9680\n",
            "Epoch 713/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 7.4067e-04 - accuracy: 1.0000 - val_loss: 0.1785 - val_accuracy: 0.9695\n",
            "Epoch 714/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 6.9359e-04 - accuracy: 1.0000 - val_loss: 0.1781 - val_accuracy: 0.9680\n",
            "Epoch 715/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 5.3947e-04 - accuracy: 1.0000 - val_loss: 0.1780 - val_accuracy: 0.9695\n",
            "Epoch 716/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 7.3941e-04 - accuracy: 1.0000 - val_loss: 0.1796 - val_accuracy: 0.9680\n",
            "Epoch 717/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 7.1917e-04 - accuracy: 1.0000 - val_loss: 0.1813 - val_accuracy: 0.9680\n",
            "Epoch 718/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 8.0973e-04 - accuracy: 1.0000 - val_loss: 0.1780 - val_accuracy: 0.9695\n",
            "Epoch 719/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 8.0808e-04 - accuracy: 1.0000 - val_loss: 0.1782 - val_accuracy: 0.9695\n",
            "Epoch 720/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 6.6141e-04 - accuracy: 1.0000 - val_loss: 0.1799 - val_accuracy: 0.9680\n",
            "Epoch 721/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 8.9020e-04 - accuracy: 0.9996 - val_loss: 0.1784 - val_accuracy: 0.9680\n",
            "Epoch 722/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 7.8661e-04 - accuracy: 1.0000 - val_loss: 0.1734 - val_accuracy: 0.9710\n",
            "Epoch 723/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 6.6533e-04 - accuracy: 1.0000 - val_loss: 0.1767 - val_accuracy: 0.9710\n",
            "Epoch 724/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 7.9216e-04 - accuracy: 1.0000 - val_loss: 0.1799 - val_accuracy: 0.9695\n",
            "Epoch 725/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 6.4542e-04 - accuracy: 1.0000 - val_loss: 0.1788 - val_accuracy: 0.9710\n",
            "Epoch 726/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 8.9596e-04 - accuracy: 0.9996 - val_loss: 0.1776 - val_accuracy: 0.9710\n",
            "Epoch 727/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 6.3862e-04 - accuracy: 1.0000 - val_loss: 0.1777 - val_accuracy: 0.9710\n",
            "Epoch 728/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 5.8139e-04 - accuracy: 1.0000 - val_loss: 0.1785 - val_accuracy: 0.9710\n",
            "Epoch 729/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 6.9108e-04 - accuracy: 1.0000 - val_loss: 0.1781 - val_accuracy: 0.9710\n",
            "Epoch 730/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 5.9193e-04 - accuracy: 1.0000 - val_loss: 0.1785 - val_accuracy: 0.9726\n",
            "Epoch 731/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 7.5519e-04 - accuracy: 1.0000 - val_loss: 0.1789 - val_accuracy: 0.9710\n",
            "Epoch 732/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 5.7095e-04 - accuracy: 1.0000 - val_loss: 0.1776 - val_accuracy: 0.9710\n",
            "Epoch 733/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 5.9089e-04 - accuracy: 1.0000 - val_loss: 0.1792 - val_accuracy: 0.9695\n",
            "Epoch 734/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 5.7829e-04 - accuracy: 1.0000 - val_loss: 0.1769 - val_accuracy: 0.9726\n",
            "Epoch 735/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 7.1427e-04 - accuracy: 1.0000 - val_loss: 0.1772 - val_accuracy: 0.9710\n",
            "Epoch 736/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 6.5277e-04 - accuracy: 1.0000 - val_loss: 0.1768 - val_accuracy: 0.9710\n",
            "Epoch 737/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 5.7565e-04 - accuracy: 1.0000 - val_loss: 0.1776 - val_accuracy: 0.9710\n",
            "Epoch 738/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 5.3731e-04 - accuracy: 1.0000 - val_loss: 0.1798 - val_accuracy: 0.9695\n",
            "Epoch 739/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 7.8851e-04 - accuracy: 1.0000 - val_loss: 0.1799 - val_accuracy: 0.9695\n",
            "Epoch 740/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 0.1797 - val_accuracy: 0.9710\n",
            "Epoch 741/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1769 - val_accuracy: 0.9710\n",
            "Epoch 742/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 4.9187e-04 - accuracy: 1.0000 - val_loss: 0.1780 - val_accuracy: 0.9710\n",
            "Epoch 743/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 6.0741e-04 - accuracy: 1.0000 - val_loss: 0.1777 - val_accuracy: 0.9695\n",
            "Epoch 744/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 5.7968e-04 - accuracy: 1.0000 - val_loss: 0.1785 - val_accuracy: 0.9710\n",
            "Epoch 745/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 9.4867e-04 - accuracy: 1.0000 - val_loss: 0.1803 - val_accuracy: 0.9695\n",
            "Epoch 746/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 6.0513e-04 - accuracy: 1.0000 - val_loss: 0.1819 - val_accuracy: 0.9695\n",
            "Epoch 747/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 6.5461e-04 - accuracy: 1.0000 - val_loss: 0.1811 - val_accuracy: 0.9695\n",
            "Epoch 748/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 6.3864e-04 - accuracy: 1.0000 - val_loss: 0.1787 - val_accuracy: 0.9710\n",
            "Epoch 749/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 7.2926e-04 - accuracy: 1.0000 - val_loss: 0.1812 - val_accuracy: 0.9710\n",
            "Epoch 750/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 6.3715e-04 - accuracy: 1.0000 - val_loss: 0.1805 - val_accuracy: 0.9695\n",
            "Epoch 751/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 5.1655e-04 - accuracy: 1.0000 - val_loss: 0.1804 - val_accuracy: 0.9695\n",
            "Epoch 752/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 9.2649e-04 - accuracy: 0.9996 - val_loss: 0.1784 - val_accuracy: 0.9710\n",
            "Epoch 753/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 9.0480e-04 - accuracy: 1.0000 - val_loss: 0.1811 - val_accuracy: 0.9680\n",
            "Epoch 754/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 7.0924e-04 - accuracy: 1.0000 - val_loss: 0.1770 - val_accuracy: 0.9710\n",
            "Epoch 755/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 7.4902e-04 - accuracy: 1.0000 - val_loss: 0.1777 - val_accuracy: 0.9726\n",
            "Epoch 756/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 5.9581e-04 - accuracy: 1.0000 - val_loss: 0.1767 - val_accuracy: 0.9695\n",
            "Epoch 757/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 7.7157e-04 - accuracy: 1.0000 - val_loss: 0.1776 - val_accuracy: 0.9695\n",
            "Epoch 758/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 5.6452e-04 - accuracy: 1.0000 - val_loss: 0.1792 - val_accuracy: 0.9710\n",
            "Epoch 759/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 5.0655e-04 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 0.9695\n",
            "Epoch 760/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 7.8530e-04 - accuracy: 1.0000 - val_loss: 0.1807 - val_accuracy: 0.9710\n",
            "Epoch 761/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 7.1242e-04 - accuracy: 1.0000 - val_loss: 0.1783 - val_accuracy: 0.9710\n",
            "Epoch 762/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 5.3903e-04 - accuracy: 1.0000 - val_loss: 0.1788 - val_accuracy: 0.9710\n",
            "Epoch 763/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 4.9295e-04 - accuracy: 1.0000 - val_loss: 0.1820 - val_accuracy: 0.9695\n",
            "Epoch 764/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 7.1019e-04 - accuracy: 1.0000 - val_loss: 0.1841 - val_accuracy: 0.9695\n",
            "Epoch 765/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 6.2882e-04 - accuracy: 1.0000 - val_loss: 0.1817 - val_accuracy: 0.9695\n",
            "Epoch 766/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 4.8623e-04 - accuracy: 1.0000 - val_loss: 0.1819 - val_accuracy: 0.9695\n",
            "Epoch 767/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 6.1983e-04 - accuracy: 1.0000 - val_loss: 0.1834 - val_accuracy: 0.9710\n",
            "Epoch 768/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 7.4376e-04 - accuracy: 1.0000 - val_loss: 0.1817 - val_accuracy: 0.9695\n",
            "Epoch 769/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 5.4249e-04 - accuracy: 1.0000 - val_loss: 0.1833 - val_accuracy: 0.9695\n",
            "Epoch 770/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 7.3168e-04 - accuracy: 1.0000 - val_loss: 0.1823 - val_accuracy: 0.9695\n",
            "Epoch 771/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 8.0047e-04 - accuracy: 1.0000 - val_loss: 0.1760 - val_accuracy: 0.9710\n",
            "Epoch 772/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 7.1308e-04 - accuracy: 1.0000 - val_loss: 0.1766 - val_accuracy: 0.9710\n",
            "Epoch 773/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 8.3383e-04 - accuracy: 0.9996 - val_loss: 0.1780 - val_accuracy: 0.9695\n",
            "Epoch 774/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 9.0079e-04 - accuracy: 0.9996 - val_loss: 0.1771 - val_accuracy: 0.9710\n",
            "Epoch 775/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 8.0781e-04 - accuracy: 1.0000 - val_loss: 0.1802 - val_accuracy: 0.9710\n",
            "Epoch 776/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 6.9353e-04 - accuracy: 1.0000 - val_loss: 0.1777 - val_accuracy: 0.9710\n",
            "Epoch 777/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 5.6678e-04 - accuracy: 1.0000 - val_loss: 0.1781 - val_accuracy: 0.9710\n",
            "Epoch 778/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 4.9845e-04 - accuracy: 1.0000 - val_loss: 0.1800 - val_accuracy: 0.9710\n",
            "Epoch 779/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 9.7378e-04 - accuracy: 0.9996 - val_loss: 0.1751 - val_accuracy: 0.9710\n",
            "Epoch 780/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 9.0651e-04 - accuracy: 0.9996 - val_loss: 0.1783 - val_accuracy: 0.9710\n",
            "Epoch 781/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 4.9950e-04 - accuracy: 1.0000 - val_loss: 0.1784 - val_accuracy: 0.9710\n",
            "Epoch 782/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 5.9973e-04 - accuracy: 1.0000 - val_loss: 0.1792 - val_accuracy: 0.9695\n",
            "Epoch 783/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 8.2650e-04 - accuracy: 1.0000 - val_loss: 0.1795 - val_accuracy: 0.9695\n",
            "Epoch 784/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 9.5687e-04 - accuracy: 1.0000 - val_loss: 0.1768 - val_accuracy: 0.9695\n",
            "Epoch 785/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 6.2621e-04 - accuracy: 1.0000 - val_loss: 0.1761 - val_accuracy: 0.9710\n",
            "Epoch 786/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 8.2297e-04 - accuracy: 1.0000 - val_loss: 0.1778 - val_accuracy: 0.9695\n",
            "Epoch 787/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 5.3462e-04 - accuracy: 1.0000 - val_loss: 0.1753 - val_accuracy: 0.9741\n",
            "Epoch 788/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 9.0060e-04 - accuracy: 0.9996 - val_loss: 0.1784 - val_accuracy: 0.9695\n",
            "Epoch 789/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 5.5062e-04 - accuracy: 1.0000 - val_loss: 0.1812 - val_accuracy: 0.9695\n",
            "Epoch 790/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 8.6822e-04 - accuracy: 0.9996 - val_loss: 0.1798 - val_accuracy: 0.9695\n",
            "Epoch 791/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 5.2628e-04 - accuracy: 1.0000 - val_loss: 0.1792 - val_accuracy: 0.9726\n",
            "Epoch 792/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 8.8949e-04 - accuracy: 1.0000 - val_loss: 0.1817 - val_accuracy: 0.9695\n",
            "Epoch 793/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 6.9185e-04 - accuracy: 1.0000 - val_loss: 0.1821 - val_accuracy: 0.9695\n",
            "Epoch 794/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 9.5165e-04 - accuracy: 1.0000 - val_loss: 0.1838 - val_accuracy: 0.9680\n",
            "Epoch 795/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 5.6872e-04 - accuracy: 1.0000 - val_loss: 0.1829 - val_accuracy: 0.9695\n",
            "Epoch 796/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 4.9708e-04 - accuracy: 1.0000 - val_loss: 0.1830 - val_accuracy: 0.9695\n",
            "Epoch 797/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 6.0976e-04 - accuracy: 1.0000 - val_loss: 0.1810 - val_accuracy: 0.9710\n",
            "Epoch 798/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 5.3392e-04 - accuracy: 1.0000 - val_loss: 0.1819 - val_accuracy: 0.9695\n",
            "Epoch 799/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 5.6257e-04 - accuracy: 1.0000 - val_loss: 0.1852 - val_accuracy: 0.9695\n",
            "Epoch 800/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 4.9623e-04 - accuracy: 1.0000 - val_loss: 0.1808 - val_accuracy: 0.9695\n",
            "Epoch 801/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 7.5860e-04 - accuracy: 0.9996 - val_loss: 0.1803 - val_accuracy: 0.9695\n",
            "Epoch 802/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 6.9712e-04 - accuracy: 1.0000 - val_loss: 0.1814 - val_accuracy: 0.9695\n",
            "Epoch 803/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 5.4630e-04 - accuracy: 1.0000 - val_loss: 0.1775 - val_accuracy: 0.9726\n",
            "Epoch 804/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 5.9415e-04 - accuracy: 1.0000 - val_loss: 0.1792 - val_accuracy: 0.9695\n",
            "Epoch 805/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 5.5958e-04 - accuracy: 1.0000 - val_loss: 0.1808 - val_accuracy: 0.9710\n",
            "Epoch 806/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.1816 - val_accuracy: 0.9695\n",
            "Epoch 807/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 7.8543e-04 - accuracy: 1.0000 - val_loss: 0.1792 - val_accuracy: 0.9710\n",
            "Epoch 808/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 6.8848e-04 - accuracy: 1.0000 - val_loss: 0.1788 - val_accuracy: 0.9710\n",
            "Epoch 809/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 5.4734e-04 - accuracy: 1.0000 - val_loss: 0.1796 - val_accuracy: 0.9695\n",
            "Epoch 810/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 7.7228e-04 - accuracy: 1.0000 - val_loss: 0.1828 - val_accuracy: 0.9695\n",
            "Epoch 811/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 4.7128e-04 - accuracy: 1.0000 - val_loss: 0.1822 - val_accuracy: 0.9710\n",
            "Epoch 812/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 4.7910e-04 - accuracy: 1.0000 - val_loss: 0.1824 - val_accuracy: 0.9710\n",
            "Epoch 813/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 4.9459e-04 - accuracy: 1.0000 - val_loss: 0.1826 - val_accuracy: 0.9695\n",
            "Epoch 814/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 5.0778e-04 - accuracy: 1.0000 - val_loss: 0.1834 - val_accuracy: 0.9680\n",
            "Epoch 815/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 5.8303e-04 - accuracy: 1.0000 - val_loss: 0.1814 - val_accuracy: 0.9695\n",
            "Epoch 816/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 7.8017e-04 - accuracy: 1.0000 - val_loss: 0.1795 - val_accuracy: 0.9695\n",
            "Epoch 817/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 5.5004e-04 - accuracy: 1.0000 - val_loss: 0.1820 - val_accuracy: 0.9695\n",
            "Epoch 818/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 7.9338e-04 - accuracy: 0.9996 - val_loss: 0.1816 - val_accuracy: 0.9695\n",
            "Epoch 819/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 6.8019e-04 - accuracy: 1.0000 - val_loss: 0.1767 - val_accuracy: 0.9710\n",
            "Epoch 820/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 5.0529e-04 - accuracy: 1.0000 - val_loss: 0.1789 - val_accuracy: 0.9695\n",
            "Epoch 821/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 5.8907e-04 - accuracy: 1.0000 - val_loss: 0.1795 - val_accuracy: 0.9695\n",
            "Epoch 822/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 5.4656e-04 - accuracy: 1.0000 - val_loss: 0.1826 - val_accuracy: 0.9695\n",
            "Epoch 823/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 6.1187e-04 - accuracy: 1.0000 - val_loss: 0.1813 - val_accuracy: 0.9726\n",
            "Epoch 824/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 5.1547e-04 - accuracy: 1.0000 - val_loss: 0.1822 - val_accuracy: 0.9710\n",
            "Epoch 825/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 6.0735e-04 - accuracy: 1.0000 - val_loss: 0.1835 - val_accuracy: 0.9710\n",
            "Epoch 826/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 6.8800e-04 - accuracy: 1.0000 - val_loss: 0.1847 - val_accuracy: 0.9695\n",
            "Epoch 827/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 6.3823e-04 - accuracy: 1.0000 - val_loss: 0.1777 - val_accuracy: 0.9726\n",
            "Epoch 828/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 5.1798e-04 - accuracy: 1.0000 - val_loss: 0.1795 - val_accuracy: 0.9726\n",
            "Epoch 829/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 7.5198e-04 - accuracy: 1.0000 - val_loss: 0.1814 - val_accuracy: 0.9741\n",
            "Epoch 830/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 5.4787e-04 - accuracy: 1.0000 - val_loss: 0.1839 - val_accuracy: 0.9710\n",
            "Epoch 831/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 6.3988e-04 - accuracy: 1.0000 - val_loss: 0.1822 - val_accuracy: 0.9710\n",
            "Epoch 832/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 8.8837e-04 - accuracy: 0.9996 - val_loss: 0.1819 - val_accuracy: 0.9710\n",
            "Epoch 833/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 5.5589e-04 - accuracy: 1.0000 - val_loss: 0.1831 - val_accuracy: 0.9695\n",
            "Epoch 834/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 8.1075e-04 - accuracy: 0.9996 - val_loss: 0.1819 - val_accuracy: 0.9680\n",
            "Epoch 835/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 5.0306e-04 - accuracy: 1.0000 - val_loss: 0.1817 - val_accuracy: 0.9695\n",
            "Epoch 836/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 4.9346e-04 - accuracy: 1.0000 - val_loss: 0.1819 - val_accuracy: 0.9710\n",
            "Epoch 837/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 5.1175e-04 - accuracy: 1.0000 - val_loss: 0.1825 - val_accuracy: 0.9710\n",
            "Epoch 838/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 7.9707e-04 - accuracy: 0.9996 - val_loss: 0.1819 - val_accuracy: 0.9695\n",
            "Epoch 839/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 5.3310e-04 - accuracy: 1.0000 - val_loss: 0.1837 - val_accuracy: 0.9710\n",
            "Epoch 840/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 6.0145e-04 - accuracy: 1.0000 - val_loss: 0.1845 - val_accuracy: 0.9695\n",
            "Epoch 841/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 6.8527e-04 - accuracy: 1.0000 - val_loss: 0.1842 - val_accuracy: 0.9695\n",
            "Epoch 842/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 4.6833e-04 - accuracy: 1.0000 - val_loss: 0.1825 - val_accuracy: 0.9710\n",
            "Epoch 843/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 6.0273e-04 - accuracy: 1.0000 - val_loss: 0.1827 - val_accuracy: 0.9710\n",
            "Epoch 844/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 4.2653e-04 - accuracy: 1.0000 - val_loss: 0.1821 - val_accuracy: 0.9695\n",
            "Epoch 845/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 5.1183e-04 - accuracy: 1.0000 - val_loss: 0.1835 - val_accuracy: 0.9726\n",
            "Epoch 846/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 9.9897e-04 - accuracy: 1.0000 - val_loss: 0.1809 - val_accuracy: 0.9695\n",
            "Epoch 847/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 5.0238e-04 - accuracy: 1.0000 - val_loss: 0.1823 - val_accuracy: 0.9710\n",
            "Epoch 848/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 5.5580e-04 - accuracy: 1.0000 - val_loss: 0.1813 - val_accuracy: 0.9695\n",
            "Epoch 849/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 5.5232e-04 - accuracy: 1.0000 - val_loss: 0.1817 - val_accuracy: 0.9695\n",
            "Epoch 850/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 5.0891e-04 - accuracy: 1.0000 - val_loss: 0.1838 - val_accuracy: 0.9710\n",
            "Epoch 851/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 8.6503e-04 - accuracy: 1.0000 - val_loss: 0.1816 - val_accuracy: 0.9710\n",
            "Epoch 852/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 8.0996e-04 - accuracy: 1.0000 - val_loss: 0.1803 - val_accuracy: 0.9710\n",
            "Epoch 853/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 5.2592e-04 - accuracy: 1.0000 - val_loss: 0.1800 - val_accuracy: 0.9710\n",
            "Epoch 854/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 5.6281e-04 - accuracy: 1.0000 - val_loss: 0.1834 - val_accuracy: 0.9710\n",
            "Epoch 855/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 7.2460e-04 - accuracy: 1.0000 - val_loss: 0.1814 - val_accuracy: 0.9710\n",
            "Epoch 856/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 6.5454e-04 - accuracy: 1.0000 - val_loss: 0.1832 - val_accuracy: 0.9710\n",
            "Epoch 857/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 4.3319e-04 - accuracy: 1.0000 - val_loss: 0.1833 - val_accuracy: 0.9710\n",
            "Epoch 858/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 3.9385e-04 - accuracy: 1.0000 - val_loss: 0.1834 - val_accuracy: 0.9710\n",
            "Epoch 859/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 5.0447e-04 - accuracy: 1.0000 - val_loss: 0.1857 - val_accuracy: 0.9710\n",
            "Epoch 860/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 6.2751e-04 - accuracy: 1.0000 - val_loss: 0.1848 - val_accuracy: 0.9710\n",
            "Epoch 861/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 6.1834e-04 - accuracy: 1.0000 - val_loss: 0.1841 - val_accuracy: 0.9710\n",
            "Epoch 862/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 5.0229e-04 - accuracy: 1.0000 - val_loss: 0.1834 - val_accuracy: 0.9710\n",
            "Epoch 863/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 0.1840 - val_accuracy: 0.9695\n",
            "Epoch 864/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 6.8235e-04 - accuracy: 1.0000 - val_loss: 0.1820 - val_accuracy: 0.9710\n",
            "Epoch 865/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 5.2903e-04 - accuracy: 1.0000 - val_loss: 0.1820 - val_accuracy: 0.9710\n",
            "Epoch 866/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 5.0350e-04 - accuracy: 1.0000 - val_loss: 0.1849 - val_accuracy: 0.9695\n",
            "Epoch 867/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 4.6387e-04 - accuracy: 1.0000 - val_loss: 0.1830 - val_accuracy: 0.9710\n",
            "Epoch 868/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 5.9624e-04 - accuracy: 1.0000 - val_loss: 0.1869 - val_accuracy: 0.9680\n",
            "Epoch 869/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 6.5698e-04 - accuracy: 1.0000 - val_loss: 0.1841 - val_accuracy: 0.9695\n",
            "Epoch 870/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 7.2554e-04 - accuracy: 1.0000 - val_loss: 0.1821 - val_accuracy: 0.9710\n",
            "Epoch 871/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 6.8803e-04 - accuracy: 1.0000 - val_loss: 0.1826 - val_accuracy: 0.9710\n",
            "Epoch 872/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 9.6260e-04 - accuracy: 0.9996 - val_loss: 0.1839 - val_accuracy: 0.9710\n",
            "Epoch 873/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 5.7512e-04 - accuracy: 1.0000 - val_loss: 0.1850 - val_accuracy: 0.9695\n",
            "Epoch 874/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 5.9358e-04 - accuracy: 1.0000 - val_loss: 0.1819 - val_accuracy: 0.9695\n",
            "Epoch 875/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 5.0979e-04 - accuracy: 1.0000 - val_loss: 0.1828 - val_accuracy: 0.9695\n",
            "Epoch 876/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 6.4916e-04 - accuracy: 1.0000 - val_loss: 0.1821 - val_accuracy: 0.9695\n",
            "Epoch 877/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 5.5587e-04 - accuracy: 1.0000 - val_loss: 0.1836 - val_accuracy: 0.9695\n",
            "Epoch 878/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 7.8947e-04 - accuracy: 1.0000 - val_loss: 0.1832 - val_accuracy: 0.9710\n",
            "Epoch 879/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 5.4020e-04 - accuracy: 1.0000 - val_loss: 0.1827 - val_accuracy: 0.9710\n",
            "Epoch 880/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 7.4377e-04 - accuracy: 0.9996 - val_loss: 0.1828 - val_accuracy: 0.9710\n",
            "Epoch 881/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 4.8459e-04 - accuracy: 1.0000 - val_loss: 0.1806 - val_accuracy: 0.9710\n",
            "Epoch 882/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 4.7716e-04 - accuracy: 1.0000 - val_loss: 0.1815 - val_accuracy: 0.9710\n",
            "Epoch 883/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 3.9931e-04 - accuracy: 1.0000 - val_loss: 0.1847 - val_accuracy: 0.9726\n",
            "Epoch 884/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 4.2341e-04 - accuracy: 1.0000 - val_loss: 0.1851 - val_accuracy: 0.9710\n",
            "Epoch 885/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 6.6189e-04 - accuracy: 1.0000 - val_loss: 0.1846 - val_accuracy: 0.9710\n",
            "Epoch 886/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 5.6000e-04 - accuracy: 1.0000 - val_loss: 0.1816 - val_accuracy: 0.9695\n",
            "Epoch 887/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 4.4199e-04 - accuracy: 1.0000 - val_loss: 0.1818 - val_accuracy: 0.9710\n",
            "Epoch 888/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 5.8933e-04 - accuracy: 1.0000 - val_loss: 0.1838 - val_accuracy: 0.9710\n",
            "Epoch 889/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 7.6968e-04 - accuracy: 1.0000 - val_loss: 0.1825 - val_accuracy: 0.9741\n",
            "Epoch 890/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 4.8227e-04 - accuracy: 1.0000 - val_loss: 0.1841 - val_accuracy: 0.9726\n",
            "Epoch 891/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 6.4891e-04 - accuracy: 0.9996 - val_loss: 0.1839 - val_accuracy: 0.9726\n",
            "Epoch 892/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 4.0802e-04 - accuracy: 1.0000 - val_loss: 0.1849 - val_accuracy: 0.9710\n",
            "Epoch 893/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 5.6731e-04 - accuracy: 1.0000 - val_loss: 0.1855 - val_accuracy: 0.9710\n",
            "Epoch 894/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 4.0540e-04 - accuracy: 1.0000 - val_loss: 0.1857 - val_accuracy: 0.9710\n",
            "Epoch 895/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 4.5121e-04 - accuracy: 1.0000 - val_loss: 0.1855 - val_accuracy: 0.9710\n",
            "Epoch 896/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 7.2253e-04 - accuracy: 1.0000 - val_loss: 0.1861 - val_accuracy: 0.9695\n",
            "Epoch 897/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 5.9513e-04 - accuracy: 1.0000 - val_loss: 0.1845 - val_accuracy: 0.9710\n",
            "Epoch 898/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 5.9585e-04 - accuracy: 1.0000 - val_loss: 0.1814 - val_accuracy: 0.9695\n",
            "Epoch 899/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 5.2256e-04 - accuracy: 1.0000 - val_loss: 0.1829 - val_accuracy: 0.9695\n",
            "Epoch 900/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 8.2061e-04 - accuracy: 1.0000 - val_loss: 0.1839 - val_accuracy: 0.9710\n",
            "Epoch 901/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 6.4504e-04 - accuracy: 1.0000 - val_loss: 0.1844 - val_accuracy: 0.9710\n",
            "Epoch 902/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 6.6999e-04 - accuracy: 1.0000 - val_loss: 0.1850 - val_accuracy: 0.9710\n",
            "Epoch 903/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 4.4905e-04 - accuracy: 1.0000 - val_loss: 0.1846 - val_accuracy: 0.9710\n",
            "Epoch 904/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 7.4044e-04 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 0.9710\n",
            "Epoch 905/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 4.0033e-04 - accuracy: 1.0000 - val_loss: 0.1857 - val_accuracy: 0.9710\n",
            "Epoch 906/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 7.6859e-04 - accuracy: 1.0000 - val_loss: 0.1932 - val_accuracy: 0.9695\n",
            "Epoch 907/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 7.7232e-04 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 0.9710\n",
            "Epoch 908/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 4.9012e-04 - accuracy: 1.0000 - val_loss: 0.1856 - val_accuracy: 0.9710\n",
            "Epoch 909/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 3.6424e-04 - accuracy: 1.0000 - val_loss: 0.1863 - val_accuracy: 0.9726\n",
            "Epoch 910/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 4.2037e-04 - accuracy: 1.0000 - val_loss: 0.1872 - val_accuracy: 0.9710\n",
            "Epoch 911/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 6.5346e-04 - accuracy: 0.9996 - val_loss: 0.1856 - val_accuracy: 0.9710\n",
            "Epoch 912/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 8.0314e-04 - accuracy: 0.9996 - val_loss: 0.1864 - val_accuracy: 0.9710\n",
            "Epoch 913/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 6.4168e-04 - accuracy: 0.9996 - val_loss: 0.1868 - val_accuracy: 0.9710\n",
            "Epoch 914/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 4.7652e-04 - accuracy: 1.0000 - val_loss: 0.1878 - val_accuracy: 0.9710\n",
            "Epoch 915/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 4.8112e-04 - accuracy: 1.0000 - val_loss: 0.1892 - val_accuracy: 0.9710\n",
            "Epoch 916/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 7.2794e-04 - accuracy: 1.0000 - val_loss: 0.1864 - val_accuracy: 0.9710\n",
            "Epoch 917/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 6.0944e-04 - accuracy: 1.0000 - val_loss: 0.1862 - val_accuracy: 0.9710\n",
            "Epoch 918/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 8.3499e-04 - accuracy: 0.9996 - val_loss: 0.1848 - val_accuracy: 0.9710\n",
            "Epoch 919/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 4.2916e-04 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 0.9710\n",
            "Epoch 920/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 5.9674e-04 - accuracy: 1.0000 - val_loss: 0.1883 - val_accuracy: 0.9710\n",
            "Epoch 921/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 5.0826e-04 - accuracy: 1.0000 - val_loss: 0.1887 - val_accuracy: 0.9710\n",
            "Epoch 922/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 8.1929e-04 - accuracy: 0.9996 - val_loss: 0.1885 - val_accuracy: 0.9710\n",
            "Epoch 923/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 4.0967e-04 - accuracy: 1.0000 - val_loss: 0.1881 - val_accuracy: 0.9710\n",
            "Epoch 924/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 4.6422e-04 - accuracy: 1.0000 - val_loss: 0.1889 - val_accuracy: 0.9710\n",
            "Epoch 925/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 3.2182e-04 - accuracy: 1.0000 - val_loss: 0.1872 - val_accuracy: 0.9710\n",
            "Epoch 926/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 6.8601e-04 - accuracy: 1.0000 - val_loss: 0.1864 - val_accuracy: 0.9710\n",
            "Epoch 927/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 6.5770e-04 - accuracy: 1.0000 - val_loss: 0.1863 - val_accuracy: 0.9710\n",
            "Epoch 928/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 5.2813e-04 - accuracy: 1.0000 - val_loss: 0.1862 - val_accuracy: 0.9710\n",
            "Epoch 929/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 7.3727e-04 - accuracy: 0.9996 - val_loss: 0.1860 - val_accuracy: 0.9710\n",
            "Epoch 930/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 4.5710e-04 - accuracy: 1.0000 - val_loss: 0.1882 - val_accuracy: 0.9710\n",
            "Epoch 931/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 3.6841e-04 - accuracy: 1.0000 - val_loss: 0.1872 - val_accuracy: 0.9710\n",
            "Epoch 932/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 5.2730e-04 - accuracy: 1.0000 - val_loss: 0.1837 - val_accuracy: 0.9726\n",
            "Epoch 933/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 5.1462e-04 - accuracy: 1.0000 - val_loss: 0.1849 - val_accuracy: 0.9710\n",
            "Epoch 934/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 4.2553e-04 - accuracy: 1.0000 - val_loss: 0.1840 - val_accuracy: 0.9741\n",
            "Epoch 935/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 4.3447e-04 - accuracy: 1.0000 - val_loss: 0.1861 - val_accuracy: 0.9710\n",
            "Epoch 936/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 4.7932e-04 - accuracy: 1.0000 - val_loss: 0.1851 - val_accuracy: 0.9741\n",
            "Epoch 937/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 5.8358e-04 - accuracy: 1.0000 - val_loss: 0.1852 - val_accuracy: 0.9710\n",
            "Epoch 938/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 7.9430e-04 - accuracy: 0.9996 - val_loss: 0.1846 - val_accuracy: 0.9710\n",
            "Epoch 939/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 7.9666e-04 - accuracy: 1.0000 - val_loss: 0.1863 - val_accuracy: 0.9710\n",
            "Epoch 940/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 3.5347e-04 - accuracy: 1.0000 - val_loss: 0.1874 - val_accuracy: 0.9710\n",
            "Epoch 941/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 5.4228e-04 - accuracy: 1.0000 - val_loss: 0.1891 - val_accuracy: 0.9710\n",
            "Epoch 942/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 8.7896e-04 - accuracy: 1.0000 - val_loss: 0.1824 - val_accuracy: 0.9726\n",
            "Epoch 943/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 4.0376e-04 - accuracy: 1.0000 - val_loss: 0.1851 - val_accuracy: 0.9710\n",
            "Epoch 944/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 5.0216e-04 - accuracy: 1.0000 - val_loss: 0.1862 - val_accuracy: 0.9726\n",
            "Epoch 945/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 4.5221e-04 - accuracy: 1.0000 - val_loss: 0.1865 - val_accuracy: 0.9726\n",
            "Epoch 946/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 7.0707e-04 - accuracy: 1.0000 - val_loss: 0.1874 - val_accuracy: 0.9726\n",
            "Epoch 947/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 3.5769e-04 - accuracy: 1.0000 - val_loss: 0.1883 - val_accuracy: 0.9726\n",
            "Epoch 948/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 5.0423e-04 - accuracy: 1.0000 - val_loss: 0.1881 - val_accuracy: 0.9726\n",
            "Epoch 949/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 5.1425e-04 - accuracy: 1.0000 - val_loss: 0.1846 - val_accuracy: 0.9741\n",
            "Epoch 950/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.1847 - val_accuracy: 0.9710\n",
            "Epoch 951/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 4.2827e-04 - accuracy: 1.0000 - val_loss: 0.1865 - val_accuracy: 0.9710\n",
            "Epoch 952/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 4.2227e-04 - accuracy: 1.0000 - val_loss: 0.1861 - val_accuracy: 0.9710\n",
            "Epoch 953/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 4.8061e-04 - accuracy: 1.0000 - val_loss: 0.1851 - val_accuracy: 0.9710\n",
            "Epoch 954/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 3.5136e-04 - accuracy: 1.0000 - val_loss: 0.1850 - val_accuracy: 0.9710\n",
            "Epoch 955/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 3.4117e-04 - accuracy: 1.0000 - val_loss: 0.1858 - val_accuracy: 0.9710\n",
            "Epoch 956/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 3.7733e-04 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 0.9710\n",
            "Epoch 957/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 2.9512e-04 - accuracy: 1.0000 - val_loss: 0.1877 - val_accuracy: 0.9710\n",
            "Epoch 958/1000\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 5.4438e-04 - accuracy: 1.0000 - val_loss: 0.1864 - val_accuracy: 0.9710\n",
            "Epoch 959/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 3.9365e-04 - accuracy: 1.0000 - val_loss: 0.1880 - val_accuracy: 0.9695\n",
            "Epoch 960/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 7.5316e-04 - accuracy: 1.0000 - val_loss: 0.1857 - val_accuracy: 0.9710\n",
            "Epoch 961/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 4.3218e-04 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 0.9710\n",
            "Epoch 962/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 4.2643e-04 - accuracy: 1.0000 - val_loss: 0.1870 - val_accuracy: 0.9710\n",
            "Epoch 963/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 5.4796e-04 - accuracy: 1.0000 - val_loss: 0.1857 - val_accuracy: 0.9710\n",
            "Epoch 964/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 5.0182e-04 - accuracy: 1.0000 - val_loss: 0.1857 - val_accuracy: 0.9710\n",
            "Epoch 965/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 6.0329e-04 - accuracy: 1.0000 - val_loss: 0.1889 - val_accuracy: 0.9710\n",
            "Epoch 966/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 4.6914e-04 - accuracy: 1.0000 - val_loss: 0.1879 - val_accuracy: 0.9710\n",
            "Epoch 967/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 5.2287e-04 - accuracy: 1.0000 - val_loss: 0.1908 - val_accuracy: 0.9710\n",
            "Epoch 968/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 4.6216e-04 - accuracy: 1.0000 - val_loss: 0.1867 - val_accuracy: 0.9710\n",
            "Epoch 969/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 7.0791e-04 - accuracy: 0.9996 - val_loss: 0.1867 - val_accuracy: 0.9710\n",
            "Epoch 970/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 4.6626e-04 - accuracy: 1.0000 - val_loss: 0.1866 - val_accuracy: 0.9726\n",
            "Epoch 971/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 4.2302e-04 - accuracy: 1.0000 - val_loss: 0.1883 - val_accuracy: 0.9710\n",
            "Epoch 972/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 4.9521e-04 - accuracy: 1.0000 - val_loss: 0.1877 - val_accuracy: 0.9726\n",
            "Epoch 973/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 4.4682e-04 - accuracy: 1.0000 - val_loss: 0.1873 - val_accuracy: 0.9741\n",
            "Epoch 974/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 5.6609e-04 - accuracy: 1.0000 - val_loss: 0.1859 - val_accuracy: 0.9726\n",
            "Epoch 975/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 4.9111e-04 - accuracy: 1.0000 - val_loss: 0.1877 - val_accuracy: 0.9710\n",
            "Epoch 976/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 3.6018e-04 - accuracy: 1.0000 - val_loss: 0.1881 - val_accuracy: 0.9710\n",
            "Epoch 977/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 4.8494e-04 - accuracy: 1.0000 - val_loss: 0.1891 - val_accuracy: 0.9710\n",
            "Epoch 978/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 4.0357e-04 - accuracy: 1.0000 - val_loss: 0.1880 - val_accuracy: 0.9710\n",
            "Epoch 979/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 4.2622e-04 - accuracy: 1.0000 - val_loss: 0.1880 - val_accuracy: 0.9710\n",
            "Epoch 980/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 4.5043e-04 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 0.9710\n",
            "Epoch 981/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 5.6130e-04 - accuracy: 1.0000 - val_loss: 0.1873 - val_accuracy: 0.9710\n",
            "Epoch 982/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 4.9971e-04 - accuracy: 1.0000 - val_loss: 0.1854 - val_accuracy: 0.9726\n",
            "Epoch 983/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 4.9600e-04 - accuracy: 1.0000 - val_loss: 0.1869 - val_accuracy: 0.9726\n",
            "Epoch 984/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 4.5103e-04 - accuracy: 1.0000 - val_loss: 0.1859 - val_accuracy: 0.9741\n",
            "Epoch 985/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 3.7845e-04 - accuracy: 1.0000 - val_loss: 0.1890 - val_accuracy: 0.9710\n",
            "Epoch 986/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 5.1360e-04 - accuracy: 1.0000 - val_loss: 0.1865 - val_accuracy: 0.9710\n",
            "Epoch 987/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 4.2854e-04 - accuracy: 1.0000 - val_loss: 0.1882 - val_accuracy: 0.9710\n",
            "Epoch 988/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 4.2537e-04 - accuracy: 1.0000 - val_loss: 0.1884 - val_accuracy: 0.9710\n",
            "Epoch 989/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 4.8515e-04 - accuracy: 1.0000 - val_loss: 0.1878 - val_accuracy: 0.9710\n",
            "Epoch 990/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 5.2383e-04 - accuracy: 1.0000 - val_loss: 0.1876 - val_accuracy: 0.9710\n",
            "Epoch 991/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 4.5276e-04 - accuracy: 1.0000 - val_loss: 0.1882 - val_accuracy: 0.9710\n",
            "Epoch 992/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 5.7583e-04 - accuracy: 1.0000 - val_loss: 0.1913 - val_accuracy: 0.9695\n",
            "Epoch 993/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 4.7741e-04 - accuracy: 1.0000 - val_loss: 0.1899 - val_accuracy: 0.9726\n",
            "Epoch 994/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 4.6087e-04 - accuracy: 1.0000 - val_loss: 0.1880 - val_accuracy: 0.9710\n",
            "Epoch 995/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 4.3712e-04 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 0.9726\n",
            "Epoch 996/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 6.7863e-04 - accuracy: 1.0000 - val_loss: 0.1890 - val_accuracy: 0.9710\n",
            "Epoch 997/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 5.2602e-04 - accuracy: 1.0000 - val_loss: 0.1863 - val_accuracy: 0.9710\n",
            "Epoch 998/1000\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 6.9919e-04 - accuracy: 0.9996 - val_loss: 0.1875 - val_accuracy: 0.9710\n",
            "Epoch 999/1000\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 4.2740e-04 - accuracy: 1.0000 - val_loss: 0.1880 - val_accuracy: 0.9710\n",
            "Epoch 1000/1000\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 3.9988e-04 - accuracy: 1.0000 - val_loss: 0.1894 - val_accuracy: 0.9710\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.predict(validation_data)\n",
        "predictions = [i.argmax() for i in preds]\n",
        "y_true = [i.argmax() for i in validation_labels]\n",
        "print('Accuracy {}'.format(accuracy_score(y_true=y_true, y_pred=predictions)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14AkpxvOzEHJ",
        "outputId": "b3292afe-07fc-4c03-e1b9-0e8736a22977"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.9710365853658537\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.predict(test_data)\n",
        "\n",
        "predictions = [i.argmax() for i in preds]\n",
        "y_true = [i.argmax() for i in test_labels]\n",
        "#cm = confusion_matrix(y_pred=predictions, y_true=y_true)\n",
        "\n",
        "print('Accuracy {}'.format(accuracy_score(y_true=y_true, y_pred=predictions)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GuJXi5yzICo",
        "outputId": "5003ae85-7ab8-4423-e209-37a96681cc2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.9867724867724867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/My_projects _and _datasets/IDRID_detection/ResNet152V2_upto15frozen.h5')\n",
        "model.save_weights('/content/drive/MyDrive/My_projects _and _datasets/IDRID_detection/ResNet152V2_upto15frozen_weights.h5')"
      ],
      "metadata": {
        "id": "TZHABh2NzK52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model=load_model('/content/drive/MyDrive/My_projects _and _datasets/IDRID_detection/ResNet152V2_upto15frozen.h5',compile=False)\n",
        "loaded_model.load_weights('/content/drive/MyDrive/My_projects _and _datasets/IDRID_detection/ResNet152V2_upto15frozen_weights.h5')"
      ],
      "metadata": {
        "id": "kny2J2XJzZ5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train','Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "h7fL0I9ZzuaE",
        "outputId": "4846e13e-8658-4554-dad6-e4ed572bf863"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train','Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "VES52pqS0DEg",
        "outputId": "91bc4542-87fe-4b1d-9315-8c3617a8a19b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report \n",
        "import seaborn as sns\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "ToxLqDgp0G2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = loaded_model.predict(test_data)\n",
        "\n",
        "y_pred = [i.argmax() for i in preds]\n",
        "y_true = [i.argmax() for i in test_labels]\n",
        "cm = confusion_matrix(y_pred=y_pred, y_true=y_true)"
      ],
      "metadata": {
        "id": "WpUKrg5g0Ke8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('CONFUSION MATRIX')\n",
        "conf_matrix = pd.DataFrame(data = cm,  \n",
        "                           columns = ['with_DR','without_DR'],  \n",
        "                           index =['with_DR','without_DR']) \n",
        "\n",
        "accuracy = np.trace(cm) / float(np.sum(cm))\n",
        "misclass = 1 - accuracy\n",
        "plt.figure(figsize = (10,8)) \n",
        "sns.heatmap(conf_matrix, annot = True, fmt = 'd', cmap = \"Blues\") \n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
        "plt.show() \n",
        "\n",
        "target_names=['with_DR','without_DR']\n",
        "print('The details for confusion matrix is =') \n",
        "print (classification_report(y_true, y_pred,target_names=target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "id": "iU8JdG0X0NXH",
        "outputId": "cf6ceecc-3030-4674-959a-dfd5f04eaa92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFUSION MATRIX\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjgAAAHsCAYAAADfMtdSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd7xkdX3/8dd7QenFgkpERJqoNCl2CKAYMXYj9lizohJ7QU2sIYpBTSJBgoqAQX6oiGBigYgCElBpLl1AUcEVFCxI3+Xz+2POhWHZe/fu3T0z957zevI4j535njPn+51Z5t7Pfr4tVYUkSVKXzBt3AyRJklY2AxxJktQ5BjiSJKlzDHAkSVLnGOBIkqTOWXXcDZjKGnse4BQvaQx+/613j7sJUm+tvioZVV1rPHrfVn7P3nzuQSN7D5MxgyNJkjrHAEeSJHXOrO6ikiRJLUp38xwGOJIk9VXGPlSmNd0N3SRJUm+ZwZEkqa863EXV3XcmSZJ6ywyOJEl91eExOAY4kiT1lV1UkiRJc4cZHEmS+qrDXVRmcCRJUueYwZEkqa8cgyNJkjR3mMGRJKmvOjwGxwBHkqS+sotKkiRp7jCDI0lSX3W4i8oMjiRJ6hwzOJIk9VWHx+AY4EiS1Fd2UUmSJM0dZnAkSeqrDndRdfedSZKk3jKDI0lSX3U4g2OAI0lSX81zkLEkSdKcYQZHkqS+6nAXVXffmSRJ6i0zOJIk9VWHF/ozwJEkqa/sopIkSZo7zOBIktRXHe6iMoMjSZI6xwyOJEl95RgcSZKkucMMjiRJfdXhMTgGOJIk9ZVdVJIkSXOHGRxJkvpqTF1USQ4DngFcW1VbN2XHAA9vLlkf+ENVbZ9kE+Bi4NLm3JlVtc+y6jDAkSRJo3Y4cBBw5ERBVb1w4nGSTwB/HLr+iqrafnkqMMCRJKmvxjQGp6pObTIz95AkwN7AHitSh2NwJEnqq6SVI8n8JGcNHfOXo1W7ANdU1WVDZQ9Lcm6SU5LsMp2bmMGRJEkrVVUdChw6w5e/GDh66PlCYOOqui7JjsDXkzyqqv401U0McCRJ6qtZNk08yarA84AdJ8qq6lbg1ubx2UmuALYEzprqXrPrnUmSpD57CnBJVV01UZBkgySrNI83BbYAfrasGxngSJLUV5nXzrGsapOjgTOAhye5KslrmlMv4u7dUwC7AguSnAd8Fdinqq5fVh12UUmS1FdjWgenql48Sfkrl1J2LHDs8tZhBkeSJHWOGRxJkvpqlg0yXpm6+84kSVJvmcGRJKmvxjQGZxTM4EiSpM4xgyNJUl91eAyOAY4kSX1lF5UkSdLcYQZHkqSeihkcSZKkucMMjiRJPdXlDI4BjiRJfdXd+MYuKkmS1D1mcCRJ6qkud1GZwZEkSZ1jBkeSpJ7qcgbHAEeSpJ7qcoBjF5UkSeocMziSJPWUGRxJkqQ5xAyOJEl91d0EjhkcSZLUPWZwJEnqqS6PwTHAkSSpp7oc4NhFJUmSOscMjiRJPWUGR5IkaQ4xgyNJUk91OYNjgCNJUl91N76xi0qSJHWPGRxJknqqy11UZnAkSVLnmMGRJKmnupzBMcCRJKmnuhzg2EUlSZI6xwyOJEl91d0EjhkcSZLUPWZwJEnqKcfgSJIkzSFmcCRJ6qkuZ3AMcCRJ6qkuBzh2UUmSpM4ZeYCTZF6Sl466XkmSdHdJWjlmg9YCnCTrJnlPkoOSPDUDfw/8DNi7rXolSZLaHIPzReD3wBnAa4H3MlhS6DlVdV6L9UqSpOmYHcmWVrQZ4GxaVdsAJPkcsBDYuKpuabFOSZI0TbOlO6kNbY7BuX3iQVUtBq4yuJEkSaPQZgZnuyR/4q4E2BpDz6uq1m2xbkmStAxmcGagqlapqnWrap3mWHXoucGNJEk9leSwJNcmuWCo7INJrk5yXnM8fejce5JcnuTSJH81nTpaX+gvyTbAVs3Ti6rqwrbrlCRJyzbGDM7hwEHAkUuUf6qqDhwuSPJI4EXAo4C/AP43yZbN8JdJtRbgJFkPOB7YGPgJg66pbZL8Enh2Vf2prbolSdI0jCm+qapTk2wyzcufDfy/qroV+HmSy4HHMJilPak2Bxl/BDgL2LyqnltVzwG2AH4M7N9ivZIkaYySzE9y1tAxf5ov3TfJgqYL6z5N2YOBXw1dc1VTNqU2u6ieAmxbVXdMFFTVHUneC5zfYr2SJGka2uqiqqpDgUOX82WfYZAcqebPTwCvnmkb2szg3FZVi5YsbMpubbFeSZI0x1TVNVW1uEmMfJZBNxTA1cBDhi7dqCmbUpsZnNWTPJp79vAFWK3FeiVJ0jTMpmniSTasqoXN0+cCEzOsTgC+lOSTDAYZbwH8aFn3azPAWQh8cpJzv2mxXkmSNIslORrYDbh/kquADwC7JdmeQRfVlcDrAKrqwiRfBi4CFgFvXNYMKmgxwKmq3adzXZI9q+qkttqhdhzy9r3Y67Gb8ds/3MRO8w8D4IvvexZbPOS+AKy/1ur84cZbeNw+h3OvVedx0Fuexg5bPog77ijecfD/ctqCX011e0nL6TcLF/K+97yL66+7DhL+5gV789KXv2LczdIsN64MTlW9eCnFn5/i+v1ZzglKra+DMw0HAAY4c8wXTzyfQ44/h8+966/vLHv5/ifc+fhjr9udP944GGr16qdvB8DO8w9jg/XX5Ov7v4An7XsEVaNts9Rlq6y6Cu9413484pGP4sYb/8yLXvB8Hvf4J7LZ5puPu2maxWZTF9XK1uYg4+nq7qfbYaeffxXX33DzpOefv+tWfPl7FwOw1UPvz/fP+wUAv/3DTfzxxlvYccsNR9JOqS822OABPOKRjwJgrbXWZtNNN+Xaa68Zc6uk8ZkNAY7/ju+YJ26zEdf84UauuPr3AJx/xbU84/Gbs8q88NAHrcejt3gQG22wzphbKXXX1VdfxSUXX8w222437qZotktLxywwG7qo7qZZDGg+wKpbPZdVN3rsmFuk5bX37o/kK032BuCIby9gq43vx+kHv4JfXvMnzrzoahbfYVwrteGmG2/k7W95E+/c772svfba426ONDazIcC5cvjJ8OJAa+x5gL8F55hV5oVnP2lLnviGI+4sW3xH8a5DTr7z+ff+9WVcdtX142ie1Gm33347b3vLm3j6Xz+Tp+z51HE3R3NAl8fgjCTASfIEYJPh+qrqyObP542iDRqNPXbYhJ/+6jqu/t0Nd5atsdqqJOGmW25njx02YdHiO7jkl9eNsZVS91QVH3z/+9h0003521e+atzN0RxhgLMCknwR2Aw4D5iYt17ccwdRzSFHvPeZ7LLtxtx/vTW4/Etv4CNH/oAjvr2AF+z+iDsHF0/YYP01+cZH9+aOgl//7gZec8B/j6nVUnede87Z/PcJx7PFlluy9/OeDcDfv+Vt7LLrX465ZdJ4pFqeq5vkYuCRNYOK7KKSxuP333r3uJsg9dbqq45umO7m7/hWK79nLz9wr7GnhkYxi+oC4EEjqEeSJAlosYsqyTcYdEWtA1yU5EcMbbJZVc9qq25JkrRsjsGZmQNbvLckSVpBHY5vWt2L6hSAJAdU1d069JMcAJzSVt2SJKnfRjEGZ8+llO01gnolSdIUkrRyzAZtjsF5PfAGYNMkC4ZOrQOc3la9kiRJbY7B+RLwLeCjwH5D5TdUlcvYSpI0ZrMk2dKKNgOcqqork7xxyRNJ7muQI0mS2tJ2BucZwNkMposPx4kFbNpi3ZIkaRnmzetuCqfNWVTPaB6ezmDG1GlVdUlb9UmSpOXT5S6qUcyi+jywIfDpJD9L8tUkbx5BvZIkqada32yzqr6X5FRgZ2B3YB9ga+Df2q5bkiRNbrZM6W7DKHYT/y6wFnAGcBqwc1Vd23a9kiSpv0bRRbUAuI1B1mZbYOska4ygXkmSNIWknWM2GEUX1VsBkqwDvBL4AoPdxVdru25JkjQ5u6hWQJJ9gV2AHYErgcMYdFVJkiS1ovUAB1gd+CRwdlUtGkF9kiRpGszgrICqOrDtOiRJkoaNIoMjSZJmoQ4ncAxwJEnqqy53UY1imrgkSdJImcGRJKmnOpzAMYMjSZK6xwyOJEk95RgcSZKkOcQMjiRJPdXhBI4BjiRJfWUXlSRJ0hxiBkeSpJ7qcALHDI4kSeoeMziSJPVUl8fgGOBIktRTHY5v7KKSJEndYwZHkqSe6nIXlRkcSZLUOWZwJEnqqQ4ncAxwJEnqK7uoJEmS5hAzOJIk9VSHEzhmcCRJ0mglOSzJtUkuGCr7lySXJFmQ5Lgk6zflmyS5Ocl5zXHIdOowwJEkqaeStHJMw+HA05YoOwnYuqq2BX4KvGfo3BVVtX1z7DOdCgxwJEnqqXEFOFV1KnD9EmUnVtWi5umZwEYr8t4McCRJ0mzzauBbQ88fluTcJKck2WU6N3CQsSRJPdXWIOMk84H5Q0WHVtWh03zt+4BFwFFN0UJg46q6LsmOwNeTPKqq/jTVfQxwJEnSStUEM9MKaIYleSXwDODJVVXNvW4Fbm0en53kCmBL4Kyp7mWAI0lST82mhf6SPA14F/CXVXXTUPkGwPVVtTjJpsAWwM+WdT8DHEmSNFJJjgZ2A+6f5CrgAwxmTa0GnNQEXmc2M6Z2BT6c5HbgDmCfqrp+qTceYoAjSVJPjSuBU1UvXkrx5ye59ljg2OWtwwBHkqSemk1dVCub08QlSVLnmMGRJKmnOpzAMYMjSZK6xwyOJEk9Na/DKRwDHEmSeqrD8Y1dVJIkqXvM4EiS1FNOE5ckSZpDzOBIktRT87qbwDHAkSSpr+yikiRJmkPM4EiS1FMdTuCYwZEkSd1jBkeSpJ4K3U3hmMGRJEmdYwZHkqSecpq4JEnqHKeJS5IkzSFmcCRJ6qkOJ3DM4EiSpO4xgyNJUk/N63AKxwBHkqSe6nB8YxeVJEnqHjM4kiT1lNPEJUmS5hAzOJIk9VSHEzgGOJIk9VWXZ1HZRSVJkjrHDI4kST3V3fyNGRxJktRBZnAkSeqpLk8TnzTASbLDVC+sqnNWfnMkSZJW3FQZnE9Mca6APVZyWyRJ0gjN624CZ/IAp6p2H2VDJEnSaHW5i2qZg4yTrJnkH5Ic2jzfIskz2m+aJEnSzExnFtUXgNuAJzTPrwb+qbUWSZKkkUjaOWaD6QQ4m1XVx4HbAarqJro9dV6SJM1x05kmfluSNRgMLCbJZsCtrbZKkiS1rstjcKYT4HwA+DbwkCRHAU8EXtlmoyRJUvt6OYtqQlWdlOQc4HEMuqbeXFW/a71lkiRJMzTdlYz/EngSg26qewHHtdYiSZI0El3uoprONPGDgX2A84ELgNcl+Y+2GyZJkjRT08ng7AE8oqomBhkfAVzYaqskSVLrupu/mV6AczmwMfCL5vlDmjJJkjSHzetwF9VUm21+g8GYm3WAi5P8qHn+WOBHo2meJEnS8psqg3PgyFohSZJGrsMJnCk32zxllA2RJElaWaYzi+pxSX6c5M9JbkuyOMmfRtE4SZLUniStHNOo97Ak1ya5YKjsvklOSnJZ8+d9mvIk+fcklydZkGSH6by36exFdRDwYuAyYA3gtYDTxCVJ0kwdDjxtibL9gO9W1RbAd5vnAHsBWzTHfOAz06lgOgEOVXU5sEpVLa6qLyylUZIkaY4Z127iVXUqcP0Sxc8GjmgeHwE8Z6j8yBo4E1g/yYbLqmM608RvSnJv4LwkHwcWMs3ASJIkzV5tTRNPMp9BtmXCoVV16DJe9sCqWtg8/g3wwObxg4FfDV13VVO2kClMJ8B5OYOAZl/grQzWwXneNF4nSZJ6qAlmlhXQTPX6SlIr0obpbLY5scDfLcCHAJIcA7xwRSqWJEnjNcumiV+TZMOqWth0QV3blF/NILkyYaOmbEoz7Wp6/AxfJ0mStDQnAK9oHr8COH6o/G+b2VSPA/441JU1qenuJj4W13/z3eNugtRL99l533E3Qeqtm889aGR1jWs38SRHA7sB909yFfAB4GPAl5O8hsH2UHs3l38TeDqDbaJuAl41nTqm2qphsnnmAe41nZtLkqTZa1wzhqrqxZOcevJSri3gjctbx1QZnE9Mce6S5a1IkiRpVKbaqmH3UTZEkiSN1ri6qEbB9WwkSVLnzOpBxpIkqT3zupvAMcCRJKmvuhzgTGc38SR5WZL3N883TvKY9psmSZI0M9MZg3Mwg4X9JqZ03YC7iUuSNOclaeWYDabTRfXYqtohybkAVfX7ZvNNSZKkWWk6Ac7tSVYBCiDJBsAdrbZKkiS1rtdjcIB/B44DHpBkf+AHwD+32ipJkqQVMJ3dxI9KcjaD5ZMDPKeqLm69ZZIkqVWzZLhMK5YZ4CTZmMHmVt8YLquqX7bZMEmS1K55HY5wpjMG538YjL8JsDrwMOBS4FEttkuSJGnGptNFtc3w82aX8Te01iJJkjQSXd6vabnfW1WdAzy2hbZIkiStFNMZg/O2oafzgB2AX7fWIkmSNBIdHoIzrTE46ww9XsRgTM6x7TRHkiSNSm8HGTcL/K1TVe8YUXskSZJW2KQBTpJVq2pRkieOskGSJGk0OpzAmTKD8yMG423OS3IC8BXgxomTVfW1ltsmSZI0I9MZg7M6cB2wB3eth1OAAY4kSXNYl/eimirAeUAzg+oC7gpsJlSrrZIkSa3r6yDjVYC1uXtgM8EAR5IkzVpTBTgLq+rDI2uJJEkaqQ4ncKZcybjDb1uSJHXZVBmcJ4+sFZIkaeS6PMh40gxOVV0/yoZIkiStLNOZJi5JkjooHR6NYoAjSVJP9bKLSpIkaa4ygyNJUk+ZwZEkSZpDzOBIktRT6fBKfwY4kiT1lF1UkiRJc4gZHEmSeqrDPVRmcCRJUveYwZEkqafmdTiFY4AjSVJPOchYkiRpDjGDI0lST3W4h8oMjiRJ6h4zOJIk9dQ8upvCMYMjSZI6xwyOJEk91eUxOAY4kiT1lNPEJUmS5hAzOJIk9ZQrGUuSJK0kSR4OHDNUtCnwfmB94O+A3zbl762qb86kDgMcSZJ6alwJnKq6FNh+0IasAlwNHAe8CvhUVR24onUY4EiS1FOzpIvqycAVVfWLrMT2OMhYkiStVEnmJzlr6Jg/xeUvAo4eer5vkgVJDktyn5m2wQBHkqSeSto5qurQqtpp6Dh06fXn3sCzgK80RZ8BNmPQfbUQ+MRM35sBjiRJGpe9gHOq6hqAqrqmqhZX1R3AZ4HHzPTGjsGRJKmnZkGW48UMdU8l2bCqFjZPnwtcMNMbG+BIktRTK3NQ7wzqXgvYE3jdUPHHk2wPFHDlEueWiwGOJEkauaq6EbjfEmUvX1n3N8CRJKmnZsUk8ZbMgu43SZKklcsMjiRJPTVLFvprhRkcSZLUOWZwJEnqqe7mbwxwJEnqrQ73UNlFJUmSuscMjiRJPTXOhf7aZgZHkiR1jhkcSZJ6qstZDgMcSZJ6yi4qSZKkOcQMjiRJPdXd/I0ZHEmS1EFmcCRJ6qkuj8ExwJEkqae63I3T5fcmSZJ6ygyOJEk91eUuKjM4kiSpc8zgSJLUU93N3xjgSJLUWx3uobKLSpIkdY8ZHEmSempehzupzOBIkqTOMYMjSVJPOQZnJUqyZZLPjrpeSZLUH60FOEm2TXJikguS/FOSDZMcC5wMXNRWvZIkaXrS0n+zQZsZnM8CXwKeD/wWOA+4Ati8qj7VYr2SJGkaknaO2aDNMTirVdXhzeNLk7y5qt7VYn2SJElAuwHO6kkezV0LJd46/LyqzmmxbkmStAxdnibeZoCzEPjk0PPfDD0vYI8W65YkST3WWoBTVbu3dW9JkrTiZst4mTa0ug5OkvsBLwG2aoouBr5UVde3Wa8kSVq2Lgc4bU4TfwRwAbAj8FPgMmBn4IIkW031WkmSpBXRZgbnI8Cbq+rLw4VJng/sz2D6uCRJGpPZsmZNG9pcB2ebJYMbgKo6Fti6xXolSVLPtZnBuXGG5yRJ0gjM624Cp9UA5wFJ3raU8gAbtFivJEmahi53UbUZ4HwWWGeSc59rsV5JktRzba6D86HpXJfkPVX10bbaIUmSls5p4u16wbgbIEmSuqXVhf6mqcPxoyRJs1eXx+DMhgxOjbsBkiSpW8zgSJLUU12eJt56BifJE5dR9pW22yBJku4pLf03G4yii+rTU5VV1T+PoA2SJKlHWuuiSvJ44AnABkss+LcusEpb9Wq8br31Vl79ipdy+223sWjxYp6y51/xhn3fNO5mSZ1yyAdeyl67bs1vr7+BnV4w+DfiNls+mE+/70WstcZq/OLX1/Gq9x3BDTfecudrHvKg+3DOsf/A/od8k3/94nfH1XTNMk4Tn5l7A2szCKLWGTr+BPxNi/VqjO5973vz2cOO4MtfO4Fjvvp1/u/001jwk/PG3SypU774jTN59hv/425ln3n/S/iHfz+enff+Z0743k946yuefLfzB7z9eZx4+oWjbKY0pSRXJjk/yXlJzmrK7pvkpCSXNX/eZ6b3b3Ohv1OAU5IcXlW/aKsezS5JWHPNtQBYtGgRixYtIl3+J4I0BqefcwUbb3jfu5VtvvED+MHZlwNw8pmXcMLBb+TDB/8PAM/cbVuuvPo6brz5tpG3VbPbLPjpvHtV/W7o+X7Ad6vqY0n2a56/eyY3HsUYnMOTnLzkMYJ6NSaLFy9m7+c/mz12fQKPe/wT2Gbb7cbdJKnzLv7ZQp6527YAPG/PHdjogYN/+K61xr15+6v2ZP///OY4m6dZal7SyrECng0c0Tw+AnjOjN/birRimt4BvLM5/hE4DzhrBPVqTFZZZRW+fOzxfOe7p3DB+Qu4/LKfjrtJUue97oNHMX/vXTj9qHex9pqrcdvtiwH4h33+mk//18lmbzQbFXBikrOTzG/KHlhVC5vHvwEeONObt74OTlWdvUTR6Ul+NNn1zZucD/Dpg/+T17x2/mSXapZbd9112fkxj+X0H5zG5ltsOe7mSJ320yuv4ZlvGIzL2XzjB7DXLo8CYOetH8pzn7I9+7/lOay3zhrccUdxy223c8gxp46zuZol2uqiGv5d3ji0qg5d4rInVdXVSR4AnJTkkuGTVVVJZrwYcOsBTpLhjuJ5wI7AepNd33wAhwLcfLurHM81119/Pauuuirrrrsut9xyC2ee8X+86tV/N+5mSZ23wX3W5re//zNJ2O/v/orPfvUHADzlNf965zXve93TufGmWw1u1Lrh3+VTXHN18+e1SY4DHgNck2TDqlqYZEPg2pm2YRQrGZ/NIA0VYBHwc+A1I6hXY/C7317LP75vP+5YvJg7qnjqXz2NXXfbfdzNkjrliI++kl123IL7r782l3/7I3zkkG+y9hqr8boX7grA8Sefx5HHnznmVmpOGNMo4yRrAfOq6obm8VOBDwMnAK8APtb8efyM66iavUkSMzjSeNz3MfuOuwlSb9187kEjCzt+eMUfW/k9+9jN1pvyPSTZFDiueboq8KWq2j/J/YAvAxsDvwD2rqrrZ9KGUXRR3Qt4PbBrU/R94D+r6va265YkSbNPVf0MuMcU26q6DnjyPV+x/EbRRfUZ4F7Awc3zlzdlrx1B3ZIkaRJdXqZsFAHOzlU1HKWdnOQnI6hXkiT11CjWwVmcZLOJJ02/2+IR1CtJkqaQlo7ZYBQZnHcC30vyMwbv+6HAq0ZQryRJ6qlRLPT33SRbAA9vii6tqlvbrleSJC3DbEm3tGAUGRwYLO63SVPf9kmoqiNHVLckSVqKdDjCGcU08S8CmzHYg2pi7E0BBjiSJKkVo8jg7AQ8smbzioKSJPVQl6eJj2IW1QXAg0ZQjyRJEtBiBifJNxh0Ra0DXNTsIH7n4OKqelZbdUuSpGXrcAKn1S6qA1u8tyRJWlEdjnBaC3Cq6hSAJAdU1buHzyU5ADilrbolSVK/jWIMzp5LKdtrBPVKkqQppKX/ZoM2x+C8HngDsGmSBUOn1gFOb6teSZKkNsfgfAn4FvBRYL+h8huq6voW65UkSdPQ5WnibQY4VVVXJnnjkieS3NcgR5Kk8epwfNN6BucZwNkMposPf44FbNpi3ZIkqcfanEX1jObh6QxmTJ1WVZe0VZ8kSVpOHU7hjGIW1eeBDYFPJ/lZkq8mefMI6pUkST3V+l5UVfW9JKcCOwO7A/sAWwP/1nbdkiRpcrNlSncbRrGb+HeBtYAzgNOAnavq2rbrlSRJ/TWKLqoFwG0MsjbbAlsnWWME9UqSpCkk7RyzwSi6qN4KkGQd4JXAFxjsLr5a23VLkqTJzZJYpBWj6KLaF9gF2BG4EjiMQVeVJElSK1oPcIDVgU8CZ1fVohHUJ0mSpqPDKZxRdFEd2HYdkiRJw0aRwZEkSbOQ08QlSVLnzJYZT20YxTRxSZKkkTKDI0lST3U4gWMGR5IkdY8ZHEmS+qrDKRwDHEmSeqrLs6jsopIkSZ1jBkeSpJ5ymrgkSdIcYgZHkqSe6nACxwyOJEnqHjM4kiT1VYdTOAY4kiT1lNPEJUmS5hAzOJIk9ZTTxCVJkuYQMziSJPVUhxM4BjiSJPVWhyMcu6gkSVLnmMGRJKmnnCYuSZI0hxjgSJLUU0k7x7LrzUOSfC/JRUkuTPLmpvyDSa5Ocl5zPH2m780uKkmSemqMHVSLgLdX1TlJ1gHOTnJSc+5TVXXgilZggCNJkkaqqhYCC5vHNyS5GHjwyqzDLipJkvoq7RxJ5ic5a+iYP2kTkk2ARwM/bIr2TbIgyWFJ7jPTt2aAI0mSVqqqOrSqdho6Dl3adUnWBo4F3lJVfwI+A2wGbM8gw/OJmbbBLipJknpqnNPEk9yLQXBzVFV9DaCqrhk6/1ngv2d6fzM4kiRppJIE+DxwcVV9cqh8w6HLngtcMNM6zOBIktRTY9xN/InAy4Hzk5zXlL0XeHGS7YECrgReN9MKDHAkSeqpccU3VfWDSar/5sqqwy4qSZLUOWZwJEnqqTF2UbXODI4kSeocMziSJPVWd1M4BjiSJPWUXVSSJElziBkcSZJ6qsMJHDM4kiSpe8zgSJLUU10eg2OAI0lST41zs8222UUlSZI6xwyOJEl91d0EjhkcSZLUPWZwJEnqqQ4ncMzgSJKk7jGDI0lSTzlNXJIkdY7TxCVJkuYQMziSJPVVdxM4ZnAkSVL3mMGRJKmnOpL14roAAA7WSURBVJzAMcCRJKmvujyLyi4qSZLUOWZwJEnqKaeJS5IkzSFmcCRJ6inH4EiSJM0hBjiSJKlz7KKSJKmn7KKSJEmaQ8zgSJLUU04TlyRJmkPM4EiS1FNdHoNjgCNJUk91OL6xi0qSJHWPGRxJkvqqwykcMziSJKlzzOBIktRTXZ4mboAjSVJPdXkWlV1UkiSpc8zgSJLUUx1O4JjBkSRJ3WMGR5KkvupwCscAR5KknuryLCq7qCRJUueYwZEkqae6PE08VTXuNqijksyvqkPH3Q6pb/zuSXZRqV3zx90Aqaf87qn3DHAkSVLnGOBIkqTOMcBRmxwDII2H3z31noOMJUlS55jBkSRJnWOAI0mSOscAR5IkdY4BjqYtyTeTrN8cbxgq3y3Jfy/Hfb6f5NIkC5JckuSgJOsPnV+c5LwkFyT5xvA5qYtW1ndrGXXsluQJy7jmg0mubr5/lyX5WpJHDp2f+O7+JMmPk2y/MtomtcEAR9NWVU+vqj8A6wNvWNb1y/DSqtoW2Ba4FTh+6NzNVbV9VW0NXA+8cQXrkma1lfzdmsxuwJQBTuNTzfdvC+AY4OQkGwydf2lVbQccDPzLym+mtHIY4OhOSd6Z5E3N408lObl5vEeSo5JcmeT+wMeAzZp/5U38gFs7yVebjMxRyfR2OKmq24B3ARsn2W4pl5wBPHiF35w0Rm18t5I8Ocm5Sc5PcliS1ZryiXuRZKcm67IJsA/w1ubeu0yn3VV1DHAi8JKlnPa7qVnNAEfDTgMmfvDtxOAH672aslOHrtsPuKL5V947m7JHA28BHglsCjxxupVW1WLgJ8BWw+VJVgGeDJyw/G9FmlVW6ncryerA4cALq2obBhsnv36yyqvqSuAQ7srOnLYcbT+HJb6bjacBX1+O+0gjZYCjYWcDOyZZl0G30RkMfhjvwuAH9FR+VFVXVdUdwHnAJstZ93DGZ40k5wG/AR4InLSc95Jmm5X93Xo48POq+mlzzRHArm00nLt/NwGOSvJz4H3Af7RUp7TCDHB0p6q6Hfg58Erg/xj84N0d2By4eBkvv3Xo8WIG/6KcliZTs81QHTdX1fbAQxn8cHUMjua0EX+3FnHXz/bVl7etS/Fo7t7GlzLIJB0BfHol3F9qhQGOlnQa8A4GafPTGPTbn1t3X/L6BmCdlVFZk6b/KPCrqlowfK6qbgLeBLw9ybQDJmmWWpnfrUuBTZJs3jx/OXBK8/hKYMfm8fNncO87JXk+8FTg6OHyps3/CDwuydK6r6SxM8DRkk4DNgTOqKprgFtYIoVeVdcBpzfTuGc6i+KoJAuAC4C1gGcv7aKqOhdYALx4hvVIs8VK+25V1S3Aq4CvJDkfuIPBGBuADwH/luQsBhmfCd8AnjuNQcYTA5EvA14G7FFVv11KG24GPgG8c8lz0mzgXlSSJKlzzOBIkqTOcVyDWpPkOOBhSxS/u6q+M472SBpI8j7gBUsUf6Wq9h9He6Q22EUlSZI6xy4qSZLUOQY4kiSpcwxwpFlgiR3Uv5JkzRW41+FJ/qZ5/Lnh3aCXcu0yd5ie5HV37nc0nfIlrvnzctb1wSTvWN42Suo3AxxpdhjeQf02BovA3WmmCx1W1Wur6qIpLtmN6e0wLUlzigGONPucBmzeZFdOS3ICcFGSVZL8S5IfJ1mQ5HUAGTgoyaVJ/hd4wMSNmp2kd2oePy3JOUl+kuS7S9thOskGSY5t6vhxkic2r71fkhOTXJjkc9xzf6J7SPL1JGc3r5m/xLlPNeXfTbJBU7ZZkm83rznNFXIlrQiniUuzSJOp2Qv4dlO0A7B1Vf28CRL+WFU7J1mNwYq3JzLYK+jhDHabfiBwEXDYEvfdAPgssGtzr/tW1fVJDgH+XFUHNtd9icGO0z9IsjHwHeARwAeAH1TVh5P8NfCaabydVzd1rAH8OMmxzUq9awFnVdVbk7y/ufe+wKHAPlV1WZLHAgcDe8zgY5QkAxxplpjYQR0GGZzPM+g6+lFV/bwpfyqw7cT4GmA9YAsGu0gfXVWLgV8nOXkp938ccOrEvarq+kna8RTgkcmdCZp1k6zd1PG85rX/k+T303hPb0ry3ObxQ5q2XsdgW4FjmvL/Ar7W1PEEBlsPTLx+tWnUIUlLZYAjzQ4TO6jfqflFf+NwEfD3Sy6UmOTpK7Ed84DHNXsdLdmWaUuyG4Ng6fFVdVOS7zP5ztbV1PuHJT8DSZopx+BIc8d3gNc3O7CTZMskazHYnfqFzRidDYHdl/LaM4Fdkzysee19m/Ild5g+Efj7iSdJJgKOU4GXNGV7AfdZRlvXA37fBDdbMcggTZgHTGShXsKg6+tPwM+TvKCpI0m2W0YdkjQpAxxp7vgcg/E15yS5APhPBlnY44DLmnNHAmcs+cJmN+j5DLqDfsJdXURL7jD9JmCnZhDzRdw1m+tDDAKkCxl0Vf1yGW39NrBqkouBjzEIsCbcCDymeQ97AB9uyl8KvKZp34VMssO8JE2HWzVIkqTOMYMjSZI6xwBHkiR1jgGOJEnqHAMcaRZIslqSY5JcnuSHzSrDS7vuzc1+VRcmectQ+fZJzmwGC5+V5DFD53Zryi9McspQ+VubsguSHJ1ksmncy/teptz/apLXbNIMOh6ZJO9pPu9Lk/zVJNc8rPn7uLz5+7l3U75rsyr0oqF1iUjy0KZ84vPepylfM8n/JLmkKf/YaN6l1F8GONIkMsP9n2boNQymVW8OfAo4YCnt2Rr4O+AxwHbAM5Js3pz+OPChZh2Z9zfPSbI+gxWBn1VVjwImpmE/mGbGVLP/1SrAi1bGG5nG/ldj1wRgLwIeBTwNODjJKku59AAGKztvDvyeu1Zw/iXwSuBLS1y/kMHaP9sDjwX2S/IXzbkDq2orBitPP7GZbi+pJQY4mnMm2+MoS+y11JStneQLSc5vpj4/vyn/89Dr/ibJ4c3jw5MckuSHwMeTPCbJGUnOTfJ/SR7eXLdKkgOb7MeCJH+fZI8kXx+6755Jjpvm23o2cETz+KvAk3PP1fUeAfywqm6qqkXAKTSrCzNYLG/d5vF6wK+bxy8BvlZVvwSoqmuH7rcqgxWUVwXWnHhNkg8nedaSDcxgV+8jMtgn6hdJnpfk481n++3ctT7P95Ps1HxGhzef0flJ3tqc3zzJ/zZ/T+ck2WyJejZp6jinOZ7QlG+Y5NTctev6LpPVMc3P+/9V1a3N6s6XMwgch9sRBtPYv9oUHQE8p/kcr6yqBQxWZb5TVd1WVbc2T1ej+Rnb/J19b+Ia4Bxgo2m2VdIMuJKx5qJ77HHE4BfJ3fZaaq79Rwb7N20DkGRZC9TB4BfPE6pqcZJ1gV2qalGSpwD/DDyfwZoymwDbN+fuy+Bf+Acn2aBZd+ZVNHtCJTmGwX5RS/pkVR0JPBj4FUBzvz8C9wN+N3TtBcD+Se4H3Aw8HTirOfcW4DtJDmw+i4kdwrcE7pXBSsLrAP9WVUdW1dXNtb9s7nViVZ3Y1P/+KT6bzRgsJPhIBuvtPL+q3tUEcn8NfH3o2u2BBzcZoolsEsBRwMeq6rgMusXmMbRBKHAtsGdV3ZJkC+BoYCcGwdp3qmr/Jtuy5mR1JHkng3V1lnRqVb2Jwec9vDbPVU3ZsPsxWF150RTX3EOShwD/A2wOvLOqfr3E+fWBZwL/tqx7SZo5AxzNRUvb42gDlr7X0lMY6nqpqunsofSVZl8nGGRDjmh+0RZwr6H7HjLxy2+iviRfBF6W5AvA44G/bc6/cCZvdFhVXZzkAAarDd8InAdMtPP1wFur6tgkezPYy+opDL7jOwJPBtYAzkhyJvBbBlmMhwF/YLAH1Muq6r+W0YxvVdXtSc5n0K01sSno+QwCvmE/AzZN8mkGv/BPTLIOg4DkuOY93QL32AriXsBBGayivJhBkAbwY+CwJlP09ao6L8k96mju+y/AvyzjvbSiqn7FYM+wvwC+nuSrVXUN3NnteTTw71X1s3G0T+oLu6g0p+TuexxtB5zL5HscTWV4hcslXz+8/9NHgO81GYJnTqOuLwAvA17MIFBa1LT7mKZrZcnjb5vXXc0gWJv4Jbgeg40p797oqs9X1Y5VtSuDjNFPm1OvAL7WPP4Kd3W3XMUg63FjVf2OwZYL2zH4DH9eVb+tqtub105kfaZya9OOO4Db666VQu9giX8wNcHkdsD3GayI/Llp3B/grcA1zWt3Au7d3O9UBpt+Xg0cnuRvJ6sjyTsn+bz/vanjzs+7sVFTNuw6YP3cNRZraddMqsncXADsMlR8KHBZVf3rdO8jaWYMcDTXTLbH0WR7LZ0EvHHixUNdVNckeUSSecBENmiy+iZ+qb1yqPwk4HUTv/wm6mt+qf0a+AcGwQ5N+QuravulHEc2l5zAIEiBwT5NJw8FD3dK8oDmz40ZjL+ZGOT6a+Avm8d7MNi6AeB44ElJVk2yJoOBrxcz6Jp6XAaze8Igw3Nxc++PDmXIZizJ/YF5VXVs83nsUFU3AFcleU5zzWpNu4atByxsgqiXM8gUkeShwDVV9VkGgcwOS6sDBhmcST7vNzV1nAC8qKn/YQyygD8abkTz+X+Pu/bNegWDz3Oq97xR03U68f/ak4BLm+f/1Ly3t0x+B0kriwGO5pql7nE0xV5L/wTcpxmE+hPu2ohyP+C/gf9jMPNlMh8HPprkXO6eofgcgyBhQXPflwydOwr4VVVdvBzv6/PA/ZJcDrytaR9J/iLJN4euOzaDPaK+Abyxqv7QlP8d8ImmLf/M4LOgacO3gQUMfoF/rqouqKofMhg8ew6D7qV5DLILANsAv1mOtk/mwcD3k5wH/Bfwnqb85Qy6GRcw+PwftMTrDgZe0byXrbgro7Yb8JPm7+KFDMawTFbHlKrqQuDLDPbv+jaDz3IxQJJv5q6ZT+8G3tb8vdyPwd8TSXZOchWDWWn/mcEeXdAMBG/afgqDmVPnJ9kIeB+DsUsT08hfO522SpoZ96KSVrIkBwHnVtXnx92WmUjynapa6rowkjRXGOBIK1GSsxlkHPYcmi4sSRoxAxxJktQ5jsGRJEmdY4AjSZI6xwBHkiR1jgGOJEnqHAMcSZLUOf8f6nHKKv5LAvcAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The details for confusion matrix is =\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     with_DR       0.98      0.99      0.99       181\n",
            "  without_DR       0.99      0.98      0.99       197\n",
            "\n",
            "    accuracy                           0.99       378\n",
            "   macro avg       0.99      0.99      0.99       378\n",
            "weighted avg       0.99      0.99      0.99       378\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sensitivity = cm[0,0]/(cm[0,0]+cm[1,0])\n",
        "print('Sensitivity : ', sensitivity*100 )\n",
        "\n",
        "Specificity = cm[1,1]/(cm[1,1]+cm[0,1])\n",
        "print('Specificity : ', Specificity*100 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWtsMSnK0akC",
        "outputId": "c374cb13-2674-4943-d715-fd99f4fc15b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sensitivity :  98.35164835164835\n",
            "Specificity :  98.9795918367347\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "QeH2BJG5_-T4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = loaded_model.predict(validation_data)\n",
        "predictions = [i.argmax() for i in preds]\n",
        "y_true = [i.argmax() for i in validation_labels]\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJxyI737ACji",
        "outputId": "bd9e24da-fb12-4fec-84ab-f6d904256e14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_df=pd.read_csv('/content/drive/MyDrive/My_projects _and _datasets/Final_work/Binary_prediction - Sheet1.csv')\n",
        "val_df['ResNet152V2']=predictions\n",
        "val_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "5NWBLAA7AE5D",
        "outputId": "a82da664-2064-4949-984c-1aeeece721d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  True Label  vgg16  xception  \\\n",
              "0             0             0               0           0      0         0   \n",
              "1             1             1               1           0      0         0   \n",
              "2             2             2               2           0      0         0   \n",
              "3             3             3               3           0      0         0   \n",
              "4             4             4               4           0      0         0   \n",
              "..          ...           ...             ...         ...    ...       ...   \n",
              "651         651           651             651           1      1         1   \n",
              "652         652           652             652           1      1         1   \n",
              "653         653           653             653           1      1         1   \n",
              "654         654           654             654           1      1         1   \n",
              "655         655           655             655           1      1         1   \n",
              "\n",
              "     DenseNet121  ResNet152V2  \n",
              "0              0            0  \n",
              "1              0            1  \n",
              "2              0            0  \n",
              "3              1            1  \n",
              "4              0            0  \n",
              "..           ...          ...  \n",
              "651            1            1  \n",
              "652            1            1  \n",
              "653            1            1  \n",
              "654            1            1  \n",
              "655            1            1  \n",
              "\n",
              "[656 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0a8f5fff-5996-4fe7-a3e4-047fc56e714d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0.1.1</th>\n",
              "      <th>True Label</th>\n",
              "      <th>vgg16</th>\n",
              "      <th>xception</th>\n",
              "      <th>DenseNet121</th>\n",
              "      <th>ResNet152V2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>651</th>\n",
              "      <td>651</td>\n",
              "      <td>651</td>\n",
              "      <td>651</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>652</th>\n",
              "      <td>652</td>\n",
              "      <td>652</td>\n",
              "      <td>652</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>653</th>\n",
              "      <td>653</td>\n",
              "      <td>653</td>\n",
              "      <td>653</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>654</th>\n",
              "      <td>654</td>\n",
              "      <td>654</td>\n",
              "      <td>654</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>655</th>\n",
              "      <td>655</td>\n",
              "      <td>655</td>\n",
              "      <td>655</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>656 rows  8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0a8f5fff-5996-4fe7-a3e4-047fc56e714d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0a8f5fff-5996-4fe7-a3e4-047fc56e714d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0a8f5fff-5996-4fe7-a3e4-047fc56e714d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_df.to_csv('/content/drive/MyDrive/My_projects _and _datasets/Final_work/Binary_prediction - Sheet1.csv')"
      ],
      "metadata": {
        "id": "cgMObWtCANdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df=pd.read_csv('/content/drive/MyDrive/My_projects _and _datasets/Final_work/Binary_confidence_matrix - Sheet1.csv')\n",
        "preds = loaded_model.predict(test_data)\n",
        "for i in range(0,2):\n",
        "  test_df['ResNet152V2_class'+str(i)]=preds[:,i]"
      ],
      "metadata": {
        "id": "860M6EGAAWpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "rQn9Kvz9Acvl",
        "outputId": "f9fe3985-c77a-4b22-fa0d-601a9fc942db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  True Label  vgg16_class0  \\\n",
              "0             0             0               0           0      1.000000   \n",
              "1             1             1               1           0      0.650171   \n",
              "2             2             2               2           0      0.999786   \n",
              "3             3             3               3           0      0.999226   \n",
              "4             4             4               4           0      1.000000   \n",
              "..          ...           ...             ...         ...           ...   \n",
              "373         373           373             373           1      0.000005   \n",
              "374         374           374             374           1      0.000115   \n",
              "375         375           375             375           1      0.000070   \n",
              "376         376           376             376           1      0.000016   \n",
              "377         377           377             377           1      0.000024   \n",
              "\n",
              "     vgg16_class1  xception_class0  xception_class1  DenseNet121_class0  \\\n",
              "0    3.271071e-08     9.999988e-01     1.115273e-06        9.820170e-01   \n",
              "1    3.464978e-01     9.999999e-01     2.007653e-07        9.999959e-01   \n",
              "2    1.910670e-04     1.000000e+00     7.120615e-14        1.000000e+00   \n",
              "3    7.497075e-04     9.805162e-01     1.904154e-02        9.609939e-01   \n",
              "4    9.023950e-08     1.000000e+00     8.365292e-09        1.000000e+00   \n",
              "..            ...              ...              ...                 ...   \n",
              "373  9.999956e-01     8.094603e-12     1.000000e+00        3.967403e-07   \n",
              "374  9.999150e-01     4.629031e-05     9.999508e-01        1.524401e-05   \n",
              "375  9.999461e-01     6.023692e-06     9.999930e-01        2.297094e-04   \n",
              "376  9.999875e-01     7.922729e-09     1.000000e+00        4.790058e-06   \n",
              "377  9.999841e-01     2.996096e-05     9.999675e-01        7.265744e-06   \n",
              "\n",
              "     DenseNet121_class1  ResNet152V2_class0  ResNet152V2_class1  \n",
              "0          1.637366e-02        9.998286e-01        1.799166e-04  \n",
              "1          3.717736e-06        9.999616e-01        4.475310e-05  \n",
              "2          4.247401e-09        1.000000e+00        3.075749e-19  \n",
              "3          4.056132e-02        9.999957e-01        4.397965e-06  \n",
              "4          4.018924e-11        1.000000e+00        3.282192e-10  \n",
              "..                  ...                 ...                 ...  \n",
              "373        9.999998e-01        1.910947e-10        1.000000e+00  \n",
              "374        9.999863e-01        1.259385e-05        9.999866e-01  \n",
              "375        9.998475e-01        3.575140e-05        9.999652e-01  \n",
              "376        9.999969e-01        1.016903e-08        1.000000e+00  \n",
              "377        9.999924e-01        1.196283e-05        9.999905e-01  \n",
              "\n",
              "[378 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-78591d21-0cd8-4224-b644-2f2d1233b033\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0.1.1</th>\n",
              "      <th>True Label</th>\n",
              "      <th>vgg16_class0</th>\n",
              "      <th>vgg16_class1</th>\n",
              "      <th>xception_class0</th>\n",
              "      <th>xception_class1</th>\n",
              "      <th>DenseNet121_class0</th>\n",
              "      <th>DenseNet121_class1</th>\n",
              "      <th>ResNet152V2_class0</th>\n",
              "      <th>ResNet152V2_class1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.271071e-08</td>\n",
              "      <td>9.999988e-01</td>\n",
              "      <td>1.115273e-06</td>\n",
              "      <td>9.820170e-01</td>\n",
              "      <td>1.637366e-02</td>\n",
              "      <td>9.998286e-01</td>\n",
              "      <td>1.799166e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.650171</td>\n",
              "      <td>3.464978e-01</td>\n",
              "      <td>9.999999e-01</td>\n",
              "      <td>2.007653e-07</td>\n",
              "      <td>9.999959e-01</td>\n",
              "      <td>3.717736e-06</td>\n",
              "      <td>9.999616e-01</td>\n",
              "      <td>4.475310e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.999786</td>\n",
              "      <td>1.910670e-04</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>7.120615e-14</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>4.247401e-09</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>3.075749e-19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.999226</td>\n",
              "      <td>7.497075e-04</td>\n",
              "      <td>9.805162e-01</td>\n",
              "      <td>1.904154e-02</td>\n",
              "      <td>9.609939e-01</td>\n",
              "      <td>4.056132e-02</td>\n",
              "      <td>9.999957e-01</td>\n",
              "      <td>4.397965e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>9.023950e-08</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>8.365292e-09</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>4.018924e-11</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>3.282192e-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>373</th>\n",
              "      <td>373</td>\n",
              "      <td>373</td>\n",
              "      <td>373</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>9.999956e-01</td>\n",
              "      <td>8.094603e-12</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>3.967403e-07</td>\n",
              "      <td>9.999998e-01</td>\n",
              "      <td>1.910947e-10</td>\n",
              "      <td>1.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>374</th>\n",
              "      <td>374</td>\n",
              "      <td>374</td>\n",
              "      <td>374</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000115</td>\n",
              "      <td>9.999150e-01</td>\n",
              "      <td>4.629031e-05</td>\n",
              "      <td>9.999508e-01</td>\n",
              "      <td>1.524401e-05</td>\n",
              "      <td>9.999863e-01</td>\n",
              "      <td>1.259385e-05</td>\n",
              "      <td>9.999866e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375</th>\n",
              "      <td>375</td>\n",
              "      <td>375</td>\n",
              "      <td>375</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000070</td>\n",
              "      <td>9.999461e-01</td>\n",
              "      <td>6.023692e-06</td>\n",
              "      <td>9.999930e-01</td>\n",
              "      <td>2.297094e-04</td>\n",
              "      <td>9.998475e-01</td>\n",
              "      <td>3.575140e-05</td>\n",
              "      <td>9.999652e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>376</th>\n",
              "      <td>376</td>\n",
              "      <td>376</td>\n",
              "      <td>376</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>9.999875e-01</td>\n",
              "      <td>7.922729e-09</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>4.790058e-06</td>\n",
              "      <td>9.999969e-01</td>\n",
              "      <td>1.016903e-08</td>\n",
              "      <td>1.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>377</th>\n",
              "      <td>377</td>\n",
              "      <td>377</td>\n",
              "      <td>377</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>9.999841e-01</td>\n",
              "      <td>2.996096e-05</td>\n",
              "      <td>9.999675e-01</td>\n",
              "      <td>7.265744e-06</td>\n",
              "      <td>9.999924e-01</td>\n",
              "      <td>1.196283e-05</td>\n",
              "      <td>9.999905e-01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>378 rows  12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-78591d21-0cd8-4224-b644-2f2d1233b033')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-78591d21-0cd8-4224-b644-2f2d1233b033 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-78591d21-0cd8-4224-b644-2f2d1233b033');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.to_csv('/content/drive/MyDrive/My_projects _and _datasets/Final_work/Binary_confidence_matrix - Sheet1.csv')"
      ],
      "metadata": {
        "id": "JQOBV_pnAno8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}